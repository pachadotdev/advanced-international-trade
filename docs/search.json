[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced International Trade in R",
    "section": "",
    "text": "About\nI tried to replicate Feenstra’s results in R, because I had to learn a bit of Stata for the course ECO3300 (International Trade) taught at the University of Toronto. To organize my notes, I used Quarto to present my R outputs in a decently formatted HTML file.\nI have a printed copy of the first edition, so I am using the data and codes from the first edition.\nThe goal of these solutions is to provide a reference for those who come from Stata and want to learn R. I prioritized readability and simplicity over performance and elegance. There were parts of the code were it was challenging to stick to a literal code translation, and I had to use R idioms to make the code more readable.\nThere are tasks that are hard to write in Stata, but easy in R, and vice versa. As the exercises progress, I intentionally used more R idioms to make the code less repetitive and using R idioms, while keeping the code as readable as possible.\nThese notes have a public GitHub repository. The repository has a detailed track of changes, but not all the codes outside the Quarto documents therein are required as of June, 2024.\nWhen I started this project (Sept, 2023), the links from Prof. Feenstra’s website were broken, so I went to the Internet Archive Wayback Machine to find the linked site (The Center for International Data) from 2005-03-08 and I downloaded it with wget (i.e., I ran bash 00-download-wayback-backup.sh from the repository). This is not needed anymore because:\n\nI added the data files to the repository.\nProf. Feenstra’s website is now working, and he was really kind to fix the links when I asked him for permission to use the data and codes that I recovered.\n\nAll the datasets and Stata codes are intellectual property of Dr. Robert C. Feenstra. The R codes are of my authorship, but these are a translation of the Stata codes, so I released them under Creative Commons Zero v1.0 Universal.\nI appreciate the feedback that I received from Prof. Feenstra and Prof. Mingzhi “Jimmy” Xu.\nPlease do not hesistate to email me if this is useful, or if you have any questions or suggestions. My email is m.sepulveda@mail.utoronto.ca."
  },
  {
    "objectID": "chapter2.html#read-and-transform-the-data",
    "href": "chapter2.html#read-and-transform-the-data",
    "title": "Chapter 2. The Heckscher-Ohlin Model",
    "section": "Read and transform the data",
    "text": "Read and transform the data\n\nFeenstra’s code\n* This is to read the data into Stata *\n\nset mem 30m\n* insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler.csv *\ninsheet using \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\hov_pub.csv\"\nrename v1 country\nrename v2 factor\nrename v3 AT\nrename v4 V\nrename v5 Y\nrename v6 B\nrename v7 YPC\nrename v8 POP\n\n* create country index *\nquietly summarize YPC\nlocal maxYPC=_result(6)\ngen ratio=YPC/`maxYPC'\nreplace ratio=ratio+0.0001 if country==\"Italy\"\n\nsort ratio\negen indexc=group(ratio)\n\n* create factor index *\nsort factor\negen indexf=group(factor)\n\n* include delta *\n\ngen delta=1\nreplace delta=0.03 if country==\"Bangladesh\"\nreplace delta=0.09 if country==\"Pakistan\"\nreplace delta=0.10 if country==\"Indonesia\"\nreplace delta=0.09 if country==\"Sri Lanka\"\nreplace delta=0.17 if country==\"Thailand\"\nreplace delta=0.16 if country==\"Colombia\"\nreplace delta=0.28 if country==\"Panama\"\nreplace delta=0.29 if country==\"Yugoslavia\"\nreplace delta=0.14 if country==\"Portugal\"\nreplace delta=0.11 if country==\"Uruguay\"\nreplace delta=0.45 if country==\"Greece\"\nreplace delta=0.55 if country==\"Ireland\"\nreplace delta=0.42 if country==\"Spain\"\nreplace delta=0.49 if country==\"Israel\"\nreplace delta=0.40 if country==\"Hong Kong\"\nreplace delta=0.38 if country==\"New Zealand\"\nreplace delta=0.60 if country==\"Austria\"\nreplace delta=0.48 if country==\"Singapore\"\nreplace delta=0.60 if country==\"Italy\"\nreplace delta=0.58 if country==\"UK\"\nreplace delta=0.70 if country==\"Japan\"\nreplace delta=0.65 if country==\"Belgium\"\nreplace delta=0.47 if country==\"Trinidad\"\nreplace delta=0.72 if country==\"Netherlands\"\nreplace delta=0.65 if country==\"Finland\"\nreplace delta=0.73 if country==\"Denmark\"\nreplace delta=0.78 if country==\"West Germany\"\nreplace delta=0.74 if country==\"France\"\nreplace delta=0.57 if country==\"Sweden\"\nreplace delta=0.69 if country==\"Norway\"\nreplace delta=0.79 if country==\"Switzerland\"\nreplace delta=0.55 if country==\"Canada\"\nreplace delta=1 if country==\"USA\"\n\ncompress\n\nlabel var country \"Name of the country\"\nlabel var factor \"Name of the factor\"\nlabel var AT \"Factor content of trade F=A*T\"\nlabel var V \"Endowment\"\nlabel var Y \"GDP, World Bank, y=p*Q\"\nlabel var B \"Trade balance, World Bank b=p*T\"\nlabel var YPC \"GDP per capita, PWT\"\nlabel var indexc \"Country indentifier\"\nlabel var indexf \"Factor Indentifier\"\n\n* save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler,replace *\nsave \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler\", replace\n\nexit\nOutput:\n. * This is to read the data into Stata *\n. set mem 30m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory           30M    max. data space                 30.000M\n    set matsize         400     max. RHS vars in models          1.254M\n                                                            -----------\n                                                                33.163M\n\n. insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Ch\n&gt; apter-2\\hov_pub.csv\n(8 vars, 297 obs)\n\n. rename v1 country\n\n. rename v2 factor\n\n. rename v3 AT\n\n. rename v4 V\n\n. rename v5 Y\n\n. rename v6 B\n\n. rename v7 YPC\n\n. rename v8 POP\n\n. \n. * create country index *\n. quietly summarize YPC\n\n. local maxYPC=_result(6)\n\n. gen ratio=YPC/`maxYPC'\n\n. replace ratio=ratio+0.0001 if country==\"Italy\"\n(9 real changes made)\n\n. \n. sort ratio\n\n. egen indexc=group(ratio)\n\n. \n. * create factor index *\n. sort factor\n\n. egen indexf=group(factor)\n\n. \n. * include delta *\n. \n. gen delta=1\n\n. replace delta=0.03 if country==\"Bangladesh\"\n(9 real changes made)\n\n. replace delta=0.09 if country==\"Pakistan\"\n(9 real changes made)\n\n. replace delta=0.10 if country==\"Indonesia\"\n(9 real changes made)\n\n. replace delta=0.09 if country==\"Sri Lanka\"\n(9 real changes made)\n\n. replace delta=0.17 if country==\"Thailand\"\n(9 real changes made)\n\n. replace delta=0.16 if country==\"Colombia\"\n(9 real changes made)\n\n. replace delta=0.28 if country==\"Panama\"\n(9 real changes made)\n\n. replace delta=0.29 if country==\"Yugoslavia\"\n(9 real changes made)\n\n. replace delta=0.14 if country==\"Portugal\"\n(9 real changes made)\n\n. replace delta=0.11 if country==\"Uruguay\"\n(9 real changes made)\n\n. replace delta=0.45 if country==\"Greece\"\n(9 real changes made)\n\n. replace delta=0.55 if country==\"Ireland\"\n(9 real changes made)\n\n. replace delta=0.42 if country==\"Spain\"\n(9 real changes made)\n\n. replace delta=0.49 if country==\"Israel\"\n(9 real changes made)\n\n. replace delta=0.40 if country==\"Hong Kong\"\n(9 real changes made)\n\n. replace delta=0.38 if country==\"New Zealand\"\n(9 real changes made)\n\n. replace delta=0.60 if country==\"Austria\"\n(9 real changes made)\n\n. replace delta=0.48 if country==\"Singapore\"\n(9 real changes made)\n\n. replace delta=0.60 if country==\"Italy\"\n(9 real changes made)\n\n. replace delta=0.58 if country==\"UK\"\n(9 real changes made)\n\n. replace delta=0.70 if country==\"Japan\"\n(9 real changes made)\n\n. replace delta=0.65 if country==\"Belgium\"\n(9 real changes made)\n\n. replace delta=0.47 if country==\"Trinidad\"\n(9 real changes made)\n\n. replace delta=0.72 if country==\"Netherlands\"\n(9 real changes made)\n\n. replace delta=0.65 if country==\"Finland\"\n(9 real changes made)\n\n. replace delta=0.73 if country==\"Denmark\"\n(9 real changes made)\n\n. replace delta=0.78 if country==\"West Germany\"\n(9 real changes made)\n\n. replace delta=0.74 if country==\"France\"\n(9 real changes made)\n\n. replace delta=0.57 if country==\"Sweden\"\n(9 real changes made)\n\n. replace delta=0.69 if country==\"Norway\"\n(9 real changes made)\n\n. replace delta=0.79 if country==\"Switzerland\"\n(9 real changes made)\n\n. replace delta=0.55 if country==\"Canada\"\n(9 real changes made)\n\n. replace delta=1 if country==\"USA\"\n(0 real changes made)\n\n. \n. compress\nYPC was float now int\nindexc was float now byte\nindexf was float now byte\n\n. \n. label var country \"Name of the country\"\n\n. label var factor \"Name of the factor\"\n\n. label var AT \"Factor content of trade F=A*T\"\n\n. label var V \"Endowment\"\n\n. label var Y \"GDP, World Bank, y=p*Q\"\n\n. label var B \"Trade balance, World Bank b=p*T\"\n\n. label var YPC \"GDP per capita, PWT\"\n\n. label var indexc \"Country indentifier\"\n\n. label var indexf \"Factor Indentifier\"\n\n. \n. save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\t\n&gt; refler,replace\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\tre\n&gt; fler.dta saved\n\n. \n. exit\n\nend of do-file\n\n\nMy code\n\n# Packages ----\n\nlibrary(archive)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(knitr)\n\n# Extract ----\n\nfzip &lt;- \"first-edition/Chapter-2.zip\"\ndout &lt;- gsub(\"\\\\.zip$\", \"\", fzip)\n\nif (!dir.exists(dout)) {\n  archive_extract(fzip, dir = dout)\n}\n\n# Read ----\n\nfout &lt;- paste0(dout, \"/trefler.rds\")\nfout2 &lt;- paste0(dout, \"/trefler_desc.rds\")\n\nif (!file.exists(fout)) {\n  trefler &lt;- read_csv(\"first-edition/Chapter-2/hov_pub.csv\", col_names = F) %&gt;%\n    rename(\n      country = X1,\n      factor = X2,\n      at = X3,\n      v = X4,\n      y = X5,\n      b = X6,\n      ypc = X7,\n      pop = X8\n    )\n\n  # Transform ----\n\n  # see https://www.stata.com/manuals/rsummarize.pdf\n  # https://www.stata.com/manuals/degen.pdf\n  # https://www.stata.com/manuals/degen.pdf\n\n  # Create an auxiliary table for delta values\n  delta_values &lt;- tibble(\n    country = c(\n      \"Bangladesh\", \"Pakistan\", \"Indonesia\", \"Sri Lanka\", \"Thailand\",\n      \"Colombia\", \"Panama\", \"Yugoslavia\", \"Portugal\", \"Uruguay\", \"Greece\",\n      \"Ireland\", \"Spain\", \"Israel\", \"Hong Kong\", \"New Zealand\", \"Austria\",\n      \"Singapore\", \"Italy\", \"UK\", \"Japan\", \"Belgium\", \"Trinidad\", \"Netherlands\",\n      \"Finland\", \"Denmark\", \"West Germany\", \"France\", \"Sweden\", \"Norway\",\n      \"Switzerland\", \"Canada\", \"USA\"\n    ),\n    delta = c(\n      0.03, 0.09, 0.10, 0.09, 0.17, 0.16, 0.28, 0.29, 0.14, 0.11, 0.45,\n      0.55, 0.42, 0.49, 0.40, 0.38, 0.60, 0.48, 0.60, 0.58, 0.70, 0.65, 0.47,\n      0.72, 0.65, 0.73, 0.78, 0.74, 0.57, 0.69, 0.79, 0.55, 1\n    )\n  )\n\n  trefler &lt;- trefler %&gt;%\n    mutate(ypc_max = max(ypc)) %&gt;%\n    mutate(\n      ratio = case_when(\n        country != \"Italy\" ~ ypc / ypc_max,\n        country == \"Italy\" ~ (ypc / ypc_max) + 0.0001\n      )\n    ) %&gt;%\n    select(-ypc_max) %&gt;%\n    arrange(ratio) %&gt;%\n    group_by(ratio) %&gt;%\n    mutate(indexc = cur_group_id()) %&gt;%\n    group_by(factor) %&gt;%\n    mutate(indexf = cur_group_id()) %&gt;%\n    ungroup() %&gt;%\n    left_join(delta_values)\n\n  # Labels ----\n\n  # Create a separate table with the variables description\n\n  trefler_desc &lt;- tibble(\n    variable = c(\n      \"country\", \"factor\", \"at\", \"v\", \"y\", \"b\", \"ypc\", \"indexc\",\n      \"indexf\"\n    ),\n    description = c(\n      \"Name of the country\", \"Name of the factor\",\n      \"Factor content of trade F=A*T\", \"Endowment\", \"GDP, World Bank, y=p*Q\",\n      \"Trade balance, World Bank b=p*T\", \"GDP per capita, PWT\",\n      \"Country indentifier\", \"Factor Indentifier\"\n    )\n  )\n\n  # Save ----\n\n  saveRDS(trefler, fout)\n  saveRDS(trefler_desc, fout2)\n} else {\n  trefler &lt;- readRDS(fout)\n  trefler_desc &lt;- readRDS(fout2)\n}"
  },
  {
    "objectID": "chapter2.html#exercise-1",
    "href": "chapter2.html#exercise-1",
    "title": "Chapter 2. The Heckscher-Ohlin Model",
    "section": "Exercise 1",
    "text": "Exercise 1\nGiven identical technologies across countries, run the program sign_rank_1.do to conduct the sign test, rank test, and test for missing trade. Use the results in sign_rank_1.log to replicate columns (2) and (4) in Table 2.5.\n\nFeenstra’s code\n* This program is to conduct sign test, Rank test and Missing trade test *\n\ncapture log close\n* log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\sign_rank_1.log, replace *\nlog using \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\sign_rank_1.log\", replace\n\nset mem 30m\n\n* use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler, clear *\nuse \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler\", clear\n\n* number of country in the dataset *\negen C=max(indexc)\negen F=max(indexf)\n\n* Calculate the world level of Yw, Bw and Vw *\negen Yww=sum(Y)\ngen Yw=Yww/F\negen Bww=sum(B)\ngen Bw=Bww/F\negen Vfw=sum(V), by(indexf)\n\n* Calculate country share Sc *\ngen Sc=(Y-B)/(Yw-Bw)\n\n* Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)*\ngen Efc=AT-(V-Sc*Vfw)\n\n* Construct the average epsilon for a given factor *\negen total=sum(Efc),by(indexf)\ngen ave=total/C\n\n* Construct sigma^2 and the weight *\n\negen tot=sum((Efc-ave)^2), by(indexf)\ngen sigma2f=tot/(C-1)\n\ncodebook sigma2f\ngen sigmaf=sqrt(sigma2f)\ngen weight=sigmaf*sqrt(Sc)\n\n* Using the weight, convert all the data *\n\ngen trAT=AT/(sigmaf*sqrt(Sc))\ngen trV=V/(sigmaf*sqrt(Sc))\ngen trY=Y/sqrt(Sc)\ngen trB=B/sqrt(Sc)\ngen trVfw=Vfw/sigmaf\n\ngen AThat=trV-Sc*trVfw\ngen AThat2=(V-Sc*Vfw)/weight\n\n* Correlation, should be .28 *\n\ncorr trAT AThat2\n\n*************\n* Sign Test *\n*************\n\nsort indexc\nby indexc: count if trAT*AThat2&gt;0\n\ncount if trAT*AThat2&gt;0\ndisplay _result(1)/_N\n\n*****************\n* Missing Trade *\n*****************\n\n* Checking for the missing trade, should be .032 *\n\nquietly summarize trAT\nlocal varAT=_result(4)\nquietly summarize AThat\nlocal varHat=_result(4)\nquietly summarize AThat2\nlocal varHat2=_result(4)\ndisplay `varAT'/`varHat'\ndisplay `varAT'/`varHat2'\n\n**************\n* Rank Tests *\n**************\n\nkeep country indexc indexf trAT AThat2\n\nsort indexc indexf\nreshape wide trAT AThat2, i(indexc) j(indexf)\n\nlocal i=1\nwhile `i'&lt;9{\n    local j=`i'+1\n    while `j'&lt;=9{\n        gen rank`i'`j'=((trAT`i'-trAT`j')*(AThat2`i'-AThat2`j')&gt;0)\n        local j=`j'+1\n    }\n    local i=`i'+1\n}\n\nkeep country indexc rank*\nreshape long rank, i(indexc) j(factor)\negen r1=sum(rank), by(indexc)\ngen r2=r1/36\ncollapse r2,by(indexc country)\nsum r2\nlist\n\nlog close\nexit\nOutput:\n. * This program is to conduct sign test, Rank test and Missing trade test *\n. \n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-2\\sign_rank_1.log, replace\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-2\\sign_rank_1.log\n  log type:  text\n opened on:  19 Jun 2024, 15:29:23\n\n. \n. set mem 30m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory           30M    max. data space                 30.000M\n    set matsize         400     max. RHS vars in models          1.254M\n                                                            -----------\n                                                                33.163M\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\tr\n&gt; efler, clear\n\n. \n. * number of country in the dataset *\n. egen C=max(indexc)\n\n. egen F=max(indexf)\n\n. \n. * Calculate the world level of Yw, Bw and Vw *\n. egen Yww=sum(Y)\n\n. gen Yw=Yww/F\n\n. egen Bww=sum(B)\n\n. gen Bw=Bww/F\n\n. egen Vfw=sum(V), by(indexf)\n\n. \n. * Calculate country share Sc *\n. gen Sc=(Y-B)/(Yw-Bw)\n\n. \n. * Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)*\n. gen Efc=AT-(V-Sc*Vfw)\n\n. \n. * Construct the average epsilon for a given factor *\n. egen total=sum(Efc),by(indexf)\n\n. gen ave=total/C\n\n. \n. * Construct sigma^2 and the weight *\n. \n. egen tot=sum((Efc-ave)^2), by(indexf)\n\n. gen sigma2f=tot/(C-1)\n\n. \n. codebook sigma2f\n\n----------------------------------------------------------------------------------\nsigma2f                                                                (unlabeled)\n----------------------------------------------------------------------------------\n\n                  type:  numeric (float)\n\n                 range:  [98198290,7.112e+22]         units:  10\n         unique values:  9                        missing .:  0/297\n\n            tabulation:  Freq.  Value\n                            33  98198288\n                            33  2.419e+08\n                            33  7.455e+11\n                            33  9.191e+11\n                            33  1.210e+12\n                            33  4.383e+12\n                            33  2.106e+13\n                            33  1.009e+14\n                            33  7.112e+22\n\n. gen sigmaf=sqrt(sigma2f)\n\n. gen weight=sigmaf*sqrt(Sc)\n\n. \n. * Using the weight, convert all the data *\n. \n. gen trAT=AT/(sigmaf*sqrt(Sc))\n\n. gen trV=V/(sigmaf*sqrt(Sc))\n\n. gen trY=Y/sqrt(Sc)\n\n. gen trB=B/sqrt(Sc)\n\n. gen trVfw=Vfw/sigmaf\n\n. \n. gen AThat=trV-Sc*trVfw\n\n. gen AThat2=(V-Sc*Vfw)/weight\n\n. \n. * Correlation, should be .28 *\n. \n. corr trAT AThat2\n(obs=297)\n\n             |     trAT   AThat2\n-------------+------------------\n        trAT |   1.0000\n      AThat2 |   0.2823   1.0000\n\n\n. \n. *************\n. * Sign Test *\n. *************\n. \n. sort indexc\n\n. by indexc: count if trAT*AThat2&gt;0\n\n----------------------------------------------------------------------------------\n-&gt; indexc = 1\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 2\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 3\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 4\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 5\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 6\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 7\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 8\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 9\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 10\n    9\n----------------------------------------------------------------------------------\n-&gt; indexc = 11\n    1\n----------------------------------------------------------------------------------\n-&gt; indexc = 12\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 13\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 14\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 15\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 16\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 17\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 18\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 19\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 20\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 21\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 22\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 23\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 24\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 25\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 26\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 27\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 28\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 29\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 30\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 31\n    8\n----------------------------------------------------------------------------------\n-&gt; indexc = 32\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 33\n    8\n\n. \n. count if trAT*AThat2&gt;0\n  148\n\n. display _result(1)/_N\n.4983165\n\n. \n. *****************\n. * Missing Trade *\n. *****************\n. \n. * Checking for the missing trade, should be .032 *\n. \n. quietly summarize trAT\n\n. local varAT=_result(4)\n\n. quietly summarize AThat\n\n. local varHat=_result(4)\n\n. quietly summarize AThat2\n\n. local varHat2=_result(4)\n\n. display `varAT'/`varHat'\n.03375119\n\n. display `varAT'/`varHat2'\n.031999\n\n. \n. **************\n. * Rank Tests *\n. **************\n. \n. keep country indexc indexf trAT AThat2\n\n. \n. sort indexc indexf\n\n. reshape wide trAT AThat2, i(indexc) j(indexf)\n(note: j = 1 2 3 4 5 6 7 8 9)\n\nData                               long   -&gt;   wide\n-----------------------------------------------------------------------------\nNumber of obs.                      297   -&gt;      33\nNumber of variables                   5   -&gt;      20\nj variable (9 values)            indexf   -&gt;   (dropped)\nxij variables:\n                                   trAT   -&gt;   trAT1 trAT2 ... trAT9\n                                 AThat2   -&gt;   AThat21 AThat22 ... AThat29\n-----------------------------------------------------------------------------\n\n. \n. local i=1\n\n. while `i'&lt;9{\n  2.         local j=`i'+1\n  3.         while `j'&lt;=9{\n  4.                 gen rank`i'`j'=((trAT`i'-trAT`j')*(AThat2`i'-AThat2`j')&gt;0)\n  5.                 local j=`j'+1\n  6.         }\n  7.         local i=`i'+1\n  8. }\n\n. \n. keep country indexc rank*\n\n. reshape long rank, i(indexc) j(factor)\n(note: j = 12 13 14 15 16 17 18 19 23 24 25 26 27 28 29 34 35 36 37 38 39 45 46 47\n&gt;  48 49 56 57 58 59 67 68 69 78 79 89)\n\nData                               wide   -&gt;   long\n-----------------------------------------------------------------------------\nNumber of obs.                       33   -&gt;    1188\nNumber of variables                  38   -&gt;       4\nj variable (36 values)                    -&gt;   factor\nxij variables:\n               rank12 rank13 ... rank89   -&gt;   rank\n-----------------------------------------------------------------------------\n\n. egen r1=sum(rank), by(indexc)\n\n. gen r2=r1/36\n\n. collapse r2,by(indexc country)\n\n. sum r2\n\n    Variable |       Obs        Mean    Std. Dev.       Min        Max\n-------------+--------------------------------------------------------\n          r2 |        33    .6026936    .1721445   .0833333   .9166667\n\n. list\n\n     +----------------------------------+\n     | indexc        country         r2 |\n     |----------------------------------|\n  1. |      1     Bangladesh        .75 |\n  2. |      2       Pakistan   .7222222 |\n  3. |      3      Indonesia   .6666667 |\n  4. |      4      Sri Lanka   .4166667 |\n  5. |      5       Thailand   .6944444 |\n     |----------------------------------|\n  6. |      6       Colombia   .8055556 |\n  7. |      7         Panama   .5555556 |\n  8. |      8     Yugoslavia   .4444444 |\n  9. |      9       Portugal   .5277778 |\n 10. |     10        Uruguay   .7222222 |\n     |----------------------------------|\n 11. |     11         Greece   .4722222 |\n 12. |     12        Ireland   .5277778 |\n 13. |     13          Spain   .3888889 |\n 14. |     14         Israel   .3888889 |\n 15. |     15      Hong Kong   .8333333 |\n     |----------------------------------|\n 16. |     16    New Zealand   .5277778 |\n 17. |     17        Austria   .5277778 |\n 18. |     18      Singapore   .6111111 |\n 19. |     19          Italy   .7777778 |\n 20. |     20             UK   .5833333 |\n     |----------------------------------|\n 21. |     21          Japan   .7777778 |\n 22. |     22        Belgium   .6111111 |\n 23. |     23       Trinidad         .5 |\n 24. |     24    Netherlands   .5277778 |\n 25. |     25        Finland   .4722222 |\n     |----------------------------------|\n 26. |     26        Denmark   .5277778 |\n 27. |     27   West Germany   .8055556 |\n 28. |     28         France   .0833333 |\n 29. |     29         Sweden   .6666667 |\n 30. |     30         Norway   .6111111 |\n     |----------------------------------|\n 31. |     31    Switzerland   .5555556 |\n 32. |     32         Canada   .8888889 |\n 33. |     33            USA   .9166667 |\n     +----------------------------------+\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-2\\sign_rank_1.log\n  log type:  text\n closed on:  19 Jun 2024, 15:29:31\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\nMy code\n\n# Transform ----\n\ntrefler &lt;- readRDS(fout) %&gt;%\n  # Number of country in the dataset\n  mutate(\n    c = max(indexc),\n    f = max(indexf)\n  ) %&gt;%\n  # Calculate the world level of Yw, Bw and Vw\n  mutate(\n    yww = sum(y),\n    yw = yww / f,\n    bww = sum(b),\n    bw = bww / f\n  ) %&gt;%\n  group_by(indexf) %&gt;%\n  mutate(\n    vfw = sum(v)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Calculate country share Sc\n  mutate(\n    sc = (y - b) / (yw - bw)\n  ) %&gt;%\n  # Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\n  mutate(\n    efc = at - (v - sc * vfw)\n  ) %&gt;%\n  # Construct the average epsilon for a given factor\n  group_by(indexf) %&gt;%\n  mutate(ave = sum(efc) / c) %&gt;%\n  # Construct sigma^2 and the weight\n  mutate(\n    sigma2f = sum((efc - ave)^2) / (c - 1),\n    sigmaf = sqrt(sigma2f),\n    weight = sigmaf * sqrt(sc)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Using the weight, convert all the data\n  mutate(\n    trat = at / (sigmaf * sqrt(sc)),\n    athat2 = (v - (sc * vfw)) / weight\n  ) %&gt;%\n  arrange(country)\n\n# Correlation, should be .28\ntrefler %&gt;%\n  select(trat, athat2) %&gt;%\n  cor()\n\n            trat    athat2\ntrat   1.0000000 0.2822883\nathat2 0.2822883 1.0000000\n\n# Sign Test ----\n\ntrefler %&gt;%\n  group_by(country, indexc) %&gt;%\n  summarize(\n    p = sum(trat * athat2 &gt; 0) / n()\n  )\n\n# A tibble: 33 × 3\n# Groups:   country [33]\n   country    indexc     p\n   &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;\n 1 Austria        17 0.556\n 2 Bangladesh      1 0.333\n 3 Belgium        22 0.667\n 4 Canada         32 0.556\n 5 Colombia        6 0.333\n 6 Denmark        26 0.444\n 7 Finland        25 0.333\n 8 France         28 0.333\n 9 Greece         11 0.111\n10 Hong Kong      15 0.667\n# ℹ 23 more rows\n\ntrefler %&gt;%\n  summarize(\n    p = sum(trat * athat2 &gt; 0) / n()\n  )\n\n# A tibble: 1 × 1\n      p\n  &lt;dbl&gt;\n1 0.498\n\n# Missing Trade ----\n\n# Checking for the missing trade, should be .032\n\ntrefler %&gt;%\n  summarize(\n    varat = var(trat),\n    varhat2 = var(athat2)\n  ) %&gt;%\n  mutate(\n    varat_varhat2 = varat / varhat2\n  )\n\n# A tibble: 1 × 3\n  varat varhat2 varat_varhat2\n  &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1  1.61    50.3        0.0320\n\n# Rank Tests ----\n\ntrefler_wide &lt;- trefler %&gt;%\n  select(country, indexc, indexf, trat, athat2) %&gt;%\n  arrange(indexc, indexf) %&gt;%\n  pivot_wider(\n    names_from = indexf,\n    values_from = c(trat, athat2)\n  )\n\n# This would be too long\n# trefler_wide &lt;- trefler_wide %&gt;%\n#   mutate(\n#     rank12 = (trat_1 - trat_2) * (athat2_1 - athat2_2) &gt; 0,\n#     rank13 = (trat_1 - trat_3) * (athat2_1 - athat2_3) &gt; 0,\n#     ...\n#     rank89 = (trat_8 - trat_9) * (athat2_8 - athat2_9) &gt; 0,\n#   )\n\n# create all relevant trat_1 - trat_2, trat_1 - trat_3, etc.\n\nranks &lt;- expand_grid(\n  x = 1:8,\n  y = 1:9\n) %&gt;%\n  filter(x &lt; y)\n\n# The syntax here is based on internal R developer functions, but these\n# allow to create columns with minimal lines of code and avoids more complicated\n# bracket syntax\ntrefler_rank &lt;- map2_df(\n  pull(ranks, x),\n  pull(ranks, y),\n  function(x, y) {\n    trefler_wide %&gt;%\n      mutate(\n        name = paste0(\"rank\", x, y),\n        value = (!!sym(paste0(\"trat_\", x)) - !!sym(paste0(\"trat_\", y))) *\n          (!!sym(paste0(\"athat2_\", x)) - !!sym(paste0(\"athat2_\", y))) &gt; 0\n      ) %&gt;%\n      select(country, indexc, name, value)\n  }\n) %&gt;%\n  group_by(country, indexc) %&gt;%\n  summarise(r1 = sum(value)) %&gt;%\n  mutate(r2 = r1 / 36)\n\ntrefler_rank\n\n# A tibble: 33 × 4\n# Groups:   country [33]\n   country    indexc    r1     r2\n   &lt;chr&gt;       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n 1 Austria        17    19 0.528 \n 2 Bangladesh      1    27 0.75  \n 3 Belgium        22    22 0.611 \n 4 Canada         32    32 0.889 \n 5 Colombia        6    29 0.806 \n 6 Denmark        26    19 0.528 \n 7 Finland        25    17 0.472 \n 8 France         28     3 0.0833\n 9 Greece         11    17 0.472 \n10 Hong Kong      15    30 0.833 \n# ℹ 23 more rows\n\ntrefler_rank %&gt;%\n  pull(r2) %&gt;%\n  mean()\n\n[1] 0.6026936\n\n\n\n\nExtra step: formatting the table\n\ntrefler %&gt;%\n  group_by(country, indexc) %&gt;%\n  summarize(\n    p = sum(trat * athat2 &gt; 0) / n()\n  ) %&gt;%\n  arrange(indexc) %&gt;% # same order as in the book\n  select(country, sign_hov = p) %&gt;%\n  left_join(\n    trefler_rank %&gt;%\n      select(country, rank_hov = r2)\n  ) %&gt;%\n  bind_rows(\n    trefler %&gt;%\n      summarize(\n        p = sum(trat * athat2 &gt; 0) / n()\n      ) %&gt;%\n      mutate(\n        country = \"All countries\",\n        rank_hov = mean(pull(trefler_rank, r2))\n      ) %&gt;%\n      select(country, sign_hov = p, rank_hov)\n  ) %&gt;%\n  mutate_if(is.numeric, round, 2) %&gt;% # same no of decimals as in the book\n  kable()\n\n\n\n\ncountry\nsign_hov\nrank_hov\n\n\n\n\nBangladesh\n0.33\n0.75\n\n\nPakistan\n0.33\n0.72\n\n\nIndonesia\n0.22\n0.67\n\n\nSri Lanka\n0.22\n0.42\n\n\nThailand\n0.22\n0.69\n\n\nColombia\n0.33\n0.81\n\n\nPanama\n0.33\n0.56\n\n\nYugoslavia\n0.56\n0.44\n\n\nPortugal\n0.22\n0.53\n\n\nUruguay\n1.00\n0.72\n\n\nGreece\n0.11\n0.47\n\n\nIreland\n0.67\n0.53\n\n\nSpain\n0.22\n0.39\n\n\nIsrael\n0.67\n0.39\n\n\nHong Kong\n0.67\n0.83\n\n\nNew Zealand\n0.44\n0.53\n\n\nAustria\n0.56\n0.53\n\n\nSingapore\n0.56\n0.61\n\n\nItaly\n0.67\n0.78\n\n\nUK\n0.67\n0.58\n\n\nJapan\n0.78\n0.78\n\n\nBelgium\n0.67\n0.61\n\n\nTrinidad\n0.67\n0.50\n\n\nNetherlands\n0.44\n0.53\n\n\nFinland\n0.33\n0.47\n\n\nDenmark\n0.44\n0.53\n\n\nWest Germany\n0.56\n0.81\n\n\nFrance\n0.33\n0.08\n\n\nSweden\n0.44\n0.67\n\n\nNorway\n0.44\n0.61\n\n\nSwitzerland\n0.89\n0.56\n\n\nCanada\n0.56\n0.89\n\n\nUSA\n0.89\n0.92\n\n\nAll countries\n0.50\n0.60"
  },
  {
    "objectID": "chapter2.html#exercise-2",
    "href": "chapter2.html#exercise-2",
    "title": "Chapter 2. The Heckscher-Ohlin Model",
    "section": "Exercise 2",
    "text": "Exercise 2\nGiven uniform technological differences across countries, run the program sign_rank_2.do to redo the sign test, rank test, and missing trade. Use the results in sign_rank_2.log to replicate column (3) and (5), given column (6) in Table 2.5.\n\nFeenstra’s code\n* This program is to conduct sign test, Rank test and Missing trade test *\n* using delta *\n\ncapture log close\n* log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\sign_rank_2.log, replace *\nlog using \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\sign_rank_2.log\", replace\n\nset mem 30m\n\n* use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler, clear *\nuse \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler\", clear\n\n* number of country in the dataset *\negen C=max(indexc)\negen F=max(indexf)\n\n* Calculate the world level of Yw, Bw and Vw *\negen Yww=sum(Y)\ngen Yw=Yww/F\negen Bww=sum(B)\ngen Bw=Bww/F\negen Vfw=sum(V), by(indexf)\negen Vw=sum(delta*V), by(indexf)\n\n* Calculate country share Sc *\ngen Sc=(Y-B)/(Yw-Bw)\n\n* Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\n\ngen Efc=delta*AT-(delta*V-Sc*Vw)\n\n* Construct the average epsilon for a given factor *\negen total=sum(Efc),by(indexf)\ngen ave=total/C\n\n* Construct sigma^2 and the weight *\n\negen tot=sum((Efc-ave)^2), by(indexf)\ngen sigma2f=tot/(C-1)\n\ncodebook sigma2f\ngen sigmaf=sqrt(sigma2f)\ngen weight=sigmaf*sqrt(Sc)\n\n* Using the weight, convert all the data *\n\ngen trAT=delta*AT/weight\ngen AThat2=(delta*V-Sc*Vw)/weight\n\n* Correlation *\n\ncorr trAT AThat2\n\n*************\n* Sign Test *\n*************\n\nsort indexc\nby indexc: count if trAT*AThat2&gt;0\n\ncount if trAT*AThat2&gt;0\ndisplay _result(1)/_N\n\n*****************\n* Missing Trade *\n*****************\n\nquietly summarize trAT\nlocal varAT=_result(4)\nquietly summarize AThat\nlocal varHat=_result(4)\nquietly summarize AThat2\nlocal varHat2=_result(4)\ndisplay `varAT'/`varHat'\ndisplay `varAT'/`varHat2'\n\n*************\n* Rank Test *\n*************\n\nkeep country indexc indexf trAT AThat2\n\nsort indexc indexf\nreshape wide trAT AThat2, i(indexc) j(indexf)\n\nlocal i=1\nwhile `i'&lt;9{\n    local j=`i'+1\n    while `j'&lt;=9{\n        gen rank`i'`j'=((trAT`i'-trAT`j')*(AThat2`i'-AThat2`j')&gt;0)\n        local j=`j'+1\n    }\n    local i=`i'+1\n}\n\nkeep country indexc rank*\nreshape long rank, i(indexc) j(factor)\negen r1=sum(rank), by(indexc)\ngen r2=r1/36\ncollapse r2,by(indexc country)\nsum r2\nlist\n\nlog close\nexit\nOutput:\n. * This program is to conduct sign test, Rank test and Missing trade test *\n. * using delta *\n. \n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-2\\sign_rank_2.log, replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-2\\sign_rank_2.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-2\\sign_rank_2.log\n  log type:  text\n opened on:  19 Jun 2024, 15:30:38\n\n. \n. set mem 30m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory           30M    max. data space                 30.000M\n    set matsize         400     max. RHS vars in models          1.254M\n                                                            -----------\n                                                                33.163M\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\tr\n&gt; efler, clear\n\n. \n. * number of country in the dataset *\n. egen C=max(indexc)\n\n. egen F=max(indexf)\n\n. \n. * Calculate the world level of Yw, Bw and Vw *\n. egen Yww=sum(Y)\n\n. gen Yw=Yww/F\n\n. egen Bww=sum(B)\n\n. gen Bw=Bww/F\n\n. egen Vfw=sum(V), by(indexf)\n\n. egen Vw=sum(delta*V), by(indexf)\n\n. \n. * Calculate country share Sc *\n. gen Sc=(Y-B)/(Yw-Bw)\n\n. \n. * Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\n. \n. gen Efc=delta*AT-(delta*V-Sc*Vw)\n\n. \n. * Construct the average epsilon for a given factor *\n. egen total=sum(Efc),by(indexf)\n\n. gen ave=total/C\n\n. \n. * Construct sigma^2 and the weight *\n. \n. egen tot=sum((Efc-ave)^2), by(indexf)\n\n. gen sigma2f=tot/(C-1)\n\n. \n. codebook sigma2f\n\n----------------------------------------------------------------------------------\nsigma2f                                                                (unlabeled)\n----------------------------------------------------------------------------------\n\n                  type:  numeric (float)\n\n                 range:  [51579730,3.418e+21]         units:  10\n         unique values:  9                        missing .:  0/297\n\n            tabulation:  Freq.  Value\n                            33  51579728\n                            33  3.926e+08\n                            33  6.172e+10\n                            33  1.211e+11\n                            33  1.883e+11\n                            33  2.320e+11\n                            33  2.662e+11\n                            33  2.113e+12\n                            33  3.418e+21\n\n. gen sigmaf=sqrt(sigma2f)\n\n. gen weight=sigmaf*sqrt(Sc)\n\n. \n. * Using the weight, convert all the data *\n. \n. gen trAT=delta*AT/weight\n\n. gen AThat2=(delta*V-Sc*Vw)/weight\n\n. \n. * Correlation *\n. \n. corr trAT AThat2\n(obs=297)\n\n             |     trAT   AThat2\n-------------+------------------\n        trAT |   1.0000\n      AThat2 |   0.4100   1.0000\n\n\n. \n. *************\n. * Sign Test *\n. *************\n. \n. sort indexc\n\n. by indexc: count if trAT*AThat2&gt;0\n\n----------------------------------------------------------------------------------\n-&gt; indexc = 1\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 2\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 3\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 4\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 5\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 6\n    8\n----------------------------------------------------------------------------------\n-&gt; indexc = 7\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 8\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 9\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 10\n    1\n----------------------------------------------------------------------------------\n-&gt; indexc = 11\n    5\n----------------------------------------------------------------------------------\n-&gt; indexc = 12\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 13\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 14\n    8\n----------------------------------------------------------------------------------\n-&gt; indexc = 15\n    8\n----------------------------------------------------------------------------------\n-&gt; indexc = 16\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 17\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 18\n    9\n----------------------------------------------------------------------------------\n-&gt; indexc = 19\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 20\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 21\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 22\n    7\n----------------------------------------------------------------------------------\n-&gt; indexc = 23\n    9\n----------------------------------------------------------------------------------\n-&gt; indexc = 24\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 25\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 26\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 27\n    6\n----------------------------------------------------------------------------------\n-&gt; indexc = 28\n    3\n----------------------------------------------------------------------------------\n-&gt; indexc = 29\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 30\n    4\n----------------------------------------------------------------------------------\n-&gt; indexc = 31\n    8\n----------------------------------------------------------------------------------\n-&gt; indexc = 32\n    2\n----------------------------------------------------------------------------------\n-&gt; indexc = 33\n    5\n\n. \n. count if trAT*AThat2&gt;0\n  184\n\n. display _result(1)/_N\n.61952862\n\n. \n. *****************\n. * Missing Trade *\n. *****************\n. \n. quietly summarize trAT\n\n. local varAT=_result(4)\n\n. quietly summarize AThat\n\n. local varHat=_result(4)\n\n. quietly summarize AThat2\n\n. local varHat2=_result(4)\n\n. display `varAT'/`varHat'\n.07061819\n\n. display `varAT'/`varHat2'\n.07061819\n\n. \n. *************\n. * Rank Test *\n. *************\n. \n. keep country indexc indexf trAT AThat2\n\n. \n. sort indexc indexf\n\n. reshape wide trAT AThat2, i(indexc) j(indexf)\n(note: j = 1 2 3 4 5 6 7 8 9)\n\nData                               long   -&gt;   wide\n-----------------------------------------------------------------------------\nNumber of obs.                      297   -&gt;      33\nNumber of variables                   5   -&gt;      20\nj variable (9 values)            indexf   -&gt;   (dropped)\nxij variables:\n                                   trAT   -&gt;   trAT1 trAT2 ... trAT9\n                                 AThat2   -&gt;   AThat21 AThat22 ... AThat29\n-----------------------------------------------------------------------------\n\n. \n. local i=1\n\n. while `i'&lt;9{\n  2.         local j=`i'+1\n  3.         while `j'&lt;=9{\n  4.                 gen rank`i'`j'=((trAT`i'-trAT`j')*(AThat2`i'-AThat2`j')&gt;0)\n  5.                 local j=`j'+1\n  6.         }\n  7.         local i=`i'+1\n  8. }\n\n. \n. keep country indexc rank*\n\n. reshape long rank, i(indexc) j(factor)\n(note: j = 12 13 14 15 16 17 18 19 23 24 25 26 27 28 29 34 35 36 37 38 39 45 46 47\n&gt;  48 49 56 57 58 59 67 68 69 78 79 89)\n\nData                               wide   -&gt;   long\n-----------------------------------------------------------------------------\nNumber of obs.                       33   -&gt;    1188\nNumber of variables                  38   -&gt;       4\nj variable (36 values)                    -&gt;   factor\nxij variables:\n               rank12 rank13 ... rank89   -&gt;   rank\n-----------------------------------------------------------------------------\n\n. egen r1=sum(rank), by(indexc)\n\n. gen r2=r1/36\n\n. collapse r2,by(indexc country)\n\n. sum r2\n\n    Variable |       Obs        Mean    Std. Dev.       Min        Max\n-------------+--------------------------------------------------------\n          r2 |        33    .6153199    .1508913   .1944444   .8611111\n\n. list\n\n     +----------------------------------+\n     | indexc        country         r2 |\n     |----------------------------------|\n  1. |      1     Bangladesh   .7777778 |\n  2. |      2       Pakistan   .7777778 |\n  3. |      3      Indonesia   .6666667 |\n  4. |      4      Sri Lanka   .6666667 |\n  5. |      5       Thailand   .7222222 |\n     |----------------------------------|\n  6. |      6       Colombia   .8611111 |\n  7. |      7         Panama   .7777778 |\n  8. |      8     Yugoslavia   .6111111 |\n  9. |      9       Portugal   .5833333 |\n 10. |     10        Uruguay   .5277778 |\n     |----------------------------------|\n 11. |     11         Greece        .75 |\n 12. |     12        Ireland   .3888889 |\n 13. |     13          Spain   .6944444 |\n 14. |     14         Israel   .6944444 |\n 15. |     15      Hong Kong   .7222222 |\n     |----------------------------------|\n 16. |     16    New Zealand   .6111111 |\n 17. |     17        Austria   .4444444 |\n 18. |     18      Singapore   .6111111 |\n 19. |     19          Italy   .6666667 |\n 20. |     20             UK   .6388889 |\n     |----------------------------------|\n 21. |     21          Japan   .7777778 |\n 22. |     22        Belgium   .5277778 |\n 23. |     23       Trinidad   .5277778 |\n 24. |     24    Netherlands   .4722222 |\n 25. |     25        Finland         .5 |\n     |----------------------------------|\n 26. |     26        Denmark   .4166667 |\n 27. |     27   West Germany   .7777778 |\n 28. |     28         France   .1944444 |\n 29. |     29         Sweden   .3611111 |\n 30. |     30         Norway   .7777778 |\n     |----------------------------------|\n 31. |     31    Switzerland         .5 |\n 32. |     32         Canada   .5555556 |\n 33. |     33            USA   .7222222 |\n     +----------------------------------+\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-2\\sign_rank_2.log\n  log type:  text\n closed on:  19 Jun 2024, 15:30:44\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\nMy code\n\n# Transform ----\n\ntrefler &lt;- readRDS(fout) %&gt;%\n  # Number of country in the dataset\n  mutate(\n    c = max(indexc),\n    f = max(indexf)\n  ) %&gt;%\n  # Calculate the world level of Yw, Bw and Vw\n  mutate(\n    yww = sum(y),\n    yw = yww / f,\n    bww = sum(b),\n    bw = bww / f\n  ) %&gt;%\n  group_by(indexf) %&gt;%\n  mutate(\n    vfw = sum(v),\n    vw = sum(delta * v)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Calculate country share Sc\n  mutate(\n    sc = (y - b) / (yw - bw)\n  ) %&gt;%\n  # Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\n  mutate(\n    efc = delta * at - (delta * v - sc * vw)\n  ) %&gt;%\n  # Construct the average epsilon for a given factor\n  group_by(indexf) %&gt;%\n  mutate(ave = sum(efc) / c) %&gt;%\n  # Construct sigma^2 and the weight\n  mutate(\n    sigma2f = sum((efc - ave)^2) / (c - 1),\n    sigmaf = sqrt(sigma2f),\n    weight = sigmaf * sqrt(sc)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Using the weight, convert all the data\n  mutate(\n    trat = delta * at / weight,\n    athat2 = (delta * v - (sc * vw)) / weight\n  )\n\n# Correlation should be .41\ntrefler %&gt;%\n  select(trat, athat2) %&gt;%\n  cor()\n\n            trat    athat2\ntrat   1.0000000 0.4099617\nathat2 0.4099617 1.0000000\n\n# Sign Test ----\n\ntrefler %&gt;%\n  group_by(country, indexc) %&gt;%\n  summarize(\n    p = sum(trat * athat2 &gt; 0) / n()\n  )\n\n# A tibble: 33 × 3\n# Groups:   country [33]\n   country    indexc     p\n   &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;\n 1 Austria        17 0.667\n 2 Bangladesh      1 0.778\n 3 Belgium        22 0.778\n 4 Canada         32 0.222\n 5 Colombia        6 0.889\n 6 Denmark        26 0.444\n 7 Finland        25 0.444\n 8 France         28 0.333\n 9 Greece         11 0.556\n10 Hong Kong      15 0.889\n# ℹ 23 more rows\n\ntrefler %&gt;%\n  summarize(\n    p = sum(trat * athat2 &gt; 0) / n()\n  )\n\n# A tibble: 1 × 1\n      p\n  &lt;dbl&gt;\n1 0.620\n\n# Missing Trade ----\n\n# Checking for the missing trade, should be .07\n\ntrefler %&gt;%\n  summarize(\n    varat = var(trat),\n    varhat2 = var(athat2)\n  ) %&gt;%\n  mutate(\n    varat_varhat2 = varat / varhat2\n  )\n\n# A tibble: 1 × 3\n  varat varhat2 varat_varhat2\n  &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1  1.34    19.0        0.0706\n\n# Rank Tests ----\n\ntrefler_wide &lt;- trefler %&gt;%\n  select(country, indexc, indexf, trat, athat2) %&gt;%\n  arrange(indexc, indexf) %&gt;%\n  pivot_wider(\n    names_from = indexf,\n    values_from = c(trat, athat2)\n  )\n\nranks &lt;- expand_grid(\n  x = 1:8,\n  y = 1:9\n) %&gt;%\n  filter(x &lt; y)\n\ntrefler_rank &lt;- map2_df(\n  pull(ranks, x),\n  pull(ranks, y),\n  function(x, y) {\n    trefler_wide %&gt;%\n      mutate(\n        name = paste0(\"rank\", x, y),\n        value = (!!sym(paste0(\"trat_\", x)) - !!sym(paste0(\"trat_\", y))) *\n          (!!sym(paste0(\"athat2_\", x)) - !!sym(paste0(\"athat2_\", y))) &gt; 0\n      ) %&gt;%\n      select(country, indexc, name, value)\n  }\n) %&gt;%\n  group_by(country, indexc) %&gt;%\n  summarise(r1 = sum(value)) %&gt;%\n  mutate(r2 = r1 / 36)\n\ntrefler_rank\n\n# A tibble: 33 × 4\n# Groups:   country [33]\n   country    indexc    r1    r2\n   &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1 Austria        17    16 0.444\n 2 Bangladesh      1    28 0.778\n 3 Belgium        22    19 0.528\n 4 Canada         32    20 0.556\n 5 Colombia        6    31 0.861\n 6 Denmark        26    15 0.417\n 7 Finland        25    18 0.5  \n 8 France         28     7 0.194\n 9 Greece         11    27 0.75 \n10 Hong Kong      15    26 0.722\n# ℹ 23 more rows\n\ntrefler_rank %&gt;%\n  pull(r2) %&gt;%\n  mean()\n\n[1] 0.6153199\n\n\n\n\nExtra step: formatting the table\n\ntrefler %&gt;%\n  group_by(country, indexc) %&gt;%\n  summarize(\n    p = sum(trat * athat2 &gt; 0) / n()\n  ) %&gt;%\n  arrange(indexc) %&gt;% # same order as in the book\n  select(country, sign_hov = p) %&gt;%\n  left_join(\n    trefler_rank %&gt;%\n      select(country, rank_hov = r2)\n  ) %&gt;%\n  bind_rows(\n    trefler %&gt;%\n      summarize(\n        p = sum(trat * athat2 &gt; 0) / n()\n      ) %&gt;%\n      mutate(\n        country = \"All countries\",\n        rank_hov = mean(pull(trefler_rank, r2))\n      ) %&gt;%\n      select(country, sign_hov = p, rank_hov)\n  ) %&gt;%\n  mutate_if(is.numeric, round, 2) %&gt;% # same no of decimals as in the book\n  kable()\n\n\n\n\ncountry\nsign_hov\nrank_hov\n\n\n\n\nBangladesh\n0.78\n0.78\n\n\nPakistan\n0.67\n0.78\n\n\nIndonesia\n0.67\n0.67\n\n\nSri Lanka\n0.56\n0.67\n\n\nThailand\n0.67\n0.72\n\n\nColombia\n0.89\n0.86\n\n\nPanama\n0.78\n0.78\n\n\nYugoslavia\n0.67\n0.61\n\n\nPortugal\n0.78\n0.58\n\n\nUruguay\n0.11\n0.53\n\n\nGreece\n0.56\n0.75\n\n\nIreland\n0.44\n0.39\n\n\nSpain\n0.78\n0.69\n\n\nIsrael\n0.89\n0.69\n\n\nHong Kong\n0.89\n0.72\n\n\nNew Zealand\n0.22\n0.61\n\n\nAustria\n0.67\n0.44\n\n\nSingapore\n1.00\n0.61\n\n\nItaly\n0.33\n0.67\n\n\nUK\n0.78\n0.64\n\n\nJapan\n0.67\n0.78\n\n\nBelgium\n0.78\n0.53\n\n\nTrinidad\n1.00\n0.53\n\n\nNetherlands\n0.44\n0.47\n\n\nFinland\n0.44\n0.50\n\n\nDenmark\n0.44\n0.42\n\n\nWest Germany\n0.67\n0.78\n\n\nFrance\n0.33\n0.19\n\n\nSweden\n0.44\n0.36\n\n\nNorway\n0.44\n0.78\n\n\nSwitzerland\n0.89\n0.50\n\n\nCanada\n0.22\n0.56\n\n\nUSA\n0.56\n0.72\n\n\nAll countries\n0.62\n0.62\n\n\n\n\n\n\n\nNotes\nThe Stata code that I run returns the same values as R. However:\n\nAustria should have values 0.67 and 0.47. I got 0.67 and 0.44.\nFrance should have values 0.33 and 0.22. I got 0.33 and 0.19.\nSwitzerland should have values 0.89 and 0.47. I got 0.89 and 0.50."
  },
  {
    "objectID": "chapter2.html#exercise-3",
    "href": "chapter2.html#exercise-3",
    "title": "Chapter 2. The Heckscher-Ohlin Model",
    "section": "Exercise 3",
    "text": "Exercise 3\nAllowing all factors in each country to have different productivities, now run the program compute_pi.do to compute factor productivities \\(\\pi_k^i\\) as Trefler (1993). Note that there are 9 factors in the original data set, but these are now aggregated to just 4 factors, which are labor (endowment 1), capital (endowment 2), cropland (endowment 3) and pasture (endowment 4). Using the results in pi_.log or alternatively in the data files pi_1.dta, pi_2.dta, pi_3.dta, pi_4.dta to answer the following:\n\nWhich factor has the most negative productivities estimated?\nWhat is the correlation between the estimated labor productivity and the productivities of other factors? What is the correlation between each factor productivity and GDP per-capita (which you can find in the file trefler.dta)?\n\n\nFeenstra’s code\n* This program is to compute pai, the factor productivity *\n\ncapture log close\n* log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi.log,replace *\nlog using \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi.log\", replace\n\nset mem 30m\n\n* use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler, clear *\nuse \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\trefler\", clear\n\n* number of country in the dataset *\negen C=max(indexc)\negen F=max(indexf)\n\n* Calculate the world level of Yw, Bw and Vw *\negen Yww=sum(Y)\ngen Yw=Yww/F\negen Bww=sum(B)\ngen Bw=Bww/F\negen Vfw=sum(V), by(indexf)\n\n* Calculate country share Sc *\ngen Sc=(Y-B)/(Yw-Bw)\n\n* Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\ngen Efc=AT-(V-Sc*Vfw)\n\n* Construct the average epsilon for a given factor *\negen total=sum(Efc),by(indexf)\ngen ave=total/C\n\n* Construct sigma^2 and the weight *\n\negen tot=sum((Efc-ave)^2), by(indexf)\ngen sigma2f=tot/(C-1)\n\ncodebook sigma2f\ngen sigmaf=sqrt(sigma2f)\ngen weight=sigmaf*sqrt(Sc)\n\n* Using the weight, convert all the data *\n\ngen trAT=AT/(sigmaf*sqrt(Sc))\ngen trV=V/(sigmaf*sqrt(Sc))\ngen trY=Y/sqrt(Sc)\ngen trB=B/sqrt(Sc)\ngen trVfw=Vfw/sigmaf\n\ngen AThat=trV-Sc*trVfw\ngen AThat2=(V-Sc*Vfw)/weight\n\n* Construct Aggregate Labor Endowment *\n\npreserve\nkeep if indexf==7 |indexf==8 | indexf==9\ngen en=2\nreplace en=3 if indexf==8\nreplace en=4 if indexf==9\nkeep country factor AT V en indexc Sc\n\n* save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_189,replace *\nsave \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_189\", replace\n\nrestore\n\npreserve\ndrop if indexf==7 |indexf==8 | indexf==9\n\negen v_l=sum(V), by(country)\negen AT_l=sum(AT), by(country)\n\ndrop V AT factor\nrename v_l V\nrename AT_l AT\ngen en=1\ncollapse (mean)AT V en indexc Sc, by(country)\ngen str5 factor=\"Labor\"\n* save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_L,replace *\nsave \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_L\", replace\n\nrestore\n\n* use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_189,clear *\nuse \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_189\", clear\n\n* append using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_L *\nappend using \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\indexf_L\"\nsort indexc en\n* save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi,replace *\nsave \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi\", replace\n\n************************************\n* Compute Pi: factor productivity *\n************************************\n\n* use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi, clear *\nuse \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi\", clear\n\ngen p_0=1\ngen p_1=1\n\nlocal i=1\nwhile `i'&lt;=4{\n    preserve\n    keep if en==`i'\n    local j=1\n    while `j'&lt;51{\n        replace p_0=p_1\n        gen Vp=p_0*V\n        egen Vpw=sum(Vp)\n        replace p_1=(AT+Sc*Vpw)/V\n        replace p_1=1 if country==\"USA\"\n        drop Vp Vpw\n        local j=`j'+1\n    }\n    keep en country indexc p_1\n    * save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_`i',replace *\n  save \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_`i'\", replace\n    restore\n    local i=`i'+1\n}\n\nlocal i=1\nwhile `i'&lt;=4{\n    * use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_`i',clear *\n  use \"Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_`i'\", clear\n    sort en indexc\n    by en: list en indexc country p_1\n    local i=`i'+1\n}\n\nlog close\n\nexit\nOutput:\n. * This program is to compute pai, the factor productivity *\n. \n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-2\\pi.log,replace\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-2\\pi.log\n  log type:  text\n opened on:  19 Jun 2024, 15:32:25\n\n. \n. set mem 30m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory           30M    max. data space                 30.000M\n    set matsize         400     max. RHS vars in models          1.254M\n                                                            -----------\n                                                                33.163M\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\tr\n&gt; efler, clear\n\n. \n. * number of country in the dataset *\n. egen C=max(indexc)\n\n. egen F=max(indexf)\n\n. \n. * Calculate the world level of Yw, Bw and Vw *\n. egen Yww=sum(Y)\n\n. gen Yw=Yww/F\n\n. egen Bww=sum(B)\n\n. gen Bw=Bww/F\n\n. egen Vfw=sum(V), by(indexf)\n\n. \n. * Calculate country share Sc *\n. gen Sc=(Y-B)/(Yw-Bw)\n\n. \n. * Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\n. gen Efc=AT-(V-Sc*Vfw)\n\n. \n. * Construct the average epsilon for a given factor *\n. egen total=sum(Efc),by(indexf)\n\n. gen ave=total/C\n\n. \n. * Construct sigma^2 and the weight *\n. \n. egen tot=sum((Efc-ave)^2), by(indexf)\n\n. gen sigma2f=tot/(C-1)\n\n. \n. codebook sigma2f\n\n----------------------------------------------------------------------------------\nsigma2f                                                                (unlabeled)\n----------------------------------------------------------------------------------\n\n                  type:  numeric (float)\n\n                 range:  [98198290,7.112e+22]         units:  10\n         unique values:  9                        missing .:  0/297\n\n            tabulation:  Freq.  Value\n                            33  98198288\n                            33  2.419e+08\n                            33  7.455e+11\n                            33  9.191e+11\n                            33  1.210e+12\n                            33  4.383e+12\n                            33  2.106e+13\n                            33  1.009e+14\n                            33  7.112e+22\n\n. gen sigmaf=sqrt(sigma2f)\n\n. gen weight=sigmaf*sqrt(Sc)\n\n. \n. * Using the weight, convert all the data *\n. \n. gen trAT=AT/(sigmaf*sqrt(Sc))\n\n. gen trV=V/(sigmaf*sqrt(Sc))\n\n. gen trY=Y/sqrt(Sc)\n\n. gen trB=B/sqrt(Sc)\n\n. gen trVfw=Vfw/sigmaf\n\n. \n. gen AThat=trV-Sc*trVfw\n\n. gen AThat2=(V-Sc*Vfw)/weight\n\n. \n. * Construct Aggregate Labor Endowment *\n. \n. preserve\n\n. keep if indexf==7 |indexf==8 | indexf==9\n(198 observations deleted)\n\n. gen en=2\n\n. replace en=3 if indexf==8\n(33 real changes made)\n\n. replace en=4 if indexf==9\n(33 real changes made)\n\n. keep country factor AT V en indexc Sc\n\n. \n. save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\i\n&gt; ndexf_189,replace\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\ind\n&gt; exf_189.dta saved\n\n. \n. restore\n\n. \n. preserve\n\n. drop if indexf==7 |indexf==8 | indexf==9\n(99 observations deleted)\n\n. \n. egen v_l=sum(V), by(country)\n\n. egen AT_l=sum(AT), by(country)\n\n. \n. drop V AT factor\n\n. rename v_l V\n\n. rename AT_l AT\n\n. gen en=1\n\n. collapse (mean)AT V en indexc Sc, by(country)\n\n. gen str5 factor=\"Labor\"\n\n. save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\i\n&gt; ndexf_L,replace\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\ind\n&gt; exf_L.dta saved\n\n. \n. restore\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\in\n&gt; dexf_189,clear\n\n. append using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Cha\n&gt; pter-2\\indexf_L\nindexc was byte now float\n\n. sort indexc en\n\n. save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\p\n&gt; i,replace\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi.\n&gt; dta saved\n\n. \n. ************************************\n. * Compute Pi: factor productivity *\n. ************************************\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi\n&gt; , clear\n\n. \n. gen p_0=1\n\n. gen p_1=1\n\n. \n. local i=1\n\n. while `i'&lt;=4{\n  2.         preserve\n  3.         keep if en==`i'\n  4.         local j=1\n  5.         while `j'&lt;51{\n  6.                 replace p_0=p_1\n  7.                 gen Vp=p_0*V\n  8.                 egen Vpw=sum(Vp)\n  9.                 replace p_1=(AT+Sc*Vpw)/V\n 10.                 replace p_1=1 if country==\"USA\"\n 11.                 drop Vp Vpw\n 12.                 local j=`j'+1\n 13.         }\n 14.         keep en country indexc p_1\n 15.         save Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\\n&gt; Chapter-2\\pi_`i',replace\n 16.         restore\n 17.         local i=`i'+1\n 18. }\n(99 observations deleted)\n(0 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(30 real changes made)\n(1 real change made)\n(29 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_\n&gt; 1.dta saved\n(99 observations deleted)\n(0 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_\n&gt; 2.dta saved\n(99 observations deleted)\n(0 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(32 real changes made)\n(1 real change made)\n(31 real changes made)\n(31 real changes made)\n(1 real change made)\n(30 real changes made)\n(29 real changes made)\n(1 real change made)\n(28 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_\n&gt; 3.dta saved\n(99 observations deleted)\n(0 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(33 real changes made)\n(1 real change made)\n(32 real changes made)\n(28 real changes made)\n(1 real change made)\n(27 real changes made)\n(31 real changes made)\n(1 real change made)\n(30 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\n(0 real changes made)\n(1 real change made)\n(1 real change made)\nfile Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-2\\pi_\n&gt; 4.dta saved\n\n. \n. local i=1\n\n. while `i'&lt;=4{\n  2.         use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\C\n&gt; hapter-2\\pi_`i',clear\n  3.         sort en indexc\n  4.         by en: list en indexc country p_1\n  5.         local i=`i'+1\n  6. }\n\n----------------------------------------------------------------------------------\n-&gt; en = 1\n\n     +---------------------------------------+\n     | en   indexc        country        p_1 |\n     |---------------------------------------|\n  1. |  1        1     Bangladesh   .0165219 |\n  2. |  1        2       Pakistan   .0394124 |\n  3. |  1        3      Indonesia   .0432824 |\n  4. |  1        4      Sri Lanka   .0344432 |\n  5. |  1        5       Thailand    .048902 |\n     |---------------------------------------|\n  6. |  1        6       Colombia   .1940833 |\n  7. |  1        7         Panama   .2279774 |\n  8. |  1        8     Yugoslavia   .1997569 |\n  9. |  1        9       Portugal   .1759864 |\n 10. |  1       10        Uruguay   .2029693 |\n     |---------------------------------------|\n 11. |  1       11         Greece   .3140718 |\n 12. |  1       12        Ireland   .4166084 |\n 13. |  1       13          Spain   .4172725 |\n 14. |  1       14         Israel   .6131932 |\n 15. |  1       15      Hong Kong   .3781684 |\n     |---------------------------------------|\n 16. |  1       16    New Zealand   .5850298 |\n 17. |  1       17        Austria   .5694186 |\n 18. |  1       18      Singapore   .4873306 |\n 19. |  1       19          Italy   .5907437 |\n 20. |  1       20             UK   .6332356 |\n     |---------------------------------------|\n 21. |  1       21          Japan    .604921 |\n 22. |  1       22        Belgium   .7233988 |\n 23. |  1       23       Trinidad    .448344 |\n 24. |  1       24    Netherlands   .7933354 |\n 25. |  1       25        Finland   .6969619 |\n     |---------------------------------------|\n 26. |  1       26        Denmark   .7061784 |\n 27. |  1       27   West Germany   .7691833 |\n 28. |  1       28         France    .735665 |\n 29. |  1       29         Sweden   .7270576 |\n 30. |  1       30         Norway   .7816517 |\n     |---------------------------------------|\n 31. |  1       31    Switzerland   .9317446 |\n 32. |  1       32         Canada   .7799865 |\n 33. |  1       33            USA          1 |\n     +---------------------------------------+\n\n\n----------------------------------------------------------------------------------\n-&gt; en = 2\n\n     +---------------------------------------+\n     | en   indexc        country        p_1 |\n     |---------------------------------------|\n  1. |  2        1     Bangladesh   .9119021 |\n  2. |  2        2       Pakistan   .4867497 |\n  3. |  2        3      Indonesia    .250653 |\n  4. |  2        4      Sri Lanka   .1259789 |\n  5. |  2        5       Thailand   .3929541 |\n     |---------------------------------------|\n  6. |  2        6       Colombia   .4856291 |\n  7. |  2        7         Panama   .3224079 |\n  8. |  2        8     Yugoslavia   .2985477 |\n  9. |  2        9       Portugal    .297107 |\n 10. |  2       10        Uruguay   .4060566 |\n     |---------------------------------------|\n 11. |  2       11         Greece   .4401574 |\n 12. |  2       12        Ireland   .4783922 |\n 13. |  2       13          Spain    .519489 |\n 14. |  2       14         Israel   .5049116 |\n 15. |  2       15      Hong Kong   .5150965 |\n     |---------------------------------------|\n 16. |  2       16    New Zealand   .6197254 |\n 17. |  2       17        Austria    .542198 |\n 18. |  2       18      Singapore   .3209652 |\n 19. |  2       19          Italy   .5122213 |\n 20. |  2       20             UK   .8159872 |\n     |---------------------------------------|\n 21. |  2       21          Japan   .6502131 |\n 22. |  2       22        Belgium   .6457499 |\n 23. |  2       23       Trinidad   .4193396 |\n 24. |  2       24    Netherlands   .7513015 |\n 25. |  2       25        Finland   .6453199 |\n     |---------------------------------------|\n 26. |  2       26        Denmark    .703564 |\n 27. |  2       27   West Germany   .6629313 |\n 28. |  2       28         France   .6150761 |\n 29. |  2       29         Sweden   .9445322 |\n 30. |  2       30         Norway   .6199874 |\n     |---------------------------------------|\n 31. |  2       31    Switzerland   .6079721 |\n 32. |  2       32         Canada   .7359194 |\n 33. |  2       33            USA          1 |\n     +---------------------------------------+\n\n\n----------------------------------------------------------------------------------\n-&gt; en = 3\n\n     +----------------------------------------+\n     | en   indexc        country         p_1 |\n     |----------------------------------------|\n  1. |  3        1     Bangladesh    .0230836 |\n  2. |  3        2       Pakistan    .0975686 |\n  3. |  3        3      Indonesia    .1641388 |\n  4. |  3        4      Sri Lanka    .2300839 |\n  5. |  3        5       Thailand    .3002517 |\n     |----------------------------------------|\n  6. |  3        6       Colombia    .5963939 |\n  7. |  3        7         Panama    .5834956 |\n  8. |  3        8     Yugoslavia    .3189657 |\n  9. |  3        9       Portugal    -.383313 |\n 10. |  3       10        Uruguay    .5709916 |\n     |----------------------------------------|\n 11. |  3       11         Greece    .6072472 |\n 12. |  3       12        Ireland    1.480371 |\n 13. |  3       13          Spain    .2365766 |\n 14. |  3       14         Israel    2.517195 |\n 15. |  3       15      Hong Kong    -229.073 |\n     |----------------------------------------|\n 16. |  3       16    New Zealand    7.520329 |\n 17. |  3       17        Austria    1.159659 |\n 18. |  3       18      Singapore   -25.49224 |\n 19. |  3       19          Italy    .6419317 |\n 20. |  3       20             UK     1.47654 |\n     |----------------------------------------|\n 21. |  3       21          Japan    4.292305 |\n 22. |  3       22        Belgium    .4575562 |\n 23. |  3       23       Trinidad    -.904206 |\n 24. |  3       24    Netherlands    9.091455 |\n 25. |  3       25        Finland      .67896 |\n     |----------------------------------------|\n 26. |  3       26        Denmark    1.759899 |\n 27. |  3       27   West Germany    1.054174 |\n 28. |  3       28         France    1.558952 |\n 29. |  3       29         Sweden     .907351 |\n 30. |  3       30         Norway    1.812922 |\n     |----------------------------------------|\n 31. |  3       31    Switzerland     3.74253 |\n 32. |  3       32         Canada    .4738446 |\n 33. |  3       33            USA           1 |\n     +----------------------------------------+\n\n\n----------------------------------------------------------------------------------\n-&gt; en = 4\n\n     +----------------------------------------+\n     | en   indexc        country         p_1 |\n     |----------------------------------------|\n  1. |  4        1     Bangladesh    1.256177 |\n  2. |  4        2       Pakistan    .4731916 |\n  3. |  4        3      Indonesia    .4576648 |\n  4. |  4        4      Sri Lanka    .7949094 |\n  5. |  4        5       Thailand    16.93923 |\n     |----------------------------------------|\n  6. |  4        6       Colombia    .1271541 |\n  7. |  4        7         Panama    .2973391 |\n  8. |  4        8     Yugoslavia    .6397428 |\n  9. |  4        9       Portugal    1.639775 |\n 10. |  4       10        Uruguay    .0984165 |\n     |----------------------------------------|\n 11. |  4       11         Greece    .5059133 |\n 12. |  4       12        Ireland    .6129137 |\n 13. |  4       13          Spain    1.017669 |\n 14. |  4       14         Israel     2.15672 |\n 15. |  4       15      Hong Kong   -879.5381 |\n     |----------------------------------------|\n 16. |  4       16    New Zealand    .3673215 |\n 17. |  4       17        Austria    1.975304 |\n 18. |  4       18      Singapore    795.1004 |\n 19. |  4       19          Italy    3.145272 |\n 20. |  4       20             UK    2.242249 |\n     |----------------------------------------|\n 21. |  4       21          Japan    100.5984 |\n 22. |  4       22        Belgium    6.886858 |\n 23. |  4       23       Trinidad     4.62197 |\n 24. |  4       24    Netherlands    13.09784 |\n 25. |  4       25        Finland    22.29664 |\n     |----------------------------------------|\n 26. |  4       26        Denmark    28.72834 |\n 27. |  4       27   West Germany    6.864776 |\n 28. |  4       28         France    3.166397 |\n 29. |  4       29         Sweden     7.64686 |\n 30. |  4       30         Norway    34.59857 |\n     |----------------------------------------|\n 31. |  4       31    Switzerland    3.335021 |\n 32. |  4       32         Canada    .9541135 |\n 33. |  4       33            USA           1 |\n     +----------------------------------------+\n\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-2\\pi.log\n  log type:  text\n closed on:  19 Jun 2024, 15:32:49\n----------------------------------------------------------------------------------\n\n. \n. exit\n\nend of do-file\n\n\nMy code\n\ntrefler &lt;- readRDS(fout) %&gt;%\n  # Number of country in the dataset\n  mutate(\n    c = max(indexc),\n    f = max(indexf)\n  ) %&gt;%\n  # Calculate the world level of Yw, Bw and Vw\n  mutate(\n    yww = sum(y),\n    yw = yww / f,\n    bww = sum(b),\n    bw = bww / f\n  ) %&gt;%\n  group_by(indexf) %&gt;%\n  mutate(\n    vfw = sum(v),\n    vw = sum(delta * v)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Calculate country share Sc\n  mutate(\n    sc = (y - b) / (yw - bw)\n  ) %&gt;%\n  # Calculate epsilon(fc) and sigma^2(f) according to eq.2 in Trefler (1995)\n  mutate(\n    efc = delta * at - (delta * v - sc * vw)\n  ) %&gt;%\n  # Construct the average epsilon for a given factor\n  group_by(indexf) %&gt;%\n  mutate(ave = sum(efc) / c) %&gt;%\n  # Construct sigma^2 and the weight\n  mutate(\n    sigma2f = sum((efc - ave)^2) / (c - 1),\n    sigmaf = sqrt(sigma2f),\n    weight = sigmaf * sqrt(sc)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Using the weight, convert all the data\n  mutate(\n    trat = delta * at / weight,\n    athat2 = (delta * v - (sc * vw)) / weight\n  )\n\n# No need to save changes and restore\ntrefler2 &lt;- trefler %&gt;%\n  # Construct Aggregate Labor Endowment\n  filter(indexf %in% 7:9) %&gt;%\n  mutate(\n    en = case_when(\n      indexf == 7 ~ 2,\n      indexf == 8 ~ 3,\n      indexf == 9 ~ 4\n    )\n  ) %&gt;%\n  select(country, factor, indexf, at, v, en, indexc, sc)\n\ntrefler3 &lt;- trefler %&gt;%\n  filter(!(indexf %in% 7:9)) %&gt;%\n  group_by(country) %&gt;%\n  # No need to create v_l and at_l to then rename and then collapse\n  summarise(\n    v = sum(v),\n    at = sum(at),\n    sc = mean(sc),\n    indexc = mean(indexc)\n  ) %&gt;%\n  mutate(\n    en = 1,\n    factor = \"Labor\"\n  )\n\ntrefler3 &lt;- trefler2 %&gt;%\n  select(-indexf) %&gt;%\n  bind_rows(trefler3) %&gt;%\n  arrange(indexc, en)\n\n# Compute Pi: factor productivity\n# No need to save intermediate outputs, we proceed with iteration\ntrefler4 &lt;- map_df(\n  trefler3 %&gt;%\n    distinct(en) %&gt;%\n    pull(),\n  function(x) {\n    d &lt;- trefler3 %&gt;%\n      filter(en == x) %&gt;%\n      mutate(p0 = 1, p1 = 1)\n\n    iter &lt;- 50\n\n    for (i in seq_len(iter)) {\n      d &lt;- d %&gt;%\n        mutate(\n          p0 = p1,\n          vp = p0 * v,\n          vpw = sum(vp),\n          p1 = ifelse(country == \"USA\", 1, (at + sc * vpw) / v)\n        ) %&gt;%\n        select(-vp, -vpw)\n    }\n\n    # Tidy alternative to the for loop\n    # d &lt;- accumulate(seq_len(iter), .init = d, ~ .x %&gt;%\n    #   mutate(\n    #     p0 = p1,\n    #     p1 = ifelse(country == \"USA\", 1, (at + sc * sum(p1 * v)) / v)\n    #   )) %&gt;%\n    #   .[[iter + 1]]\n\n    d %&gt;%\n      select(country, indexc, en, p1)\n  }\n)\n\n\n\nExtra step: formatting the tables\n\ntrefler4 %&gt;%\n  arrange(country, en) %&gt;%\n  kable()\n\n\n\n\ncountry\nindexc\nen\np1\n\n\n\n\nAustria\n17\n1\n0.5694186\n\n\nAustria\n17\n2\n0.5421980\n\n\nAustria\n17\n3\n1.1596592\n\n\nAustria\n17\n4\n1.9753040\n\n\nBangladesh\n1\n1\n0.0165219\n\n\nBangladesh\n1\n2\n0.9119021\n\n\nBangladesh\n1\n3\n0.0230836\n\n\nBangladesh\n1\n4\n1.2561775\n\n\nBelgium\n22\n1\n0.7233988\n\n\nBelgium\n22\n2\n0.6457500\n\n\nBelgium\n22\n3\n0.4575561\n\n\nBelgium\n22\n4\n6.8868596\n\n\nCanada\n32\n1\n0.7799865\n\n\nCanada\n32\n2\n0.7359194\n\n\nCanada\n32\n3\n0.4738445\n\n\nCanada\n32\n4\n0.9541137\n\n\nColombia\n6\n1\n0.1940833\n\n\nColombia\n6\n2\n0.4856291\n\n\nColombia\n6\n3\n0.5963939\n\n\nColombia\n6\n4\n0.1271541\n\n\nDenmark\n26\n1\n0.7061784\n\n\nDenmark\n26\n2\n0.7035640\n\n\nDenmark\n26\n3\n1.7598990\n\n\nDenmark\n26\n4\n28.7283398\n\n\nFinland\n25\n1\n0.6969619\n\n\nFinland\n25\n2\n0.6453199\n\n\nFinland\n25\n3\n0.6789600\n\n\nFinland\n25\n4\n22.2966445\n\n\nFrance\n28\n1\n0.7356650\n\n\nFrance\n28\n2\n0.6150762\n\n\nFrance\n28\n3\n1.5589519\n\n\nFrance\n28\n4\n3.1663974\n\n\nGreece\n11\n1\n0.3140718\n\n\nGreece\n11\n2\n0.4401574\n\n\nGreece\n11\n3\n0.6072472\n\n\nGreece\n11\n4\n0.5059134\n\n\nHong Kong\n15\n1\n0.3781684\n\n\nHong Kong\n15\n2\n0.5150965\n\n\nHong Kong\n15\n3\n-229.0729738\n\n\nHong Kong\n15\n4\n-879.5376414\n\n\nIndonesia\n3\n1\n0.0432824\n\n\nIndonesia\n3\n2\n0.2506530\n\n\nIndonesia\n3\n3\n0.1641388\n\n\nIndonesia\n3\n4\n0.4576649\n\n\nIreland\n12\n1\n0.4166084\n\n\nIreland\n12\n2\n0.4783923\n\n\nIreland\n12\n3\n1.4803708\n\n\nIreland\n12\n4\n0.6129137\n\n\nIsrael\n14\n1\n0.6131932\n\n\nIsrael\n14\n2\n0.5049116\n\n\nIsrael\n14\n3\n2.5171947\n\n\nIsrael\n14\n4\n2.1567210\n\n\nItaly\n19\n1\n0.5907437\n\n\nItaly\n19\n2\n0.5122213\n\n\nItaly\n19\n3\n0.6419316\n\n\nItaly\n19\n4\n3.1452732\n\n\nJapan\n21\n1\n0.6049210\n\n\nJapan\n21\n2\n0.6502130\n\n\nJapan\n21\n3\n4.2923043\n\n\nJapan\n21\n4\n100.5984017\n\n\nNetherlands\n24\n1\n0.7933355\n\n\nNetherlands\n24\n2\n0.7513015\n\n\nNetherlands\n24\n3\n9.0914542\n\n\nNetherlands\n24\n4\n13.0978390\n\n\nNew Zealand\n16\n1\n0.5850298\n\n\nNew Zealand\n16\n2\n0.6197254\n\n\nNew Zealand\n16\n3\n7.5203295\n\n\nNew Zealand\n16\n4\n0.3673216\n\n\nNorway\n30\n1\n0.7816517\n\n\nNorway\n30\n2\n0.6199874\n\n\nNorway\n30\n3\n1.8129219\n\n\nNorway\n30\n4\n34.5985787\n\n\nPakistan\n2\n1\n0.0394124\n\n\nPakistan\n2\n2\n0.4867497\n\n\nPakistan\n2\n3\n0.0975686\n\n\nPakistan\n2\n4\n0.4731917\n\n\nPanama\n7\n1\n0.2279774\n\n\nPanama\n7\n2\n0.3224079\n\n\nPanama\n7\n3\n0.5834955\n\n\nPanama\n7\n4\n0.2973391\n\n\nPortugal\n9\n1\n0.1759864\n\n\nPortugal\n9\n2\n0.2971070\n\n\nPortugal\n9\n3\n-0.3833130\n\n\nPortugal\n9\n4\n1.6397757\n\n\nSingapore\n18\n1\n0.4873306\n\n\nSingapore\n18\n2\n0.3209652\n\n\nSingapore\n18\n3\n-25.4922493\n\n\nSingapore\n18\n4\n795.1006524\n\n\nSpain\n13\n1\n0.4172726\n\n\nSpain\n13\n2\n0.5194890\n\n\nSpain\n13\n3\n0.2365766\n\n\nSpain\n13\n4\n1.0176692\n\n\nSri Lanka\n4\n1\n0.0344433\n\n\nSri Lanka\n4\n2\n0.1259789\n\n\nSri Lanka\n4\n3\n0.2300838\n\n\nSri Lanka\n4\n4\n0.7949096\n\n\nSweden\n29\n1\n0.7270576\n\n\nSweden\n29\n2\n0.9445322\n\n\nSweden\n29\n3\n0.9073509\n\n\nSweden\n29\n4\n7.6468612\n\n\nSwitzerland\n31\n1\n0.9317447\n\n\nSwitzerland\n31\n2\n0.6079722\n\n\nSwitzerland\n31\n3\n3.7425295\n\n\nSwitzerland\n31\n4\n3.3350218\n\n\nThailand\n5\n1\n0.0489020\n\n\nThailand\n5\n2\n0.3929541\n\n\nThailand\n5\n3\n0.3002516\n\n\nThailand\n5\n4\n16.9392348\n\n\nTrinidad\n23\n1\n0.4483440\n\n\nTrinidad\n23\n2\n0.4193396\n\n\nTrinidad\n23\n3\n-0.9042060\n\n\nTrinidad\n23\n4\n4.6219780\n\n\nUK\n20\n1\n0.6332355\n\n\nUK\n20\n2\n0.8159872\n\n\nUK\n20\n3\n1.4765402\n\n\nUK\n20\n4\n2.2422499\n\n\nUSA\n33\n1\n1.0000000\n\n\nUSA\n33\n2\n1.0000000\n\n\nUSA\n33\n3\n1.0000000\n\n\nUSA\n33\n4\n1.0000000\n\n\nUruguay\n10\n1\n0.2029693\n\n\nUruguay\n10\n2\n0.4060566\n\n\nUruguay\n10\n3\n0.5709917\n\n\nUruguay\n10\n4\n0.0984165\n\n\nWest Germany\n27\n1\n0.7691833\n\n\nWest Germany\n27\n2\n0.6629313\n\n\nWest Germany\n27\n3\n1.0541740\n\n\nWest Germany\n27\n4\n6.8647780\n\n\nYugoslavia\n8\n1\n0.1997569\n\n\nYugoslavia\n8\n2\n0.2985477\n\n\nYugoslavia\n8\n3\n0.3189656\n\n\nYugoslavia\n8\n4\n0.6397429"
  },
  {
    "objectID": "chapter4.html#data-description",
    "href": "chapter4.html#data-description",
    "title": "Chapter 4. Trade in Intermediate Inputs and Wages",
    "section": "Data Description",
    "text": "Data Description\nHere are some variable definitions in data file data_Chp4 to help you in the replication exercise. The variable names also give you a hint as to the naming conventions used by Feenstra & Hanson with their other variables.\n\nSources\n\nNBER productivity dataset (Bartelsman, Becker, Gray):\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nsic\nStandard Industrial Classification (4-digit manufacturing)\n\n\nyear\nYear ranges from 58 to 97\n\n\nemp\nTotal employment in 1000s\n\n\npay\nTotal payroll in $1,000,000\n\n\nprode\nProduction workers in 1000s\n\n\nprodh\nProduction worker hours in 1,000,000\n\n\nprodw\nProduction worker wages in $1,000,000\n\n\nvship\nTotal value of shipments in $1,000,000\n\n\nmaterial\nTotal cost of materials in $1,000,000\n\n\nvadd\nTotal value added in $1,000,000\n\n\ninvest\nTotal capital expenditure in $1,000,000\n\n\ninvent\nEnd-of-year inventories in $1,000,000\n\n\nenergy\nCost of electric & fuels in $1,000,000\n\n\ncap\nTotal real capital stock in $1,000,000\n\n\nequip\nReal capital: equipment in $1,000,000\n\n\nplant\nReal capital: structures in $1,000,000\n\n\npiship\nDeflator for VSHIP 1987=1.000\n\n\npimat\nDeflator for MATCOST 1987=1.000\n\n\npiinv\nDeflator for INVEST 1987=1.000\n\n\npien\nDeflator for ENERGY 1987=1.000\n\n\n\n\n\nOther variables created by Feenstra and Hanson:\nThe prefix “a” generally denotes an average of that variable over two periods.\nThe prefix “d” indicates annual average change in that variable x 100.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nsic72\n4 digit SIC code\n\n\nsic2\n2 digit SIC code\n\n\nptfp\nprimary TFP\n\n\nerr\nerror as defined in (4.26) of Chapter 4, or (3) in Feenstra and Hanson (1999)\n\n\nsimat1a\nShare of imported materials (broad outsourcing)\n\n\nsimat1b\nshare of imported materials from inside 2-digit industry (narrow outsourcing)\n\n\ndiffout\n= simat1a – simat1b = share of imported materials from outside 2-digit industry\n\n\nimat\nimported materials\n\n\namsh\naverage material share\n\n\naosh\naverage energy share\n\n\nadlhw\nannual change in log production wage\n\n\nadlnw\nannual chage in log non-production wage\n\n\nadlpk\nannual change in log capital price\n\n\namesh\naosh + amsh\n\n\napsh\naverage production share\n\n\nansh\naverage non-production share\n\n\naksh\naverage capital share\n\n\nnwsh\nnonproduction share of the total wages\n\n\ndlpvad\nchange in log value-added\n\n\ndlpmx\nchange in log material price\n\n\ndlpe\nchange in log energy price\n\n\ndlp\nchange in log price\n\n\ndlky\nchange in log capital stock to real shipments ratio\n\n\ndly\nchange in log real shipments\n\n\nmvshipsh\nindustry share of total manufacturing shipments, averaged over the first and last period\n\n\ndsimat1b\nchange in outsourcing (narrow); that is, change in imported inputs from the same 2-digit industry divided by total materials purchases\n\n\ndsimat1a\nchange in outsourcing (broad); that is, imported inputs divided by total material purchases\n\n\ndofsh\nchange in office equipment/total capital (capital=pstk x ex post rental price)\n\n\ndofsh1\nchange in office equipment/total capital (capital=pstk x ex ante rental price)\n\n\ndhtsh\nchange in High-tech capital/total capital (capital=pstk x ex post rental price)\n\n\ndhtsh1\nchange in High-tech capital/total capital (capital=pstk x ex ante rental price)\n\n\nci\ncomputer investment/total investment"
  },
  {
    "objectID": "chapter4.html#exercise-1",
    "href": "chapter4.html#exercise-1",
    "title": "Chapter 4. Trade in Intermediate Inputs and Wages",
    "section": "Exercise 1",
    "text": "Exercise 1\nDownload the NBER productivity dataset at http://www.nber.org/nberces/nbprod96.htm, compute the relative wage and relative employment for 1958 – 1996, and reconstruct Figure 4.1 and 4.2.\nNote: Given this data, you need to first compute the wage rates in production and nonproduction sectors using the following formula (\\(i\\) denotes the industry):\n\\[\\begin{align}\n  \\text{Production worker wage rate} &= \\frac{\\sum_i \\text{production worker wage bill}_i}{\\sum_i \\text{production workers}_i} \\\\\n  \\text{Non production worker wage rate} &= \\frac{\\sum_i \\text{non production worker wage bill}_i}{\\sum_i \\text{non production workers}_i} \\\\\n  &= \\frac{\\sum_i (\\text{total pay roll}_i - \\text{production worker wage bill}_i)}{\\sum_i (\\text{total employment}_i - \\text{production workers}_i)}\n\\end{align}\\]\n\nMy code\n\n# Packages ----\n\nlibrary(readr)\nlibrary(janitor)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Download and read ----\n\n# the refered link is not available anymore\n# I found a backup here: https://web.archive.org/web/20051224023622/http://www.nber.org/nberces/nbprod96.htm\n\nurl &lt;- \"https://web.archive.org/web/20051224023622/http://www.nber.org/nberces/bbg96_87.txt\"\nfinp &lt;- gsub(\".*/\", \"first-edition/Chapter-4/\", url)\n\nif (!file.exists(finp)) {\n  download.file(url, finp)\n}\n\nfout &lt;- gsub(\"txt\", \"rds\", finp)\n\nif (!file.exists(fout)) {\n  bbg96_87 &lt;- read_csv(finp) %&gt;%\n    clean_names() %&gt;%\n    mutate(year = year + 1900) %&gt;%\n    filter(year &gt;= 1958, year &lt;= 1996)\n\n  saveRDS(bbg96_87, fout)\n} else {\n  bbg96_87 &lt;- readRDS(fout)\n}\n\n# Compute the wage rates in production and nonproduction sectors ----\n\n# \\begin{align}\n#   \\text{Production worker wage rate} &= \\frac{\\sum_i \\text{production worker wage bill}_i}{\\sum_i \\text{production workers}_i} \\\\\n#   \\text{Non production worker wage rate} &= \\frac{\\sum_i \\text{non production worker wage bill}_i}{\\sum_i \\text{non production workers}_i} \\\\\n#   &= \\frac{\\sum_i (\\text{total pay roll}_i - \\text{production worker wage bill}_i)}{\\sum_i (\\text{total employment}_i - \\text{production workers}_i)}\n# \\end{align}\n\n# from the NBER website\n# prodw Production worker wages in $1,000,000\n# prode: Production workers in 1000s\n# pay Total payroll in $1,000,000\n# emp Total employment in 1000s\n\n# calculated variables\n# pwwr: Production worker wage rate\n# npwwr: Non production worker wage rate\n\nwage_rates &lt;- bbg96_87 %&gt;%\n  group_by(year) %&gt;%\n  summarise(\n    pwwr = sum(prodw) / sum(prode),\n    npwwr = (sum(pay) - sum(prodw)) / (sum(emp) - sum(prode))\n  ) %&gt;%\n  mutate(npwwr_pwwr = npwwr / pwwr)\n\n# Compute the relative nonproduction/production employment ----\n\nemployment_rates &lt;- bbg96_87 %&gt;%\n  group_by(year) %&gt;%\n  summarise(\n    pemp = sum(prode),\n    npemp = sum(emp) - pemp\n  ) %&gt;%\n  mutate(npemp_pemp = npemp / pemp)\n\n# Figure 4.1: Relative wage of nonproduction / production workers ----\n\nggplot(wage_rates, aes(x = year, y = npwwr_pwwr)) +\n  geom_line() +\n  geom_point(size = 4) +\n  theme_minimal(base_size = 13) +\n  labs(\n    title = \"Relative wage of nonproduction / production workers, U.S. Manufacturing\",\n    subtitle = \"Source: NBER productivity database (Bartelsman and Gray 1996)\",\n    x = \"Year\",\n    y = \"Relative wage\"\n  )\n\n\n\n# Figure 4.2: Relative employment of nonproduction / production workers ----\n\nggplot(employment_rates, aes(x = year, y = npemp_pemp)) +\n  geom_line() +\n  geom_point(size = 4) +\n  theme_minimal(base_size = 13) +\n  labs(\n    title = \"Relative employment of nonproduction / production workers, U.S. Manufacturing\",\n    subtitle = \"Source: NBER productivity database (Bartelsman and Gray 1996)\",\n    x = \"Year\",\n    y = \"Relative employment\"\n  )"
  },
  {
    "objectID": "chapter4.html#exercise-2",
    "href": "chapter4.html#exercise-2",
    "title": "Chapter 4. Trade in Intermediate Inputs and Wages",
    "section": "Exercise 2",
    "text": "Exercise 2\nRun the STATA program Problem_4_2.do to reproduce the regressions in Table 4.4 (which is simplified from Table III in Feenstra and Hanson, 1999). Then answer:\n\nWhat weights are used in these regressions?\nHow are the results affected if these weights are not used?\n\n\nFeenstra’s code\nset mem 300m\n\nlog using c:\\Empirical_Exercise\\Chapter_4\\log_4_2.log,replace\n\nuse c:\\Empirical_Exercise\\Chapter_4\\data_Chp4,clear\ndrop if year==1972|year==1987\ndrop if sic72==2067|sic72==2794|sic72==3483\n\negen wagebill=sum(pay), by(year)\ngen share=pay/wagebill\n\nsort sic72 year\nby sic72: gen lagshare=share[_n-1]\ngen ashare=(share+lagshare)/2\n\nby sic72: gen lagnwsh=nwsh[_n-1]\ngen chanwsh=(nwsh-lagnwsh)*100/11\n\ngen wchanwsh=chanwsh*ashare\ngen wdlky=dlky*ashare\ngen wdly=dly*ashare\ngen wdsimat1a=dsimat1a*ashare\ngen wdsimat1b=dsimat1a*ashare\ngen diffout=dsimat1a-dsimat1b\ngen wdiffout=(dsimat1a-dsimat1b)*ashare\ngen wcosh_exp=dofsh*ashare\ngen htsh_exp=dhtsh-dofsh\ngen whtsh_exp=(dhtsh-dofsh)*ashare\ngen wcosh_exa=dofsh1*ashare\ngen htsh_exa=dhtsh1-dofsh1\ngen whtsh_exa=(dhtsh1-dofsh1)*ashare\ngen wcosh=ci*ashare\ngen whtsh=dhtsh*ashare\n\n* Check with the first column of Table 4.4 *\n\ntabstat wchanwsh wdlky wdly wdsimat1a wcosh_exp whtsh_exp wcosh_exa whtsh_exa wcosh whtsh, stats(sum)\n\n* Reproduce the rest of the columns in Table 4.4 *\n\nregress chanwsh dlky dly dsimat1a dofsh htsh_exp [aw=ashare], cluster (sic2)\n\nregress chanwsh dlky dly dsimat1a dofsh1 htsh_exa [aw=ashare], cluster (sic2)\n\nregress chanwsh dlky dly dsimat1a ci dhtsh [aw=ashare], cluster (sic2)\n\n* To instead distinguish narrow and other outsourcing, we can reproduce column (1) of table III in Feenstra and Hanson, 1999 *\n\ntabstat wchanwsh wdlky wdly wdsimat1b wdiffout wcosh_exp whtsh_exp wcosh_exa whtsh_exa wcosh whtsh, stats(sum)\n\n* Reproduce the rest of the columns in Table III *\n\nregress chanwsh dlky dly dsimat1b diffout dofsh htsh_exp [aw=ashare], cluster (sic2)\n\nregress chanwsh dlky dly dsimat1b diffout dofsh1 htsh_exa [aw=ashare], cluster (sic2)\n\nregress chanwsh dlky dly dsimat1b diffout ci dhtsh [aw=ashare], cluster (sic2)\n\nlog close\n\nclear\nexit\nOutput:\n. set mem 300m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory          300M    max. data space                300.000M\n    set matsize         100     max. RHS vars in models          0.085M\n                                                            -----------\n                                                               301.994M\n\n. \n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-4\\log_4_2.log,replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-4\\log_4_2.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-4\\log_4_2.log\n  log type:  text\n opened on:  19 Jun 2024, 14:02:42\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-4\\da\n&gt; ta_Chp4,clear\n(Matrl Cons (72 SIC), 67-92)\n\n. drop if year==1972|year==1987\n(900 observations deleted)\n\n. drop if sic72==2067|sic72==2794|sic72==3483\n(6 observations deleted)\n\n. \n. egen wagebill=sum(pay), by(year)\n\n. gen share=pay/wagebill\n\n. \n. sort sic72 year\n\n. by sic72: gen lagshare=share[_n-1]\n(447 missing values generated)\n\n. gen ashare=(share+lagshare)/2\n(447 missing values generated)\n\n. \n. by sic72: gen lagnwsh=nwsh[_n-1]\n(447 missing values generated)\n\n. gen chanwsh=(nwsh-lagnwsh)*100/11\n(447 missing values generated)\n\n. \n. gen wchanwsh=chanwsh*ashare\n(447 missing values generated)\n\n. gen wdlky=dlky*ashare\n(447 missing values generated)\n\n. gen wdly=dly*ashare\n(447 missing values generated)\n\n. gen wdsimat1a=dsimat1a*ashare\n(447 missing values generated)\n\n. gen wdsimat1b=dsimat1a*ashare\n(447 missing values generated)\n\n. gen diffout=dsimat1a-dsimat1b\n\n. gen wdiffout=(dsimat1a-dsimat1b)*ashare\n(447 missing values generated)\n\n. gen wcosh_exp=dofsh*ashare\n(447 missing values generated)\n\n. gen htsh_exp=dhtsh-dofsh\n\n. gen whtsh_exp=(dhtsh-dofsh)*ashare\n(447 missing values generated)\n\n. gen wcosh_exa=dofsh1*ashare\n(447 missing values generated)\n\n. gen htsh_exa=dhtsh1-dofsh1\n\n. gen whtsh_exa=(dhtsh1-dofsh1)*ashare\n(447 missing values generated)\n\n. gen wcosh=ci*ashare\n(447 missing values generated)\n\n. gen whtsh=dhtsh*ashare\n(447 missing values generated)\n\n. \n. * Check with the first column of Table 4.4 *\n. \n. tabstat wchanwsh wdlky wdly wdsimat1a wcosh_exp whtsh_exp wcosh_exa whtsh_exa wc\n&gt; osh whtsh, stats(sum)\n\n   stats |  wchanwsh     wdlky      wdly  wdsim~1a  wcosh_~p  whtsh_~p  wcosh_~a\n---------+----------------------------------------------------------------------\n     sum |  .3889885  .7063639  1.540769  .4225266  .2505536  .1444164  .0703266\n--------------------------------------------------------------------------------\n\n   stats |  whtsh_~a     wcosh     whtsh\n---------+------------------------------\n     sum |  .1655768  6.561565    .39497\n----------------------------------------\n\n. \n. * Reproduce the rest of the columns in Table 4.4 *\n. \n. regress chanwsh dlky dly dsimat1a dofsh htsh_exp [aw=ashare], cluster (sic2)\n(sum of wgt is   1.0000e+00)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  5,    19) =    6.72\n                                                       Prob &gt; F      =  0.0009\n                                                       R-squared     =  0.1557\n                                                       Root MSE      =  .38912\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n     chanwsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        dlky |   .0467948   .0113832     4.11   0.001     .0229695    .0706201\n         dly |   .0197383   .0063797     3.09   0.006     .0063853    .0330912\n    dsimat1a |   .1966658   .0962066     2.04   0.055     -.004697    .3980286\n       dofsh |     .19534   .0915302     2.13   0.046     .0037651    .3869148\n    htsh_exp |  -.0650465   .1371193    -0.47   0.641    -.3520404    .2219474\n       _cons |   .2028764   .0428851     4.73   0.000     .1131169     .292636\n------------------------------------------------------------------------------\n\n. \n. regress chanwsh dlky dly dsimat1a dofsh1 htsh_exa [aw=ashare], cluster (sic2)\n(sum of wgt is   1.0000e+00)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  5,    19) =    8.01\n                                                       Prob &gt; F      =  0.0003\n                                                       R-squared     =  0.1592\n                                                       Root MSE      =  .38832\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n     chanwsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        dlky |   .0444529   .0113121     3.93   0.001     .0207764    .0681293\n         dly |   .0173278   .0062906     2.75   0.013     .0041613    .0304942\n    dsimat1a |   .2207528   .0999711     2.21   0.040     .0115109    .4299947\n      dofsh1 |   .4309753   .1671453     2.58   0.018     .0811362    .7808144\n    htsh_exa |   .0052436   .0712031     0.07   0.942    -.1437862    .1542735\n       _cons |   .2064394   .0397614     5.19   0.000     .1232178     .289661\n------------------------------------------------------------------------------\n\n. \n. regress chanwsh dlky dly dsimat1a ci dhtsh [aw=ashare], cluster (sic2)\n(sum of wgt is   1.0000e+00)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  5,    19) =   11.87\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.1885\n                                                       Root MSE      =  .38148\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n     chanwsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        dlky |   .0399279   .0087378     4.57   0.000     .0216396    .0582162\n         dly |   .0100379   .0062332     1.61   0.124    -.0030084    .0230841\n    dsimat1a |   .1346024   .0883067     1.52   0.144    -.0502257    .3194306\n          ci |   .0180834   .0066465     2.72   0.014     .0041722    .0319946\n       dhtsh |   .0324624      .0519     0.63   0.539    -.0761655    .1410904\n       _cons |   .1569685   .0446895     3.51   0.002     .0634323    .2505048\n------------------------------------------------------------------------------\n\n. \n. * To instead distinguish narrow and other outsourcing, we can reproduce column (\n&gt; 1) of table III in Feenstra and Hanson, 1999 *\n. \n. tabstat wchanwsh wdlky wdly wdsimat1b wdiffout wcosh_exp whtsh_exp wcosh_exa wht\n&gt; sh_exa wcosh whtsh, stats(sum)\n\n   stats |  wchanwsh     wdlky      wdly  wdsim~1b  wdiffout  wcosh_~p  whtsh_~p\n---------+----------------------------------------------------------------------\n     sum |  .3889885  .7063639  1.540769  .4225266  .1998607  .2505536  .1444164\n--------------------------------------------------------------------------------\n\n   stats |  wcosh_~a  whtsh_~a     wcosh     whtsh\n---------+----------------------------------------\n     sum |  .0703266  .1655768  6.561565    .39497\n--------------------------------------------------\n\n. \n. * Reproduce the rest of the columns in Table III *\n. \n. regress chanwsh dlky dly dsimat1b diffout dofsh htsh_exp [aw=ashare], cluster (s\n&gt; ic2)\n(sum of wgt is   1.0000e+00)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  6,    19) =    7.00\n                                                       Prob &gt; F      =  0.0005\n                                                       R-squared     =  0.1627\n                                                       Root MSE      =  .38794\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n     chanwsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        dlky |   .0421152   .0141103     2.98   0.008     .0125821    .0716483\n         dly |   .0178086   .0080568     2.21   0.040     .0009456    .0346716\n    dsimat1b |   .2454613   .1692732     1.45   0.163    -.1088315    .5997541\n     diffout |    .121362   .0457066     2.66   0.016      .025697    .2170271\n       dofsh |   .2060218   .1021206     2.02   0.058    -.0077192    .4197627\n    htsh_exp |  -.0392957   .1289341    -0.30   0.764     -.309158    .2305665\n       _cons |    .206945   .0415146     4.98   0.000      .120054    .2938361\n------------------------------------------------------------------------------\n\n. \n. regress chanwsh dlky dly dsimat1b diffout dofsh1 htsh_exa [aw=ashare], cluster (\n&gt; sic2)\n(sum of wgt is   1.0000e+00)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  6,    19) =    7.37\n                                                       Prob &gt; F      =  0.0004\n                                                       R-squared     =  0.1650\n                                                       Root MSE      =  .38742\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n     chanwsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        dlky |   .0408212   .0141101     2.89   0.009     .0112884     .070354\n         dly |   .0159677   .0078375     2.04   0.056    -.0004365    .0323718\n    dsimat1b |   .2653356    .175142     1.51   0.146    -.1012407    .6319119\n     diffout |   .1537718   .0502819     3.06   0.006     .0485307     .259013\n      dofsh1 |   .4207269   .1707522     2.46   0.023     .0633383    .7781154\n    htsh_exa |   .0143582     .07223     0.20   0.845    -.1368209    .1655373\n       _cons |   .2137716   .0390531     5.47   0.000     .1320326    .2955107\n------------------------------------------------------------------------------\n\n. \n. regress chanwsh dlky dly dsimat1b diffout ci dhtsh [aw=ashare], cluster (sic2)\n(sum of wgt is   1.0000e+00)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  6,    19) =   14.96\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.1995\n                                                       Root MSE      =  .37933\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n     chanwsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        dlky |   .0331274   .0119999     2.76   0.012     .0080113    .0582434\n         dly |   .0068629   .0087795     0.78   0.444    -.0115128    .0252386\n    dsimat1b |   .1928059   .1657117     1.16   0.259    -.1540328    .5396445\n     diffout |   .0380044   .0539983     0.70   0.490    -.0750153    .1510241\n          ci |   .0186984   .0068931     2.71   0.014     .0042711    .0331258\n       dhtsh |   .0519438   .0512489     1.01   0.324    -.0553214    .1592091\n       _cons |   .1612801   .0401323     4.02   0.001     .0772822    .2452781\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-4\\log_4_2.log\n  log type:  text\n closed on:  19 Jun 2024, 14:02:47\n----------------------------------------------------------------------------------\n\n. \n. clear\n\n. exit\n\nend of do-file\n\n\nMy code\n\n# Packages ----\n\nlibrary(archive)\nlibrary(haven)\nlibrary(dplyr)\nlibrary(lmtest)\nlibrary(sandwich)\n\n# Extract ----\n\nfzip &lt;- \"first-edition/Chapter-4.zip\"\ndout &lt;- gsub(\"\\\\.zip$\", \"\", fzip)\n\nif (!dir.exists(dout)) {\n  archive_extract(fzip, dir = dout)\n}\n\n# Read and transform ----\n\nfout &lt;- paste0(dout, \"/datachp4.rds\")\n\nif (!file.exists(fout)) {\n  datachp4 &lt;- read_dta(paste0(dout, \"/data_Chp4.dta\"))\n  saveRDS(datachp4, fout)\n} else {\n  datachp4 &lt;- readRDS(fout) %&gt;%\n    filter(!year %in% c(1972, 1987)) %&gt;%\n    filter(!sic72 %in% c(2067, 2794, 3483)) %&gt;%\n    group_by(year) %&gt;%\n    mutate(wagebill = sum(pay)) %&gt;%\n    ungroup() %&gt;%\n    mutate(share = pay / wagebill) %&gt;%\n    arrange(sic72, year) %&gt;%\n    group_by(sic72) %&gt;%\n    mutate(\n      lagshare = lag(share),\n      ashare = (share + lagshare) / 2,\n      lagnwsh = lag(nwsh),\n      chanwsh = (nwsh - lagnwsh) * 100 / 11\n    ) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n      wchanwsh = chanwsh * ashare,\n      wdlky = dlky * ashare,\n      wdly = dly * ashare,\n      wdsimat1a = dsimat1a * ashare,\n      wdsimat1b = dsimat1a * ashare,\n      diffout = dsimat1a - dsimat1b,\n      wdiffout = (dsimat1a - dsimat1b) * ashare,\n      wcosh_exp = dofsh * ashare,\n      htsh_exp = dhtsh - dofsh,\n      whtsh_exp = (dhtsh - dofsh) * ashare,\n      wcosh_exa = dofsh1 * ashare,\n      htsh_exa = dhtsh1 - dofsh1,\n      whtsh_exa = (dhtsh1 - dofsh1) * ashare,\n      wcosh = ci * ashare,\n      whtsh = dhtsh * ashare\n    )\n}\n\n# Check with the first column of Table 4.4 ----\n\ndatachp4 %&gt;%\n  select(wchanwsh:whtsh) %&gt;%\n  summarise(across(everything(), sum, na.rm = T))\n\n# A tibble: 1 × 15\n  wchanwsh wdlky  wdly wdsimat1a wdsimat1b diffout wdiffout wcosh_exp htsh_exp\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1    0.389 0.706  1.54     0.423     0.423    206.    0.200     0.251     164.\n# ℹ 6 more variables: whtsh_exp &lt;dbl&gt;, wcosh_exa &lt;dbl&gt;, htsh_exa &lt;dbl&gt;,\n#   whtsh_exa &lt;dbl&gt;, wcosh &lt;dbl&gt;, whtsh &lt;dbl&gt;\n\n# Reproduce the rest of the columns in Table 4.4 ----\n\nreg1 &lt;- lm(\n  chanwsh ~ dlky + dly + dsimat1a + dofsh + htsh_exp,\n  data = datachp4,\n  weights = datachp4$ashare\n)\n\n# summary(reg1) # no clustered robust standard errors\ncoeftest(reg1, vcov = vcovCL(reg1, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n              Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  0.2028764  0.0428851  4.7307 3.017e-06 ***\ndlky         0.0467948  0.0113832  4.1109 4.702e-05 ***\ndly          0.0197383  0.0063797  3.0939  0.002101 ** \ndsimat1a     0.1966658  0.0962066  2.0442  0.041527 *  \ndofsh        0.1953400  0.0915302  2.1342  0.033381 *  \nhtsh_exp    -0.0650465  0.1371193 -0.4744  0.635464    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nreg2 &lt;- lm(\n  chanwsh ~ dlky + dly + dsimat1a + dofsh1 + htsh_exa,\n  data = datachp4,\n  weights = datachp4$ashare\n)\n\ncoeftest(reg2, vcov = vcovCL(reg2, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 0.2064394  0.0397614  5.1920 3.183e-07 ***\ndlky        0.0444529  0.0113121  3.9297 9.872e-05 ***\ndly         0.0173278  0.0062906  2.7545  0.006121 ** \ndsimat1a    0.2207528  0.0999711  2.2082  0.027746 *  \ndofsh1      0.4309753  0.1671453  2.5784  0.010248 *  \nhtsh_exa    0.0052436  0.0712031  0.0736  0.941328    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nreg3 &lt;- lm(\n  chanwsh ~ dlky + dly + dsimat1a + ci + dhtsh,\n  data = datachp4,\n  weights = datachp4$ashare\n)\n\ncoeftest(reg3, vcov = vcovCL(reg3, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 0.1569685  0.0446895  3.5124 0.0004898 ***\ndlky        0.0399279  0.0087378  4.5696 6.353e-06 ***\ndly         0.0100379  0.0062332  1.6104 0.1080293    \ndsimat1a    0.1346024  0.0883067  1.5243 0.1281605    \nci          0.0180834  0.0066465  2.7208 0.0067708 ** \ndhtsh       0.0324624  0.0519000  0.6255 0.5319791    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Column (1) of table III in Feenstra and Hanson, 1999 ----\n\n# To distinguish narrow and other outsourcing\n\ndatachp4 %&gt;%\n  select(wchanwsh:whtsh) %&gt;%\n  summarise(across(everything(), sum, na.rm = T))\n\n# A tibble: 1 × 15\n  wchanwsh wdlky  wdly wdsimat1a wdsimat1b diffout wdiffout wcosh_exp htsh_exp\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1    0.389 0.706  1.54     0.423     0.423    206.    0.200     0.251     164.\n# ℹ 6 more variables: whtsh_exp &lt;dbl&gt;, wcosh_exa &lt;dbl&gt;, htsh_exa &lt;dbl&gt;,\n#   whtsh_exa &lt;dbl&gt;, wcosh &lt;dbl&gt;, whtsh &lt;dbl&gt;\n\n# Reproduce the rest of the columns in Table III ----\n\nreg4 &lt;- lm(\n  chanwsh ~ dlky + dly + dsimat1b + diffout + dofsh + htsh_exp,\n  data = datachp4,\n  weights = datachp4$ashare\n)\n\ncoeftest(reg4, vcov = vcovCL(reg4, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n              Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  0.2069450  0.0415146  4.9849 8.933e-07 ***\ndlky         0.0421152  0.0141103  2.9847  0.002997 ** \ndly          0.0178086  0.0080568  2.2104  0.027592 *  \ndsimat1b     0.2454613  0.1692732  1.4501  0.147746    \ndiffout      0.1213620  0.0457066  2.6552  0.008213 ** \ndofsh        0.2060217  0.1021206  2.0174  0.044257 *  \nhtsh_exp    -0.0392957  0.1289341 -0.3048  0.760683    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nreg5 &lt;- lm(\n  chanwsh ~ dlky + dly + dsimat1b + diffout + dofsh1 + htsh_exa,\n  data = datachp4,\n  weights = datachp4$ashare\n)\n\ncoeftest(reg5, vcov = vcovCL(reg5, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.2137716  0.0390531  5.4739 7.41e-08 ***\ndlky        0.0408212  0.0141101  2.8930 0.004005 ** \ndly         0.0159677  0.0078375  2.0373 0.042215 *  \ndsimat1b    0.2653356  0.1751420  1.5150 0.130497    \ndiffout     0.1537718  0.0502819  3.0582 0.002363 ** \ndofsh1      0.4207269  0.1707522  2.4640 0.014123 *  \nhtsh_exa    0.0143582  0.0722300  0.1988 0.842523    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nreg6 &lt;- lm(\n  chanwsh ~ dlky + dly + dsimat1b + diffout + ci + dhtsh,\n  data = datachp4,\n  weights = datachp4$ashare\n)\n\ncoeftest(reg6, vcov = vcovCL(reg6, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 0.1612801  0.0401323  4.0187 6.883e-05 ***\ndlky        0.0331274  0.0119999  2.7606  0.006010 ** \ndly         0.0068629  0.0087795  0.7817  0.434811    \ndsimat1b    0.1928058  0.1657117  1.1635  0.245257    \ndiffout     0.0380044  0.0539983  0.7038  0.481925    \nci          0.0186984  0.0068931  2.7126  0.006937 ** \ndhtsh       0.0519438  0.0512489  1.0136  0.311350    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "chapter4.html#exercise-3",
    "href": "chapter4.html#exercise-3",
    "title": "Chapter 4. Trade in Intermediate Inputs and Wages",
    "section": "Exercise 3",
    "text": "Exercise 3\nRun the STATA program Problem_4_3a.do to reproduce the regressions in Table 4.5 (i.e. Table I in Feenstra and Hansen, 1999). Then run Problem_4_3b.do to perform the two-step regression, Table IV and Table V in Feenstra and Hanson (1999). Note that Table V is obtained using the coefficients in the first column of Table IV.\n\nFeenstra’s code\n\nPart A\nset mem 3m\n\nlog using c:\\Empirical_Exercise\\Chapter_4\\log_4_3a.log,replace\n\nuse c:\\Empirical_Exercise\\Chapter_4\\data_Chp4.dta, clear\n\nkeep if year==1990\ndrop if sic72==2067\ndrop if sic72==2794\ndrop if sic72==3483\ngen etfp=ptfp-err\ngen adj1=1/(1-amesh)\ngen etfp1=adj1*etfp\ngen dlpvad1=adj1*dlpvad\ngen apsh1=adj1*apsh\ngen ansh1=adj1*ansh\ngen aksh1=adj1*aksh\ngen mshxpr=amsh*dlpmx\ngen eshxpr=aosh*dlpe\n\n* Reproduce Table 4.5 *\n\ngen dlp34=dlp-mshxpr-eshxpr\n\nregress dlp34 ptfp apsh ansh aksh [aw=mvshipsh], robust\n\npreserve\ndrop if sic72==3573\nregress dlp34 ptfp apsh ansh aksh [aw=mvshipsh], robust\n\nregress dlp apsh ansh aksh mshxpr eshxpr [aw=mvshipsh], robust\nrestore\n\nregress dlpvad1 etfp1 apsh1 ansh1 aksh1 [aw=mvshipsh],robust noconstant\n\nregress dlp etfp apsh ansh aksh mshxpr eshxpr [aw=mvshipsh], robust\n\nlog close\nclear\nexit\nOutput:\n. set mem 3m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory            3M    max. data space                  3.000M\n    set matsize         100     max. RHS vars in models          0.085M\n                                                            -----------\n                                                                 4.994M\n\n. \n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-4\\log_4_3a.log,replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-4\\log_4_3a.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-4\\log_4_3a.log\n  log type:  text\n opened on:  19 Jun 2024, 14:14:42\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-4\\da\n&gt; ta_Chp4.dta, clear\n(Matrl Cons (72 SIC), 67-92)\n\n. \n. keep if year==1990\n(1350 observations deleted)\n\n. drop if sic72==2067\n(1 observation deleted)\n\n. drop if sic72==2794\n(1 observation deleted)\n\n. drop if sic72==3483\n(1 observation deleted)\n\n. gen etfp=ptfp-err\n\n. gen adj1=1/(1-amesh)\n\n. gen etfp1=adj1*etfp\n\n. gen dlpvad1=adj1*dlpvad\n\n. gen apsh1=adj1*apsh\n\n. gen ansh1=adj1*ansh\n\n. gen aksh1=adj1*aksh\n\n. gen mshxpr=amsh*dlpmx\n\n. gen eshxpr=aosh*dlpe\n\n. \n. \n. * Reproduce Table 4.5 *\n. \n. gen dlp34=dlp-mshxpr-eshxpr\n\n. \n. regress dlp34 ptfp apsh ansh aksh [aw=mvshipsh], robust\n(sum of wgt is   9.9873e-01)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  4,   442) =  106.29\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.8957\n                                                       Root MSE      =  .80656\n\n------------------------------------------------------------------------------\n             |               Robust\n       dlp34 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        ptfp |  -.9631819   .0702093   -13.72   0.000    -1.101168   -.8251963\n        apsh |   3.062598    1.22198     2.51   0.013     .6609845    5.464212\n        ansh |   2.294716   1.430073     1.60   0.109    -.5158719    5.105305\n        aksh |   7.887571   .7810006    10.10   0.000     6.352634    9.422507\n       _cons |  -.7051116   .3006016    -2.35   0.019    -1.295898   -.1143256\n------------------------------------------------------------------------------\n\n. \n. preserve\n\n. drop if sic72==3573\n(1 observation deleted)\n\n. regress dlp34 ptfp apsh ansh aksh [aw=mvshipsh], robust\n(sum of wgt is   9.8179e-01)\n\nLinear regression                                      Number of obs =     446\n                                                       F(  4,   441) =   92.17\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.8059\n                                                       Root MSE      =  .74139\n\n------------------------------------------------------------------------------\n             |               Robust\n       dlp34 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        ptfp |  -.7531151   .0751891   -10.02   0.000    -.9008886   -.6053416\n        apsh |   2.427856   1.162844     2.09   0.037      .142451    4.713261\n        ansh |   4.086394   1.722144     2.37   0.018     .7017647    7.471024\n        aksh |   8.058291   .9411699     8.56   0.000     6.208556    9.908027\n       _cons |  -.8249273   .2930995    -2.81   0.005    -1.400973   -.2488819\n------------------------------------------------------------------------------\n\n. \n. regress dlp apsh ansh aksh mshxpr eshxpr [aw=mvshipsh], robust\n(sum of wgt is   9.8179e-01)\n\nLinear regression                                      Number of obs =     446\n                                                       F(  5,   440) =   10.85\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.4289\n                                                       Root MSE      =  1.2034\n\n------------------------------------------------------------------------------\n             |               Robust\n         dlp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        apsh |   3.605277    1.88524     1.91   0.056    -.0999163    7.310471\n        ansh |   6.202674   4.036466     1.54   0.125    -1.730475    14.13582\n        aksh |   9.535214    2.18722     4.36   0.000     5.236518    13.83391\n      mshxpr |   1.219304   .2471334     4.93   0.000     .7335958    1.705013\n      eshxpr |  -.9301182   .9150299    -1.02   0.310    -2.728491    .8682541\n       _cons |  -1.929187   .9147773    -2.11   0.036    -3.727063   -.1313111\n------------------------------------------------------------------------------\n\n. restore\n\n. \n. regress dlpvad1 etfp1 apsh1 ansh1 aksh1 [aw=mvshipsh],robust noconstant\n(sum of wgt is   9.9873e-01)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  4,   443) =       .\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.9998\n                                                       Root MSE      =  .07762\n\n------------------------------------------------------------------------------\n             |               Robust\n     dlpvad1 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n       etfp1 |  -1.000041   .0006831 -1463.88   0.000    -1.001384   -.9986986\n       apsh1 |   4.680657   .0157718   296.77   0.000      4.64966    4.711654\n       ansh1 |   5.482807   .0194677   281.64   0.000     5.444547    5.521068\n       aksh1 |   3.952538   .0083407   473.89   0.000     3.936146     3.96893\n------------------------------------------------------------------------------\n\n. \n. regress dlp etfp apsh ansh aksh mshxpr eshxpr [aw=mvshipsh], robust\n(sum of wgt is   9.9873e-01)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  6,   440) =       .\n                                                       Prob &gt; F      =  0.0000\n                                                       R-squared     =  0.9999\n                                                       Root MSE      =   .0262\n\n------------------------------------------------------------------------------\n             |               Robust\n         dlp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        etfp |  -1.000358    .000677 -1477.55   0.000    -1.001689   -.9990273\n        apsh |   4.700013    .011911   394.60   0.000     4.676603    4.723422\n        ansh |   5.443315   .0314405   173.13   0.000     5.381523    5.505107\n        aksh |   3.972308   .0150284   264.32   0.000     3.942772    4.001845\n      mshxpr |   .9974072   .0023115   431.50   0.000     .9928643     1.00195\n      eshxpr |   .9961108   .0057421   173.47   0.000     .9848254    1.007396\n       _cons |   .0010799    .005423     0.20   0.842    -.0095784    .0117382\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-4\\log_4_3a.log\n  log type:  text\n closed on:  19 Jun 2024, 14:14:44\n----------------------------------------------------------------------------------\n\n. clear\n\n. exit\n\nend of do-file\n\n\nPart B\nset mem 3m\ncapture log close\nlog using c:\\Empirical_Exercise\\Chapter_4\\log_4_3b.log,replace\n\nuse c:\\Empirical_Exercise\\Chapter_4\\data_Chp4, clear\n\nkeep if year==1990\ndrop if sic72==2067\ndrop if sic72==2794\ndrop if sic72==3483\ngen etfp=ptfp-err\ngen adj1=1/(1-amesh)\ngen etfp1=adj1*etfp\ngen dlpvad1=adj1*dlpvad\ngen apsh1=adj1*apsh\ngen ansh1=adj1*ansh\ngen aksh1=adj1*aksh\ngen t4dlpvad=(dlpvad+etfp)*adj1\npreserve\n\n* Reproduce the first column of Table IV  *\n* generating difference measure of outsourcing *\n\ngen dsimatd1=dsimat1a-dsimat1b\n\n* generating difference measure of high tech share *\n\ngen dhtdsh=dhtsh-dofsh\n\n* check whether we are using the right variable as described in table II *\n\nsum dsimatd1 dhtdsh dofsh [aw=mvshipsh]\n\nregress t4dlpvad dsimat1b dsimatd1 dofsh dhtdsh [aw=mvshipsh], cluster(sic2)\n\n* Reproduce Table V using the coefficients in column(1) of Table IV *\n\ngen wt=mvshipsh^.5\ngen apsh5=apsh1*wt\ngen ansh5=ansh1*wt\ngen aksh5=aksh1*wt\ngen narrout=dsimat1b*wt*_coef[dsimat1b]\ngen diffout=dsimatd1*wt*_coef[dsimatd1]\ngen comsh=dofsh*wt*_coef[dofsh]\ngen difcom=dhtdsh*wt*_coef[dhtdsh]\n\nsum narrout diffout comsh difcom\n\nregress narrout apsh5 ansh5 aksh5, noconstant\nregress diffout apsh5 ansh5 aksh5, noconstant\nregress comsh apsh5 ansh5 aksh5, noconstant\nregress difcom apsh5 ansh5 aksh5, noconstant\n\nrestore\n\n* Reproduce column (2) of Table IV *\n\npreserve\n\n* generating difference measure of outsourcing *\n\ngen dsimatd1=dsimat1a-dsimat1b\n\n* generate difference measure of high tech share with ex ante rental price *\n\ngen dhtdsh1=dhtsh1-dofsh1\n\n* check whether we are using the right variable as described in table II *\n\nsum dsimatd1 dhtdsh1 dofsh1 [aw=mvshipsh]\n\nregress t4dlpvad dsimat1b dsimatd1 dofsh1 dhtdsh1 [aw=mvshipsh], cluster(sic2)\n\n* Reproduce column (3) of Table IV *\n\n* generating difference measure of high tech share *\n\ngen dhtdsh=dhtsh-dofsh\n\nregress t4dlpvad dsimat1b dsimatd1 ci dhtsh [aw=mvshipsh], cluster(sic2)\n\nlog close\nclear\n\nexit\nOutput:\n. set mem 3m\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory            3M    max. data space                  3.000M\n    set matsize         100     max. RHS vars in models          0.085M\n                                                            -----------\n                                                                 4.994M\n\n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-4\\log_4_3b.log,replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-4\\log_4_3b.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-4\\log_4_3b.log\n  log type:  text\n opened on:  19 Jun 2024, 14:15:50\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-4\\da\n&gt; ta_Chp4, clear\n(Matrl Cons (72 SIC), 67-92)\n\n. \n. keep if year==1990\n(1350 observations deleted)\n\n. drop if sic72==2067\n(1 observation deleted)\n\n. drop if sic72==2794\n(1 observation deleted)\n\n. drop if sic72==3483\n(1 observation deleted)\n\n. gen etfp=ptfp-err\n\n. gen adj1=1/(1-amesh)\n\n. gen etfp1=adj1*etfp\n\n. gen dlpvad1=adj1*dlpvad\n\n. gen apsh1=adj1*apsh\n\n. gen ansh1=adj1*ansh\n\n. gen aksh1=adj1*aksh\n\n. gen t4dlpvad=(dlpvad+etfp)*adj1\n\n. preserve\n\n. \n. * Reproduce the first column of Table IV  *\n. * generating difference measure of outsourcing *\n. \n. gen dsimatd1=dsimat1a-dsimat1b\n\n. \n. * generating difference measure of high tech share *\n. \n. gen dhtdsh=dhtsh-dofsh\n\n. \n. * check whether we are using the right variable as described in table II *\n. \n. sum dsimatd1 dhtdsh dofsh [aw=mvshipsh]\n\n    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max\n-------------+-----------------------------------------------------------------\n    dsimatd1 |     447  .998730832    .1598317   .3220691  -1.763297   2.735888\n      dhtdsh |     447  .998730832    .1281193   .1962393  -.0841524   .9744269\n       dofsh |     447  .998730832    .1983744    .244483  -.3634307   .8313999\n\n. \n. regress t4dlpvad dsimat1b dsimatd1 dofsh dhtdsh [aw=mvshipsh], cluster(sic2)\n(sum of wgt is   9.9873e-01)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  4,    19) =    5.40\n                                                       Prob &gt; F      =  0.0044\n                                                       R-squared     =  0.1534\n                                                       Root MSE      =  .14521\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n    t4dlpvad |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n    dsimat1b |   .0635024    .030585     2.08   0.052    -.0005128    .1275177\n    dsimatd1 |   .0788136   .0472159     1.67   0.111    -.0200103    .1776375\n       dofsh |   .1665693   .0658945     2.53   0.021     .0286505    .3044881\n      dhtdsh |    .075982   .0722494     1.05   0.306    -.0752377    .2272016\n       _cons |   4.262727   .0322917   132.01   0.000      4.19514    4.330314\n------------------------------------------------------------------------------\n\n. \n. * Reproduce Table V using the coefficients in column(1) of Table IV *\n. \n. gen wt=mvshipsh^.5\n\n. gen apsh5=apsh1*wt\n\n. gen ansh5=ansh1*wt\n\n. gen aksh5=aksh1*wt\n\n. gen narrout=dsimat1b*wt*_coef[dsimat1b]\n\n. gen diffout=dsimatd1*wt*_coef[dsimatd1]\n\n. gen comsh=dofsh*wt*_coef[dofsh]\n\n. gen difcom=dhtdsh*wt*_coef[dhtdsh]\n\n. \n. sum narrout diffout comsh difcom\n\n    Variable |       Obs        Mean    Std. Dev.       Min        Max\n-------------+--------------------------------------------------------\n     narrout |       447    .0004107    .0012838  -.0077687   .0131523\n     diffout |       447    .0005548    .0012192  -.0053996   .0156501\n       comsh |       447    .0012452    .0021439  -.0028531   .0110437\n      difcom |       447    .0004038    .0007386  -.0009354   .0064305\n\n. \n. regress narrout apsh5 ansh5 aksh5, noconstant\n\n      Source |       SS       df       MS              Number of obs =     447\n-------------+------------------------------           F(  3,   444) =   52.29\n       Model |  .000211586     3  .000070529           Prob &gt; F      =  0.0000\n    Residual |  .000598861   444  1.3488e-06           R-squared     =  0.2611\n-------------+------------------------------           Adj R-squared =  0.2561\n       Total |  .000810447   447  1.8131e-06           Root MSE      =  .00116\n\n------------------------------------------------------------------------------\n     narrout |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n       apsh5 |  -.0095155   .0093511    -1.02   0.309    -.0278934    .0088624\n       ansh5 |   .0986666   .0147744     6.68   0.000     .0696303     .127703\n       aksh5 |   .0026378    .003536     0.75   0.456    -.0043116    .0095872\n------------------------------------------------------------------------------\n\n. regress diffout apsh5 ansh5 aksh5, noconstant\n\n      Source |       SS       df       MS              Number of obs =     447\n-------------+------------------------------           F(  3,   444) =   44.65\n       Model |  .000185525     3  .000061842           Prob &gt; F      =  0.0000\n    Residual |  .000615016   444  1.3852e-06           R-squared     =  0.2317\n-------------+------------------------------           Adj R-squared =  0.2266\n       Total |  .000800542   447  1.7909e-06           Root MSE      =  .00118\n\n------------------------------------------------------------------------------\n     diffout |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n       apsh5 |   .0203644   .0094764     2.15   0.032     .0017403    .0389885\n       ansh5 |   .0628478   .0149723     4.20   0.000     .0334224    .0922732\n       aksh5 |  -.0011399   .0035834    -0.32   0.751    -.0081824    .0059026\n------------------------------------------------------------------------------\n\n. regress comsh apsh5 ansh5 aksh5, noconstant\n\n      Source |       SS       df       MS              Number of obs =     447\n-------------+------------------------------           F(  3,   444) =  153.17\n       Model |  .001395044     3  .000465015           Prob &gt; F      =  0.0000\n    Residual |  .001347998   444  3.0360e-06           R-squared     =  0.5086\n-------------+------------------------------           Adj R-squared =  0.5053\n       Total |  .002743042   447  6.1366e-06           Root MSE      =  .00174\n\n------------------------------------------------------------------------------\n       comsh |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n       apsh5 |  -.0049722   .0140295    -0.35   0.723    -.0325447    .0226004\n       ansh5 |   .2480141   .0221661    11.19   0.000     .2044505    .2915777\n       aksh5 |   .0007009   .0053051     0.13   0.895    -.0097253    .0111272\n------------------------------------------------------------------------------\n\n. regress difcom apsh5 ansh5 aksh5, noconstant\n\n      Source |       SS       df       MS              Number of obs =     447\n-------------+------------------------------           F(  3,   444) =   68.02\n       Model |  .000099567     3  .000033189           Prob &gt; F      =  0.0000\n    Residual |  .000216627   444  4.8790e-07           R-squared     =  0.3149\n-------------+------------------------------           Adj R-squared =  0.3103\n       Total |  .000316194   447  7.0737e-07           Root MSE      =   .0007\n\n------------------------------------------------------------------------------\n      difcom |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n       apsh5 |   .0259448   .0056241     4.61   0.000     .0148915     .036998\n       ansh5 |   .0069214   .0088859     0.78   0.436    -.0105422    .0243851\n       aksh5 |   .0043305   .0021267     2.04   0.042     .0001509    .0085102\n------------------------------------------------------------------------------\n\n. \n. restore\n\n. \n. * Reproduce column (2) of Table IV *\n. \n. preserve\n\n. \n. * generating difference measure of outsourcing *\n. \n. gen dsimatd1=dsimat1a-dsimat1b\n\n. \n. * generate difference measure of high tech share with ex ante rental price *\n. \n. gen dhtdsh1=dhtsh1-dofsh1\n\n. \n. * check whether we are using the right variable as described in table II *\n. \n. sum dsimatd1 dhtdsh1 dofsh1 [aw=mvshipsh]\n\n    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max\n-------------+-----------------------------------------------------------------\n    dsimatd1 |     447  .998730832    .1598317   .3220691  -1.763297   2.735888\n     dhtdsh1 |     447  .998730832    .1643722   .1506561   .0204334   .9001704\n      dofsh1 |     447  .998730832    .0534329    .124323  -.2700591   .3795505\n\n. \n. regress t4dlpvad dsimat1b dsimatd1 dofsh1 dhtdsh1 [aw=mvshipsh], cluster(sic2)\n(sum of wgt is   9.9873e-01)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  4,    19) =    2.42\n                                                       Prob &gt; F      =  0.0844\n                                                       R-squared     =  0.1089\n                                                       Root MSE      =  .14898\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n    t4dlpvad |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n    dsimat1b |   .0795164    .034676     2.29   0.033     .0069387    .1520942\n    dsimatd1 |     .11368   .0440198     2.58   0.018     .0215455    .2058144\n      dofsh1 |   .1924159   .1083624     1.78   0.092    -.0343891    .4192209\n     dhtdsh1 |  -.0477944   .0820494    -0.58   0.567    -.2195258    .1239369\n       _cons |   4.294261   .0385949   111.27   0.000     4.213481    4.375041\n------------------------------------------------------------------------------\n\n. \n. * Reproduce column (3) of Table IV *\n. \n. * generating difference measure of high tech share *\n. \n. gen dhtdsh=dhtsh-dofsh\n\n. \n. regress t4dlpvad dsimat1b dsimatd1 ci dhtsh [aw=mvshipsh], cluster(sic2)\n(sum of wgt is   9.9873e-01)\n\nLinear regression                                      Number of obs =     447\n                                                       F(  4,    19) =    5.96\n                                                       Prob &gt; F      =  0.0028\n                                                       R-squared     =  0.2129\n                                                       Root MSE      =  .14002\n\n                                  (Std. Err. adjusted for 20 clusters in sic2)\n------------------------------------------------------------------------------\n             |               Robust\n    t4dlpvad |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n    dsimat1b |   .0404059   .0295213     1.37   0.187    -.0213829    .1021947\n    dsimatd1 |   .0351687   .0488208     0.72   0.480    -.0670145    .1373518\n          ci |   .0081792   .0045064     1.82   0.085    -.0012528    .0176112\n       dhtsh |    .093074   .0496036     1.88   0.076    -.0107475    .1968955\n       _cons |   4.243861   .0334856   126.74   0.000     4.173775    4.313947\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-4\\log_4_3b.log\n  log type:  text\n closed on:  19 Jun 2024, 14:15:52\n----------------------------------------------------------------------------------\n\n. clear\n\n. \n. exit\n\nend of do-file\n\n\n\nMy code\n\nPart A\n\n# Read and transform ----\n\ndatachp4 &lt;- readRDS(fout) %&gt;%\n  filter(year == 1990) %&gt;%\n  filter(!sic72 %in% c(2067, 2794, 3483)) %&gt;%\n  mutate(\n    etfp = ptfp - err,\n    adj1 = 1 / (1 - amesh),\n    etfp1 = adj1 * etfp,\n    dlpvad1 = adj1 * dlpvad,\n    apsh1 = adj1 * apsh,\n    ansh1 = adj1 * ansh,\n    aksh1 = adj1 * aksh,\n    mshxpr = amsh * dlpmx,\n    eshxpr = aosh * dlpe\n  )\n\n# Reproduce Table 4.5 ----\n\ndatachp4 &lt;- datachp4 %&gt;%\n  mutate(dlp34 = dlp - mshxpr - eshxpr)\n\nreg1 &lt;- lm(\n  dlp34 ~ ptfp + apsh + ansh + aksh,\n  data = datachp4,\n  weights = datachp4$mvshipsh\n)\n\n# HC1 is the Stata default\ncoeftest(reg1, vcov = vcovHC(reg1, type = \"HC1\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept) -0.705112   0.300602  -2.3457  0.01943 *  \nptfp        -0.963182   0.070209 -13.7187  &lt; 2e-16 ***\napsh         3.062598   1.221980   2.5063  0.01256 *  \nansh         2.294716   1.430073   1.6046  0.10929    \naksh         7.887571   0.781001  10.0993  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# there is no equivalent to the Stata command \"preserve\" in R\n# therefore, I make a copy of the data and drop the observations\n\ndatachp4_2 &lt;- datachp4 %&gt;%\n  filter(sic72 != 3573)\n\nreg2 &lt;- lm(\n  dlp34 ~ ptfp + apsh + ansh + aksh,\n  data = datachp4_2,\n  weights = datachp4_2$mvshipsh\n)\n\ncoeftest(reg2, vcov = vcovHC(reg2, type = \"HC1\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -0.824927   0.293099  -2.8145  0.005104 ** \nptfp        -0.753115   0.075189 -10.0163 &lt; 2.2e-16 ***\napsh         2.427856   1.162844   2.0879  0.037384 *  \nansh         4.086394   1.722144   2.3729  0.018079 *  \naksh         8.058291   0.941170   8.5620 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nreg3 &lt;- lm(\n  dlp ~ apsh + ansh + aksh + mshxpr + eshxpr,\n  data = datachp4_2,\n  weights = datachp4_2$mvshipsh\n)\n\ncoeftest(reg3, vcov = vcovHC(reg3, type = \"HC1\"))\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -1.92919    0.91478 -2.1089   0.03552 *  \napsh         3.60528    1.88524  1.9124   0.05648 .  \nansh         6.20267    4.03647  1.5367   0.12510    \naksh         9.53521    2.18722  4.3595 1.625e-05 ***\nmshxpr       1.21930    0.24713  4.9338 1.146e-06 ***\neshxpr      -0.93012    0.91503 -1.0165   0.30995    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nreg4 &lt;- lm(\n  dlpvad1 ~ etfp1 + apsh1 + ansh1 + aksh1 + 0,\n  data = datachp4,\n  weights = datachp4$mvshipsh\n)\n\ncoeftest(reg4, vcov = vcovHC(reg4, type = \"HC1\"))\n\n\nt test of coefficients:\n\n         Estimate  Std. Error  t value  Pr(&gt;|t|)    \netfp1 -1.00004119  0.00068315 -1463.87 &lt; 2.2e-16 ***\napsh1  4.68065661  0.01577181   296.77 &lt; 2.2e-16 ***\nansh1  5.48280782  0.01946769   281.64 &lt; 2.2e-16 ***\naksh1  3.95253801  0.00834071   473.88 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# regress dlp etfp apsh ansh aksh mshxpr eshxpr [aw=mvshipsh], robust\n\nreg5 &lt;- lm(\n  dlp ~ etfp + apsh + ansh + aksh + mshxpr + eshxpr,\n  data = datachp4,\n  weights = datachp4$mvshipsh\n)\n\ncoeftest(reg5, vcov = vcovHC(reg5, type = \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error    t value Pr(&gt;|t|)    \n(Intercept)  0.00107993  0.00542304     0.1991   0.8422    \netfp        -1.00035789  0.00067704 -1477.5556   &lt;2e-16 ***\napsh         4.70001239  0.01191103   394.5931   &lt;2e-16 ***\nansh         5.44331510  0.03144047   173.1308   &lt;2e-16 ***\naksh         3.97230835  0.01502835   264.3210   &lt;2e-16 ***\nmshxpr       0.99740722  0.00231147   431.5032   &lt;2e-16 ***\neshxpr       0.99611082  0.00574213   173.4741   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nPart B\n\n# Packages ----\n\nlibrary(tidyr)\n\n# Read and transform ----\n\ndatachp4 &lt;- readRDS(fout) %&gt;%\n  filter(year == 1990) %&gt;%\n  filter(!sic72 %in% c(2067, 2794, 3483)) %&gt;%\n  mutate(\n    etfp = ptfp - err,\n    adj1 = 1 / (1 - amesh),\n    etfp1 = adj1 * etfp,\n    dlpvad1 = adj1 * dlpvad,\n    apsh1 = adj1 * apsh,\n    ansh1 = adj1 * ansh,\n    aksh1 = adj1 * aksh,\n    t4dlpvad = (dlpvad + etfp) * adj1\n  )\n\n# Reproduce the first column of Table IV ----\n\n# generating difference measure of outsourcing\n\ndatachp4_2 &lt;- datachp4 %&gt;%\n  mutate(dsimatd1 = dsimat1a - dsimat1b)\n\n# generating difference measure of high tech share\n\ndatachp4_2 &lt;- datachp4_2 %&gt;%\n  mutate(dhtdsh = dhtsh - dofsh)\n\n# check whether we are using the right variable as described in table II\n\n# sum dsimatd1 dhtdsh dofsh [aw=mvshipsh] is particularly hard to replicate\n\n# function to calculate weighted standard deviation\nweighted.sd &lt;- function(x, w) {\n  sqrt(sum(w * (x - weighted.mean(x, w))^2) / sum(w))\n}\n\ndatachp4_2_1 &lt;- datachp4_2 %&gt;%\n  select(dsimatd1, dhtdsh, dofsh) %&gt;%\n  summarise(\n    across(\n      everything(),\n      list(nobs = length, min = min, max = max)\n    )\n  ) %&gt;%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %&gt;%\n  separate_wider_delim(variable, \"_\", names = c(\"var\", \"stat\")) %&gt;%\n  pivot_wider(\n    names_from = stat,\n    values_from = value\n  )\n\ndatachp4_2_2 &lt;- datachp4_2 %&gt;%\n  mutate(across(c(dsimatd1, dhtdsh, dofsh), ~ . * mvshipsh)) %&gt;%\n  select(dsimatd1, dhtdsh, dofsh) %&gt;%\n  summarise(across(everything(), list(wsum = sum))) %&gt;%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %&gt;%\n  separate_wider_delim(variable, \"_\", names = c(\"var\", \"stat\")) %&gt;%\n  pivot_wider(\n    names_from = stat,\n    values_from = value\n  ) %&gt;%\n  rename(weighted_sum = wsum)\n\ndatachp4_2_3 &lt;- datachp4_2 %&gt;%\n  select(dsimatd1, dhtdsh, dofsh, mvshipsh) %&gt;%\n  pivot_longer(\n    cols = c(dsimatd1, dhtdsh, dofsh),\n    names_to = \"var\",\n    values_to = \"val\"\n  ) %&gt;%\n  group_by(var) %&gt;%\n  summarise(weighted_sd = weighted.sd(val, mvshipsh))\n\ndatachp4_2_4 &lt;- datachp4_2 %&gt;%\n  summarise(sum_weights = sum(mvshipsh))\n\ndatachp4_2_1 %&gt;%\n  left_join(datachp4_2_2) %&gt;%\n  left_join(datachp4_2_3) %&gt;%\n  bind_cols(datachp4_2_4)\n\n# A tibble: 3 × 7\n  var       nobs     min   max weighted_sum weighted_sd sum_weights\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 dsimatd1   447 -1.76   2.74         0.160       0.322       0.999\n2 dhtdsh     447 -0.0842 0.974        0.128       0.196       0.999\n3 dofsh      447 -0.363  0.831        0.198       0.244       0.999\n\nreg1 &lt;- lm(\n  t4dlpvad ~ dsimat1b + dsimatd1 + dofsh + dhtdsh,\n  data = datachp4_2,\n  weights = datachp4_2$mvshipsh\n)\n\ncoeftest(reg1, vcov = vcovCL(reg1, cluster = datachp4_2$sic2))\n\n\nt test of coefficients:\n\n            Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept) 4.262727   0.032292 132.0067  &lt; 2e-16 ***\ndsimat1b    0.063503   0.030585   2.0763  0.03845 *  \ndsimatd1    0.078814   0.047216   1.6692  0.09578 .  \ndofsh       0.166569   0.065895   2.5278  0.01182 *  \ndhtdsh      0.075982   0.072249   1.0517  0.29353    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Reproduce Table V using the coefficients in column(1) of Table IV ----\n\ndatachp4_2 &lt;- datachp4_2 %&gt;%\n  mutate(\n    wt = sqrt(mvshipsh),\n    apsh5 = apsh1 * wt,\n    ansh5 = ansh1 * wt,\n    aksh5 = aksh1 * wt,\n    narrout = dsimat1b * wt * coef(reg1)[\"dsimat1b\"],\n    diffout = dsimatd1 * wt * coef(reg1)[\"dsimatd1\"],\n    comsh = dofsh * wt * coef(reg1)[\"dofsh\"],\n    difcom = dhtdsh * wt * coef(reg1)[\"dhtdsh\"]\n  )\n\ndatachp4_2 %&gt;%\n  select(narrout:difcom) %&gt;%\n  summarise(\n    across(\n      everything(),\n      list(nobs = length, mean = mean, sd = sd, min = min, max = max)\n    )\n  ) %&gt;%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %&gt;%\n  separate_wider_delim(variable, \"_\", names = c(\"var\", \"stat\")) %&gt;%\n  pivot_wider(\n    names_from = stat,\n    values_from = value\n  )\n\n# A tibble: 4 × 6\n  var      nobs     mean       sd       min     max\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 narrout   447 0.000411 0.00128  -0.00777  0.0132 \n2 diffout   447 0.000555 0.00122  -0.00540  0.0157 \n3 comsh     447 0.00125  0.00214  -0.00285  0.0110 \n4 difcom    447 0.000404 0.000739 -0.000935 0.00643\n\nreg2 &lt;- lm(\n  narrout ~ apsh5 + ansh5 + aksh5 + 0,\n  data = datachp4_2\n)\n\nsummary(reg2)\n\n\nCall:\nlm(formula = narrout ~ apsh5 + ansh5 + aksh5 + 0, data = datachp4_2)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0083329 -0.0004728 -0.0002127  0.0000644  0.0119091 \n\nCoefficients:\n       Estimate Std. Error t value Pr(&gt;|t|)    \napsh5 -0.009516   0.009351  -1.018    0.309    \nansh5  0.098667   0.014774   6.678 7.25e-11 ***\naksh5  0.002638   0.003536   0.746    0.456    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.001161 on 444 degrees of freedom\nMultiple R-squared:  0.2611,    Adjusted R-squared:  0.2561 \nF-statistic: 52.29 on 3 and 444 DF,  p-value: &lt; 2.2e-16\n\nreg3 &lt;- lm(\n  diffout ~ apsh5 + ansh5 + aksh5 + 0,\n  data = datachp4_2\n)\n\nsummary(reg3)\n\n\nCall:\nlm(formula = diffout ~ apsh5 + ansh5 + aksh5 + 0, data = datachp4_2)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0063691 -0.0003192 -0.0000461  0.0003706  0.0133647 \n\nCoefficients:\n       Estimate Std. Error t value Pr(&gt;|t|)    \napsh5  0.020364   0.009476   2.149   0.0322 *  \nansh5  0.062848   0.014972   4.198 3.26e-05 ***\naksh5 -0.001140   0.003583  -0.318   0.7506    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.001177 on 444 degrees of freedom\nMultiple R-squared:  0.2317,    Adjusted R-squared:  0.2266 \nF-statistic: 44.65 on 3 and 444 DF,  p-value: &lt; 2.2e-16\n\nreg4 &lt;- lm(\n  comsh ~ apsh5 + ansh5 + aksh5 + 0,\n  data = datachp4_2\n)\n\nsummary(reg4)\n\n\nCall:\nlm(formula = comsh ~ apsh5 + ansh5 + aksh5 + 0, data = datachp4_2)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0051922 -0.0009209 -0.0003753  0.0007447  0.0074504 \n\nCoefficients:\n        Estimate Std. Error t value Pr(&gt;|t|)    \napsh5 -0.0049722  0.0140295  -0.354    0.723    \nansh5  0.2480142  0.0221662  11.189   &lt;2e-16 ***\naksh5  0.0007009  0.0053051   0.132    0.895    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.001742 on 444 degrees of freedom\nMultiple R-squared:  0.5086,    Adjusted R-squared:  0.5053 \nF-statistic: 153.2 on 3 and 444 DF,  p-value: &lt; 2.2e-16\n\nreg5 &lt;- lm(\n  difcom ~ apsh5 + ansh5 + aksh5 + 0,\n  data = datachp4_2\n)\n\nsummary(reg5)\n\n\nCall:\nlm(formula = difcom ~ apsh5 + ansh5 + aksh5 + 0, data = datachp4_2)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0025959 -0.0002751 -0.0000947  0.0001466  0.0058306 \n\nCoefficients:\n      Estimate Std. Error t value Pr(&gt;|t|)    \napsh5 0.025945   0.005624   4.613  5.2e-06 ***\nansh5 0.006921   0.008886   0.779   0.4364    \naksh5 0.004331   0.002127   2.036   0.0423 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0006985 on 444 degrees of freedom\nMultiple R-squared:  0.3149,    Adjusted R-squared:  0.3103 \nF-statistic: 68.02 on 3 and 444 DF,  p-value: &lt; 2.2e-16\n\n# Reproduce column (2) of Table IV ----\n\n## generating difference measure of outsourcing\n\ndatachp4 &lt;- datachp4 %&gt;%\n  mutate(dsimatd1 = dsimat1a - dsimat1b)\n\n## generate difference measure of high tech share with ex ante rental price\n\ndatachp4 &lt;- datachp4 %&gt;%\n  mutate(dhtdsh1 = dhtsh1 - dofsh1)\n\n## check whether we are using the right variable as described in table II\n\ndatachp4 %&gt;%\n  select(dsimatd1, dhtdsh1, dofsh1) %&gt;%\n  summarise(\n    across(\n      everything(),\n      list(nobs = length, min = min, max = max)\n    )\n  ) %&gt;%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %&gt;%\n  separate_wider_delim(variable, \"_\", names = c(\"var\", \"stat\")) %&gt;%\n  pivot_wider(\n    names_from = stat,\n    values_from = value\n  ) %&gt;%\n  left_join(\n    datachp4 %&gt;%\n      select(dsimatd1, dhtdsh1, dofsh1, mvshipsh) %&gt;%\n      mutate(across(c(dsimatd1, dhtdsh1, dofsh1), ~ . * mvshipsh)) %&gt;%\n      select(-mvshipsh) %&gt;%\n      summarise(across(everything(), list(wsum = sum))) %&gt;%\n      pivot_longer(\n        cols = everything(),\n        names_to = \"variable\",\n        values_to = \"value\"\n      ) %&gt;%\n      separate_wider_delim(variable, \"_\", names = c(\"var\", \"stat\")) %&gt;%\n      pivot_wider(\n        names_from = stat,\n        values_from = value\n      ) %&gt;%\n      rename(weighted_sum = wsum)\n  ) %&gt;%\n  left_join(\n    datachp4 %&gt;%\n      select(dsimatd1, dhtdsh1, dofsh1, mvshipsh) %&gt;%\n      pivot_longer(\n        cols = c(dsimatd1, dhtdsh1, dofsh1),\n        names_to = \"var\",\n        values_to = \"val\"\n      ) %&gt;%\n      group_by(var) %&gt;%\n      summarise(weighted_sd = weighted.sd(val, mvshipsh))\n  ) %&gt;%\n  bind_cols(\n    datachp4 %&gt;%\n      summarise(sum_weights = sum(mvshipsh))\n  )\n\n# A tibble: 3 × 7\n  var       nobs     min   max weighted_sum weighted_sd sum_weights\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 dsimatd1   447 -1.76   2.74        0.160        0.322       0.999\n2 dhtdsh1    447  0.0204 0.900       0.164        0.150       0.999\n3 dofsh1     447 -0.270  0.380       0.0534       0.124       0.999\n\n# regress t4dlpvad dsimat1b dsimatd1 dofsh1 dhtdsh1 [aw=mvshipsh], cluster(sic2)\n\nreg2 &lt;- lm(\n  t4dlpvad ~ dsimat1b + dsimatd1 + dofsh1 + dhtdsh1,\n  data = datachp4,\n  weights = datachp4$mvshipsh\n)\n\ncoeftest(reg2, vcov = vcovCL(reg2, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n             Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)  4.294261   0.038595 111.2650  &lt; 2e-16 ***\ndsimat1b     0.079517   0.034676   2.2931  0.02231 *  \ndsimatd1     0.113680   0.044020   2.5825  0.01013 *  \ndofsh1       0.192416   0.108362   1.7757  0.07647 .  \ndhtdsh1     -0.047795   0.082049  -0.5825  0.56052    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Reproduce column (3) of Table IV ----\n\n## generating difference measure of high tech share\n\ndatachp4 &lt;- datachp4 %&gt;%\n  mutate(dhtdsh = dhtsh - dofsh)\n\nreg3 &lt;- lm(\n  t4dlpvad ~ dsimat1b + dsimatd1 + ci + dhtsh,\n  data = datachp4,\n  weights = datachp4$mvshipsh\n)\n\ncoeftest(reg3, vcov = vcovCL(reg3, cluster = datachp4$sic2))\n\n\nt test of coefficients:\n\n             Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept) 4.2438613  0.0334856 126.7368  &lt; 2e-16 ***\ndsimat1b    0.0404060  0.0295213   1.3687  0.17179    \ndsimatd1    0.0351687  0.0488208   0.7204  0.47168    \nci          0.0081792  0.0045064   1.8150  0.07020 .  \ndhtsh       0.0930741  0.0496036   1.8764  0.06126 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "chapter5.html#documentation",
    "href": "chapter5.html#documentation",
    "title": "Chapter 5. Increasing Returns and the Gravity Equation",
    "section": "Documentation",
    "text": "Documentation\nUS-Canada data for Anderson and van Wincoop (2002)\nThere are a total of 63 US-Canada regions (states, District of Columbia, provinces and territories). They are listed below. The regressions, however, are based on the same 40 states and provinces as in McCallum (these are indicated with a star below).\n\n\n\nCode\nState/Province\n\n\n\n\n1\nAlabama*\n\n\n2\nAlaska\n\n\n3\nArizona*\n\n\n4\nArkansas\n\n\n5\nCalifornia*\n\n\n6\nColorado\n\n\n7\nConnecticut\n\n\n8\nDelaware\n\n\n9\nFlorida*\n\n\n10\nGeorgia*\n\n\n11\nHawaii\n\n\n12\nIdaho*\n\n\n13\nIllinois*\n\n\n14\nIndiana*\n\n\n15\nIowa\n\n\n16\nKansas\n\n\n17\nKentucky*\n\n\n18\nLouisiana*\n\n\n19\nMaine*\n\n\n20\nMaryland*\n\n\n21\nMassachusetts*\n\n\n22\nMichigan*\n\n\n23\nMinnesota*\n\n\n24\nMississippi\n\n\n25\nMissouri*\n\n\n26\nMontana*\n\n\n27\nNebraska\n\n\n28\nNevada\n\n\n29\nNew Hampshire*\n\n\n30\nNew Jersey*\n\n\n31\nNew Mexico\n\n\n32\nNew York*\n\n\n33\nNorth Carolina*\n\n\n34\nNorth Dakota*\n\n\n35\nOhio*\n\n\n36\nOklahoma\n\n\n37\nOregon\n\n\n38\nPennsylvania*\n\n\n39\nRhode Island\n\n\n40\nSouth Carolina\n\n\n41\nSouth Dakota\n\n\n42\nTennessee*\n\n\n43\nTexas*\n\n\n44\nUtah\n\n\n45\nVermont*\n\n\n46\nVirginia*\n\n\n47\nWashington*\n\n\n48\nWest Virginia\n\n\n49\nWisconsin*\n\n\n50\nWyoming\n\n\n51\nDist. of Col.\n\n\n52\nAlberta*\n\n\n53\nBritish Columbia*\n\n\n54\nManitoba*\n\n\n55\nNew Brunswick*\n\n\n56\nNewfoundland*\n\n\n57\nNW Territories\n\n\n58\nNova Scotia*\n\n\n59\nOntario*\n\n\n60\nPrince Edward Island*\n\n\n61\nQuebec*\n\n\n62\nSaskatchewan*\n\n\n63\nYukon Territory\n\n\n\nData files:\n\ndist.csv: Contains distances between the 40 regions listed above. The distances are in kilometers and are between the capitals of the regions.\ngdp_ce_93.csv and gdp_ci_93.csv: Contains nominal GDP in millions of Canadian dollars in 1993 for the 40 regions above.\ntrade_93.csv\n\nContains 1993 trade data between the 40 regions listed above, in US dollars. The indicator variables 1_ex and 1_im equal 1 if the exporter or importer is a US state, and 2 for a Canadian province."
  },
  {
    "objectID": "chapter5.html#empirical-exercise",
    "href": "chapter5.html#empirical-exercise",
    "title": "Chapter 5. Increasing Returns and the Gravity Equation",
    "section": "Empirical exercise",
    "text": "Empirical exercise\nIn this exercise, you are asked to reproduce the empirical results shown in Table 5.2. There are four datasets available: dist.csv which is distances; gdp_ce_93.csv which is GDP in exporting location in 1993; gdp_ci_93.csv which is GDP in importing location in 1993; and trade_93.csv which is trade in 1993. To complete the exercise, these files should be stored in the directory Chapter-5. After this, run the STATA program data_trans.do, which will convert these datasets to STATA files with the same name. The trade data is already converted into US dollars, but GDP data is in Canadian dollars, so this is converted with the exchange rate 1 Canadian dollar = 0.775134 U.S. dollars."
  },
  {
    "objectID": "chapter5.html#exercise-1",
    "href": "chapter5.html#exercise-1",
    "title": "Chapter 5. Increasing Returns and the Gravity Equation",
    "section": "Exercise 1",
    "text": "Exercise 1\nRun the program gravity_1.do to replicate the gravity equations in columns (1)-(3) of Table 5.2.\n\nFeenstra’s code\nData transformation:\n* Input data set into STATA and save as STATA file *\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\dist.csv\nsort c_e c_i\nsave Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\dist,replace\n\nclear\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\trade_93.csv\nsort c_e c_i\n\nmerge c_e c_i using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\dist\ndrop _merge\n\nsort c_e c_i\n\nsave Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\trade_93,replace\n\nclear\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ce_93.csv\ngen gce=gdp_ce*0.775134\ndrop gdp_ce\nren gce gdp_ce\nsort c_e\nsave Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ce_93,replace\n\nclear\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ci_93.csv\ngen gci=gdp_ci*0.775134\ndrop gdp_ci\nren gci gdp_ci\nsort c_i\nsave Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ci_93,replace\n\nclear\nModels:\ncapture log close\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gravity_1.log, replace\n\nset matsize 100\n\nuse Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\trade_93,clear\nsort c_e\nmerge c_e using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ce_93\ndrop _merge\nsort c_i\nmerge c_i using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ci_93\ndrop _merge\ndrop if vx==0\ndrop if dist==0\n\ngen lnvx=log(vx)\ngen lndist=log(dist)\ngen lngdp_ce=log(gdp_ce)\ngen lngdp_ci=log(gdp_ci)\n\n* Estimate Gravity Equation from the Canadian Perspective *\n\npreserve\ngen d_ca=0\nreplace d_ca=1 if (l_ex==2) & (l_im==2)\ndrop if (l_ex==1) & (l_im==1)\n\nregress lnvx lngdp_ce lngdp_ci lndist d_ca\nrestore\n\n* Estimate Gravity Equation from the U.S. Perspective *\n\npreserve\ngen d_us=0\nreplace d_us=1 if (l_ex==1) & (l_im==1)\ndrop if (l_ex==2) & (l_im==2)\n\nregress lnvx lngdp_ce lngdp_ci lndist d_us\nrestore\n\n* Estimate Gravity Equation by Pooling All Data *\n\npreserve\ngen d_ca=0\ngen d_us=0\nreplace d_ca=1 if (l_ex==2) & (l_im==2)\nreplace d_us=1 if (l_ex==1) & (l_im==1)\n\nregress lnvx lngdp_ce lngdp_ci lndist d_ca d_us\nvce\nrestore\n\nclear\n\nlog close\nOutput:\n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-5\\gravity_1.log, replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-5\\gravity_1.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-5\\gravity_1.log\n  log type:  text\n opened on:  19 Jun 2024, 13:34:35\n\n. \n. set matsize 100\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory           50M    max. data space                 50.000M\n    set matsize         100     max. RHS vars in models          0.085M\n                                                            -----------\n                                                                51.994M\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\tr\n&gt; ade_93,clear\n\n. sort c_e\n\n. merge c_e using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\\n&gt; Chapter-5\\gdp_ce_93\n(note: you are using old merge syntax; see [R] merge for new syntax)\nvariable c_e does not uniquely identify observations in the master data\n\n. drop _merge\n\n. sort c_i\n\n. merge c_i using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\\n&gt; Chapter-5\\gdp_ci_93\n(note: you are using old merge syntax; see [R] merge for new syntax)\nvariable c_i does not uniquely identify observations in the master data\n\n. drop _merge\n\n. drop if vx==0\n(49 observations deleted)\n\n. drop if dist==0\n(40 observations deleted)\n\n. \n. gen lnvx=log(vx)\n\n. gen lndist=log(dist)\n\n. gen lngdp_ce=log(gdp_ce)\n\n. gen lngdp_ci=log(gdp_ci)\n\n. \n. * Estimate Gravity Equation from the Canadian Perspective *\n. \n. preserve\n\n. gen d_ca=0\n\n. replace d_ca=1 if (l_ex==2) & (l_im==2)\n(90 real changes made)\n\n. drop if (l_ex==1) & (l_im==1)\n(832 observations deleted)\n\n. \n. regress lnvx lngdp_ce lngdp_ci lndist d_ca\n\n      Source |       SS       df       MS              Number of obs =     679\n-------------+------------------------------           F(  4,   674) =  540.02\n       Model |  3020.52204     4  755.130511           Prob &gt; F      =  0.0000\n    Residual |  942.471913   674  1.39832628           R-squared     =  0.7622\n-------------+------------------------------           Adj R-squared =  0.7608\n       Total |  3962.99396   678  5.84512383           Root MSE      =  1.1825\n\n------------------------------------------------------------------------------\n        lnvx |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n    lngdp_ce |   1.218705   .0331581    36.75   0.000       1.1536    1.283811\n    lngdp_ci |   .9797792   .0325254    30.12   0.000     .9159159    1.043642\n      lndist |  -1.353149   .0690128   -19.61   0.000    -1.488655   -1.217643\n        d_ca |   2.802034   .1416955    19.78   0.000     2.523816    3.080251\n       _cons |   3.742672   .7721966     4.85   0.000     2.226472    5.258873\n------------------------------------------------------------------------------\n\n. restore\n\n. \n. * Estimate Gravity Equation from the U.S. Perspective *\n. \n. preserve\n\n. gen d_us=0\n\n. replace d_us=1 if (l_ex==1) & (l_im==1)\n(832 real changes made)\n\n. drop if (l_ex==2) & (l_im==2)\n(90 observations deleted)\n\n. \n. regress lnvx lngdp_ce lngdp_ci lndist d_us\n\n      Source |       SS       df       MS              Number of obs =    1421\n-------------+------------------------------           F(  4,  1416) = 2052.61\n       Model |  7089.25392     4  1772.31348           Prob &gt; F      =  0.0000\n    Residual |  1222.63635  1416  .863443752           R-squared     =  0.8529\n-------------+------------------------------           Adj R-squared =  0.8525\n       Total |  8311.89028  1420  5.85344386           Root MSE      =  .92922\n\n------------------------------------------------------------------------------\n        lnvx |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n    lngdp_ce |   1.128429    .020453    55.17   0.000     1.088308     1.16855\n    lngdp_ci |   .9820314    .020396    48.15   0.000     .9420218    1.022041\n      lndist |  -1.081888    .035227   -30.71   0.000    -1.150991   -1.012785\n        d_us |   .4059649   .0578667     7.02   0.000     .2924511    .5194786\n       _cons |   2.659586   .4492747     5.92   0.000      1.77827    3.540901\n------------------------------------------------------------------------------\n\n. restore\n\n. \n. * Estimate Gravity Equation by Pooling All Data *\n. \n. preserve\n\n. gen d_ca=0\n\n. gen d_us=0\n\n. replace d_ca=1 if (l_ex==2) & (l_im==2)\n(90 real changes made)\n\n. replace d_us=1 if (l_ex==1) & (l_im==1)\n(832 real changes made)\n\n. \n. regress lnvx lngdp_ce lngdp_ci lndist d_ca d_us\n\n      Source |       SS       df       MS              Number of obs =    1511\n-------------+------------------------------           F(  5,  1505) = 1732.75\n       Model |  7499.70876     5  1499.94175           Prob &gt; F      =  0.0000\n    Residual |  1302.79013  1505  .865641282           R-squared     =  0.8520\n-------------+------------------------------           Adj R-squared =  0.8515\n       Total |  8802.49889  1510  5.82946946           Root MSE      =   .9304\n\n------------------------------------------------------------------------------\n        lnvx |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n    lngdp_ce |   1.132974   .0196797    57.57   0.000     1.094371    1.171577\n    lngdp_ci |   .9742161   .0196294    49.63   0.000     .9357122     1.01272\n      lndist |  -1.110705   .0337347   -32.92   0.000    -1.176877   -1.044533\n        d_ca |   2.751708   .1086755    25.32   0.000     2.538536    2.964879\n        d_us |   .3982716   .0574423     6.93   0.000     .2855962    .5109471\n       _cons |   2.911512   .4267171     6.82   0.000     2.074488    3.748535\n------------------------------------------------------------------------------\n\n. vce\n\nCovariance matrix of coefficients of regress model\n\n        e(V) |   lngdp_ce    lngdp_ci      lndist        d_ca        d_us \n-------------+------------------------------------------------------------\n    lngdp_ce |  .00038729                                                 \n    lngdp_ci |  .00008279   .00038531                                     \n      lndist |  .00001868   .00001752   .00113803                         \n        d_ca |  .00041241   .00040103   .00017043   .01181037             \n        d_us | -.00037488  -.00039315   .00039698   .00085625   .00329962 \n       _cons | -.00524428  -.00520461   -.0089485  -.01157481   .00387661 \n\n        e(V) |      _cons \n-------------+------------\n       _cons |  .18208752 \n\n. restore\n\n. \n. clear\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-5\\gravity_1.log\n  log type:  text\n closed on:  19 Jun 2024, 13:34:38\n----------------------------------------------------------------------------------\n\n. \n. \n. \n. \nend of do-file\n\n\nMy code\n\n# Packages ----\n\nlibrary(archive)\nlibrary(readr)\nlibrary(janitor)\nlibrary(dplyr)\n\n# Extract ----\n\nfzip &lt;- \"first-edition/Chapter-5.zip\"\ndout &lt;- gsub(\"\\\\.zip$\", \"\", fzip)\n\nif (!dir.exists(dout)) {\n  archive_extract(fzip, dir = dout)\n}\n\n# Read and transform ----\n\nfout &lt;- paste0(dout, \"/trade_93.rds\")\n\nif (!file.exists(fout)) {\n  # trade_93 &lt;- read_dta(paste0(dout, \"/trade_93.dta\"))\n  # gdp_ce_93 &lt;- read_dta(paste0(dout, \"/gdp_ce_93.dta\"))\n  # gdp_ci_93 &lt;- read_dta(paste0(dout, \"/gdp_ci_93.dta\"))\n\n  # instead of reading the DTA files, I will read the CSV files and transform\n\n  dist &lt;- read_csv(paste0(dout, \"/dist.csv\")) %&gt;%\n    clean_names() %&gt;%\n    arrange(c_e, c_i)\n\n  trade_93 &lt;- read_csv(paste0(dout, \"/trade_93.csv\")) %&gt;%\n    clean_names() %&gt;%\n    arrange(c_e, c_i)\n\n  trade_93 &lt;- trade_93 %&gt;%\n    left_join(dist, by = c(\"c_e\", \"c_i\"))\n\n  rm(dist)\n\n  gdp_ce_93 &lt;- read_csv(paste0(dout, \"/gdp_ce_93.csv\")) %&gt;%\n    clean_names() %&gt;%\n    mutate(gdp_ce = gdp_ce * 0.775134) %&gt;%\n    arrange(c_e)\n\n  gdp_ci_93 &lt;- read_csv(paste0(dout, \"/gdp_ci_93.csv\")) %&gt;%\n    clean_names() %&gt;%\n    mutate(gdp_ci = gdp_ci * 0.775134) %&gt;%\n    arrange(c_i)\n\n  trade_93 &lt;- trade_93 %&gt;%\n    left_join(gdp_ce_93, by = \"c_e\") %&gt;%\n    left_join(gdp_ci_93, by = \"c_i\") %&gt;%\n    filter(vx != 0, dist != 0) %&gt;%\n    mutate(\n      lnvx = log(vx),\n      lndist = log(dist),\n      lngdp_ce = log(gdp_ce),\n      lngdp_ci = log(gdp_ci)\n    )\n\n  saveRDS(trade_93, fout)\n} else {\n  trade_93 &lt;- readRDS(fout)\n}\n\n# Estimate Gravity Equation from the Canadian Perspective ----\n\ntrade_93_2 &lt;- trade_93 %&gt;%\n  mutate(d_ca = ifelse(l_ex == 2 & l_im == 2, 1, 0)) %&gt;%\n  filter(l_ex != 1 | l_im != 1)\n\nfit_ca &lt;- lm(lnvx ~ lngdp_ce + lngdp_ci + lndist + d_ca, data = trade_93_2)\n\nsummary(fit_ca)\n\n\nCall:\nlm(formula = lnvx ~ lngdp_ce + lngdp_ci + lndist + d_ca, data = trade_93_2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9344 -0.6428  0.0174  0.6225  4.0379 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.74267    0.77220   4.847 1.56e-06 ***\nlngdp_ce     1.21871    0.03316  36.754  &lt; 2e-16 ***\nlngdp_ci     0.97978    0.03253  30.124  &lt; 2e-16 ***\nlndist      -1.35315    0.06901 -19.607  &lt; 2e-16 ***\nd_ca         2.80203    0.14170  19.775  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.183 on 674 degrees of freedom\nMultiple R-squared:  0.7622,    Adjusted R-squared:  0.7608 \nF-statistic:   540 on 4 and 674 DF,  p-value: &lt; 2.2e-16\n\n# Estimate Gravity Equation from the U.S. Perspective ----\n\ntrade_93_3 &lt;- trade_93 %&gt;%\n  mutate(d_us = ifelse(l_ex == 1 & l_im == 1, 1, 0)) %&gt;%\n  filter(l_ex != 2 | l_im != 2)\n\nfit_us &lt;- lm(lnvx ~ lngdp_ce + lngdp_ci + lndist + d_us, data = trade_93_3)\n\nsummary(fit_us)\n\n\nCall:\nlm(formula = lnvx ~ lngdp_ce + lngdp_ci + lndist + d_us, data = trade_93_3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.2863 -0.4620 -0.0077  0.4822  3.7858 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.65959    0.44927   5.920 4.04e-09 ***\nlngdp_ce     1.12843    0.02045  55.172  &lt; 2e-16 ***\nlngdp_ci     0.98203    0.02040  48.148  &lt; 2e-16 ***\nlndist      -1.08189    0.03523 -30.712  &lt; 2e-16 ***\nd_us         0.40597    0.05787   7.016 3.54e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9292 on 1416 degrees of freedom\nMultiple R-squared:  0.8529,    Adjusted R-squared:  0.8525 \nF-statistic:  2053 on 4 and 1416 DF,  p-value: &lt; 2.2e-16\n\n# Estimate Gravity Equation by Pooling All Data ----\n\ntrade_93_4 &lt;- trade_93 %&gt;%\n  mutate(\n    d_ca = ifelse(l_ex == 2 & l_im == 2, 1, 0),\n    d_us = ifelse(l_ex == 1 & l_im == 1, 1, 0)\n  )\n\nfit_all &lt;- lm(\n  lnvx ~ lngdp_ce + lngdp_ci + lndist + d_ca + d_us,\n  data = trade_93_4\n)\n\nsummary(fit_all)\n\n\nCall:\nlm(formula = lnvx ~ lngdp_ce + lngdp_ci + lndist + d_ca + d_us, \n    data = trade_93_4)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.2531 -0.4630 -0.0099  0.4902  3.8101 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.91151    0.42672   6.823 1.29e-11 ***\nlngdp_ce     1.13297    0.01968  57.571  &lt; 2e-16 ***\nlngdp_ci     0.97422    0.01963  49.630  &lt; 2e-16 ***\nlndist      -1.11070    0.03373 -32.925  &lt; 2e-16 ***\nd_ca         2.75171    0.10868  25.320  &lt; 2e-16 ***\nd_us         0.39827    0.05744   6.933 6.08e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9304 on 1505 degrees of freedom\nMultiple R-squared:  0.852, Adjusted R-squared:  0.8515 \nF-statistic:  1733 on 5 and 1505 DF,  p-value: &lt; 2.2e-16\n\nvcov(fit_all)\n\n             (Intercept)      lngdp_ce      lngdp_ci        lndist\n(Intercept)  0.182087515 -5.244280e-03 -5.204609e-03 -8.948498e-03\nlngdp_ce    -0.005244280  3.872922e-04  8.278679e-05  1.867887e-05\nlngdp_ci    -0.005204609  8.278679e-05  3.853139e-04  1.752375e-05\nlndist      -0.008948498  1.867887e-05  1.752375e-05  1.138030e-03\nd_ca        -0.011574809  4.124081e-04  4.010346e-04  1.704325e-04\nd_us         0.003876605 -3.748832e-04 -3.931548e-04  3.969829e-04\n                     d_ca          d_us\n(Intercept) -0.0115748090  0.0038766051\nlngdp_ce     0.0004124081 -0.0003748832\nlngdp_ci     0.0004010346 -0.0003931548\nlndist       0.0001704325  0.0003969829\nd_ca         0.0118103647  0.0008562509\nd_us         0.0008562509  0.0032996176"
  },
  {
    "objectID": "chapter5.html#exercise-2",
    "href": "chapter5.html#exercise-2",
    "title": "Chapter 5. Increasing Returns and the Gravity Equation",
    "section": "Exercise 2",
    "text": "Exercise 2\nRun the program gravity_2.do to replicate gravity equation using fixed-effects, i.e., column (5) in Table 5.2. Then answer:\n\nHow are these results affected if we allow the provincial and state GDP’s to have coefficients different from unity?\nWhat coefficients are obtained if we introduce separate indicator variables for intra-Canadian and intra-U.S. trade, rather than the border dummy?\n\n\nFeenstra’s code\ncapture log close\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gravity_2.log, replace\n\nset matsize 100\n\nuse Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\trade_93,clear\nsort c_e\nmerge c_e using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ce_93\ndrop _merge\nsort c_i\nmerge c_i using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\gdp_ci_93\ndrop _merge\ndrop if vx==0\ndrop if dist==0\n\ntab c_e, gen (ced)\ntab c_i, gen (cid)\n\ngen d_border=1\nreplace d_border=0 if (l_ex==1) & (l_im==1)\nreplace d_border=0 if (l_ex==2) & (l_im==2)\n\ngen lnvx=log(vx)\ngen lndist=log(dist)\ngen lngdp_ce=log(gdp_ce)\ngen lngdp_ci=log(gdp_ci)\ngen lnn_vx=lnvx-lngdp_ce-lngdp_ci\n\nregress lnn_vx lndist d_border ced* cid*\n\nclear\nlog close\nOutput:\n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-5\\gravity_2.log, replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-5\\gravity_2.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-5\\gravity_2.log\n  log type:  text\n opened on:  19 Jun 2024, 13:41:01\n\n. \n. set matsize 100\n\nCurrent memory allocation\n\n                    current                                 memory usage\n    settable          value     description                 (1M = 1024k)\n    --------------------------------------------------------------------\n    set maxvar         5000     max. variables allowed           1.909M\n    set memory           50M    max. data space                 50.000M\n    set matsize         100     max. RHS vars in models          0.085M\n                                                            -----------\n                                                                51.994M\n\n. \n. use Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-5\\tr\n&gt; ade_93,clear\n\n. sort c_e\n\n. merge c_e using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\\n&gt; Chapter-5\\gdp_ce_93\n(note: you are using old merge syntax; see [R] merge for new syntax)\nvariable c_e does not uniquely identify observations in the master data\n\n. drop _merge\n\n. sort c_i\n\n. merge c_i using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\\n&gt; Chapter-5\\gdp_ci_93\n(note: you are using old merge syntax; see [R] merge for new syntax)\nvariable c_i does not uniquely identify observations in the master data\n\n. drop _merge\n\n. drop if vx==0\n(49 observations deleted)\n\n. drop if dist==0\n(40 observations deleted)\n\n. \n. tab c_e, gen (ced)\n\n        c_e |      Freq.     Percent        Cum.\n------------+-----------------------------------\n         AB |         39        2.58        2.58\n        Ala |         38        2.51        5.10\n        Ari |         37        2.45        7.54\n         BC |         39        2.58       10.13\n        Cal |         37        2.45       12.57\n        Flo |         39        2.58       15.16\n        Geo |         39        2.58       17.74\n        Ida |         36        2.38       20.12\n        Ill |         39        2.58       22.70\n        Ind |         38        2.51       25.22\n        Ken |         37        2.45       27.66\n        Lou |         36        2.38       30.05\n         MN |         39        2.58       32.63\n         MO |         37        2.45       35.08\n        Mai |         37        2.45       37.52\n        Mas |         39        2.58       40.11\n        Mic |         37        2.45       42.55\n        Min |         38        2.51       45.07\n        Mon |         36        2.38       47.45\n        Mry |         37        2.45       49.90\n         NB |         39        2.58       52.48\n        NHm |         38        2.51       55.00\n        NJr |         39        2.58       57.58\n         NS |         39        2.58       60.16\n        Nca |         39        2.58       62.74\n        Nda |         36        2.38       65.12\n       Nfld |         35        2.32       67.44\n        Nyr |         39        2.58       70.02\n         ON |         39        2.58       72.60\n        Ohi |         37        2.45       75.05\n        PEI |         34        2.25       77.30\n        Pen |         39        2.58       79.88\n        Que |         39        2.58       82.46\n         SK |         39        2.58       85.04\n        Ten |         38        2.51       87.56\n        Tex |         37        2.45       90.01\n        Ver |         37        2.45       92.46\n        Vir |         39        2.58       95.04\n        Was |         36        2.38       97.42\n        Wis |         39        2.58      100.00\n------------+-----------------------------------\n      Total |      1,511      100.00\n\n. tab c_i, gen (cid)\n\n        c_I |      Freq.     Percent        Cum.\n------------+-----------------------------------\n         AB |         39        2.58        2.58\n        Ala |         38        2.51        5.10\n        Ari |         36        2.38        7.48\n         BC |         39        2.58       10.06\n        Cal |         39        2.58       12.64\n        Flo |         39        2.58       15.22\n        Geo |         39        2.58       17.80\n        Ida |         33        2.18       19.99\n        Ill |         39        2.58       22.57\n        Ind |         39        2.58       25.15\n        Ken |         37        2.45       27.60\n        Lou |         36        2.38       29.98\n         MN |         39        2.58       32.56\n         MO |         39        2.58       35.14\n        Mai |         36        2.38       37.52\n        Mas |         37        2.45       39.97\n        Mic |         39        2.58       42.55\n        Min |         39        2.58       45.14\n        Mon |         34        2.25       47.39\n        Mry |         39        2.58       49.97\n         NB |         39        2.58       52.55\n        NHm |         38        2.51       55.06\n        NJr |         39        2.58       57.64\n         NS |         39        2.58       60.23\n        Nca |         39        2.58       62.81\n        Nda |         31        2.05       64.86\n       Nfld |         38        2.51       67.37\n        Nyr |         37        2.45       69.82\n         ON |         39        2.58       72.40\n        Ohi |         38        2.51       74.92\n        PEI |         38        2.51       77.43\n        Pen |         38        2.51       79.95\n        Que |         39        2.58       82.53\n         SK |         39        2.58       85.11\n        Ten |         39        2.58       87.69\n        Tex |         39        2.58       90.27\n        Ver |         33        2.18       92.46\n        Vir |         38        2.51       94.97\n        Was |         37        2.45       97.42\n        Wis |         39        2.58      100.00\n------------+-----------------------------------\n      Total |      1,511      100.00\n\n. \n. gen d_border=1\n\n. replace d_border=0 if (l_ex==1) & (l_im==1)\n(832 real changes made)\n\n. replace d_border=0 if (l_ex==2) & (l_im==2)\n(90 real changes made)\n\n. \n. gen lnvx=log(vx)\n\n. gen lndist=log(dist)\n\n. gen lngdp_ce=log(gdp_ce)\n\n. gen lngdp_ci=log(gdp_ci)\n\n. gen lnn_vx=lnvx-lngdp_ce-lngdp_ci\n\n. \n. regress lnn_vx lndist d_border ced* cid*\nnote: ced39 omitted because of collinearity\nnote: cid37 omitted because of collinearity\n\n      Source |       SS       df       MS              Number of obs =    1511\n-------------+------------------------------           F( 80,  1430) =   35.32\n       Model |  1998.34711    80  24.9793388           Prob &gt; F      =  0.0000\n    Residual |   1011.4731  1430  .707323845           R-squared     =  0.6639\n-------------+------------------------------           Adj R-squared =  0.6451\n       Total |   3009.8202  1510  1.99325841           Root MSE      =  .84103\n\n------------------------------------------------------------------------------\n      lnn_vx |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      lndist |  -1.251681   .0368191   -34.00   0.000    -1.323906   -1.179456\n    d_border |  -1.550514   .0588941   -26.33   0.000    -1.666042   -1.434986\n        ced1 |   1.575054   .1969728     8.00   0.000     1.188667    1.961441\n        ced2 |  -.0615169   .1968394    -0.31   0.755    -.4476419    .3246082\n        ced3 |  -.2180008   .1971536    -1.11   0.269     -.604742    .1687405\n        ced4 |   1.373042   .1968679     6.97   0.000     .9868611    1.759223\n        ced5 |   .3855025    .197204     1.95   0.051    -.0013377    .7723426\n        ced6 |  -.7112586   .1952711    -3.64   0.000    -1.094307   -.3282102\n        ced7 |   -.068018   .1960215    -0.35   0.729    -.4525384    .3165025\n        ced8 |     .26858   .1986056     1.35   0.176    -.1210097    .6581697\n        ced9 |   .2175036   .1965116     1.11   0.269    -.1679784    .6029856\n       ced10 |  -.0031177   .1983064    -0.02   0.987    -.3921204    .3858849\n       ced11 |   .1779582   .1996637     0.89   0.373     -.213707    .5696233\n       ced12 |  -.2567707   .1990797    -1.29   0.197    -.6472903    .1337489\n       ced13 |   1.044481   .1978236     5.28   0.000     .6564256    1.432537\n       ced14 |   .1701477   .1984997     0.86   0.391    -.2192341    .5595295\n       ced15 |  -.1910339   .1989122    -0.96   0.337    -.5812249    .1991571\n       ced16 |  -.3029544   .1964512    -1.54   0.123     -.688318    .0824091\n       ced17 |  -.0113933   .1994526    -0.06   0.954    -.4026443    .3798577\n       ced18 |   .3979938   .1970337     2.02   0.044     .0114877    .7844999\n       ced19 |  -.3888902   .1986962    -1.96   0.051    -.7786574     .000877\n       ced20 |  -.3808243   .1996346    -1.91   0.057    -.7724324    .0107838\n       ced21 |   .4754037   .1983009     2.40   0.017     .0864117    .8643956\n       ced22 |  -.3342633   .1979945    -1.69   0.092    -.7226541    .0541276\n       ced23 |  -.2890499   .1967737    -1.47   0.142    -.6750459    .0969461\n       ced24 |   .7414483   .1978522     3.75   0.000     .3533366     1.12956\n       ced25 |   .0208998   .1962026     0.11   0.915    -.3639759    .4057755\n       ced26 |  -.2802188   .1992561    -1.41   0.160    -.6710844    .1106468\n       ced27 |  -.2037673   .2019207    -1.01   0.313    -.5998598    .1923251\n       ced28 |   -.886426   .1967576    -4.51   0.000     -1.27239   -.5004615\n       ced29 |   .9150161   .1997198     4.58   0.000     .5232408    1.306791\n       ced30 |   .1505522   .1996938     0.75   0.451    -.2411719    .5422764\n       ced31 |   .0338336    .204322     0.17   0.869    -.3669694    .4346365\n       ced32 |  -.2727766   .1970444    -1.38   0.166    -.6593036    .1137504\n       ced33 |   1.116763   .1987298     5.62   0.000       .72693    1.506596\n       ced34 |   .8830361    .197432     4.47   0.000     .4957487    1.270324\n       ced35 |   .2703462   .1977387     1.37   0.172    -.1175428    .6582352\n       ced36 |   .0104498   .1972876     0.05   0.958    -.3765544     .397454\n       ced37 |  -.4834816   .1993893    -2.42   0.015    -.8746085   -.0923547\n       ced38 |  -.7100399   .1965941    -3.61   0.000    -1.095684   -.3243962\n       ced39 |  (omitted)\n       ced40 |    .198035   .1963542     1.01   0.313    -.1871383    .5832082\n        cid1 |   1.680152   .2029079     8.28   0.000     1.282123    2.078181\n        cid2 |  -.1178891   .2007464    -0.59   0.557    -.5116781    .2758998\n        cid3 |   .3834953   .2058763     1.86   0.063    -.0203566    .7873472\n        cid4 |   1.526394   .2034908     7.50   0.000     1.127221    1.925566\n        cid5 |   .6636691   .2025088     3.28   0.001      .266423    1.060915\n        cid6 |    .123873   .1998081     0.62   0.535    -.2680755    .5158215\n        cid7 |   .1817594   .1993881     0.91   0.362    -.2093651    .5728839\n        cid8 |   .2205046   .2089568     1.06   0.291    -.1893901    .6303994\n        cid9 |   .2764433   .1992735     1.39   0.166    -.1144564    .6673429\n       cid10 |   .1159431   .1992318     0.58   0.561    -.2748747     .506761\n       cid11 |   .1272816   .2017003     0.63   0.528    -.2683786    .5229418\n       cid12 |   .1406299   .2038587     0.69   0.490    -.2592642     .540524\n       cid13 |    1.46582   .2017388     7.27   0.000     1.070084    1.861556\n       cid14 |  -.0078626   .1993992    -0.04   0.969    -.3990089    .3832838\n       cid15 |    .364058    .203114     1.79   0.073    -.0343753    .7624914\n       cid16 |   .1078348   .2018047     0.53   0.593    -.2880302    .5036999\n       cid17 |   .2382488   .1991692     1.20   0.232    -.1524464    .6289439\n       cid18 |    .230515   .1994864     1.16   0.248    -.1608024    .6218323\n       cid19 |   .5098527   .2072802     2.46   0.014     .1032468    .9164585\n       cid20 |  -.3389257   .1992385    -1.70   0.089    -.7297569    .0519054\n       cid21 |   1.754684   .2015199     8.71   0.000     1.359378    2.149991\n       cid22 |   .0106125   .2004059     0.05   0.958    -.3825087    .4037336\n       cid23 |  -.0698658    .199243    -0.35   0.726    -.4607058    .3209742\n       cid24 |   .9934234   .2017215     4.92   0.000     .5977216    1.389125\n       cid25 |  -.0952417   .1993355    -0.48   0.633    -.4862632    .2957797\n       cid26 |   .3526411   .2113739     1.67   0.095     -.061995    .7672773\n       cid27 |   1.892756   .2044776     9.26   0.000     1.491648    2.293864\n       cid28 |  -.3546606   .2017692    -1.76   0.079    -.7504559    .0411347\n       cid29 |   1.177096   .2013695     5.85   0.000     .7820845    1.572107\n       cid30 |   .1004037   .2004709     0.50   0.617    -.2928449    .4936523\n       cid31 |   1.255257   .2028449     6.19   0.000     .8573513    1.653162\n       cid32 |    .142753   .2003897     0.71   0.476    -.2503363    .5358422\n       cid33 |   1.354079   .2014154     6.72   0.000     .9589778    1.749181\n       cid34 |   1.397366   .2020603     6.92   0.000        1.001    1.793733\n       cid35 |   .1029397    .199289     0.52   0.606    -.2879904    .4938697\n       cid36 |   .6433019    .200675     3.21   0.001      .249653    1.036951\n       cid37 |  (omitted)\n       cid38 |  -.3321485   .2004144    -1.66   0.098    -.7252863    .0609892\n       cid39 |   .8115608   .2044609     3.97   0.000     .4104853    1.212636\n       cid40 |   .2613272   .1993011     1.31   0.190    -.1296268    .6522811\n       _cons |   5.531002   .3406908    16.23   0.000     4.862695     6.19931\n------------------------------------------------------------------------------\n\n. \n. clear\n\n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-5\\gravity_2.log\n  log type:  text\n closed on:  19 Jun 2024, 13:41:11\n----------------------------------------------------------------------------------\n\n. \nend of do-file\n\n\nMy code\n\ntrade_93 &lt;- readRDS(paste0(dout, \"/trade_93.rds\"))\n\ntrade_93 %&gt;%\n  group_by(c_e) %&gt;%\n  summarise(freq = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    percent = freq / sum(freq) * 100,\n    cum = cumsum(percent)\n  )\n\n# A tibble: 40 × 4\n   c_e    freq percent   cum\n   &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 AB       39    2.58  2.58\n 2 Ala      38    2.51  5.10\n 3 Ari      37    2.45  7.54\n 4 BC       39    2.58 10.1 \n 5 Cal      37    2.45 12.6 \n 6 Flo      39    2.58 15.2 \n 7 Geo      39    2.58 17.7 \n 8 Ida      36    2.38 20.1 \n 9 Ill      39    2.58 22.7 \n10 Ind      38    2.51 25.2 \n# ℹ 30 more rows\n\ntrade_93 %&gt;%\n  group_by(c_i) %&gt;%\n  summarise(freq = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    percent = freq / sum(freq) * 100,\n    cum = cumsum(percent)\n  )\n\n# A tibble: 40 × 4\n   c_i    freq percent   cum\n   &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 AB       39    2.58  2.58\n 2 Ala      38    2.51  5.10\n 3 Ari      36    2.38  7.48\n 4 BC       39    2.58 10.1 \n 5 Cal      39    2.58 12.6 \n 6 Flo      39    2.58 15.2 \n 7 Geo      39    2.58 17.8 \n 8 Ida      33    2.18 20.0 \n 9 Ill      39    2.58 22.6 \n10 Ind      39    2.58 25.1 \n# ℹ 30 more rows\n\ntrade_93 &lt;- trade_93 %&gt;%\n  mutate(\n    d_border = case_when(\n      l_ex == 1 & l_im == 1 ~ 0,\n      l_ex == 2 & l_im == 2 ~ 0,\n      TRUE ~ 1\n    ),\n    lnvx = log(vx),\n    lndist = log(dist),\n    lngdp_ce = log(gdp_ce),\n    lngdp_ci = log(gdp_ci),\n    lnn_vx = lnvx - lngdp_ce - lngdp_ci\n  )\n\n# some of the FEs are dropped in Stata\n# the slopes are identical, which is what matters\n\nfit_fe &lt;- lm(\n  lnn_vx ~ lndist + d_border + as.factor(c_e) + as.factor(c_i),\n  data = trade_93\n)\n\nsummary(fit_fe)\n\n\nCall:\nlm(formula = lnn_vx ~ lndist + d_border + as.factor(c_e) + as.factor(c_i), \n    data = trade_93)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1033 -0.3934 -0.0101  0.3892  4.3379 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         8.78621    0.35661  24.638  &lt; 2e-16 ***\nlndist             -1.25168    0.03682 -33.995  &lt; 2e-16 ***\nd_border           -1.55051    0.05889 -26.327  &lt; 2e-16 ***\nas.factor(c_e)Ala  -1.63657    0.19473  -8.404  &lt; 2e-16 ***\nas.factor(c_e)Ari  -1.79305    0.19567  -9.164  &lt; 2e-16 ***\nas.factor(c_e)BC   -0.20201    0.19057  -1.060 0.289297    \nas.factor(c_e)Cal  -1.18955    0.19584  -6.074 1.59e-09 ***\nas.factor(c_e)Flo  -2.28631    0.19321 -11.833  &lt; 2e-16 ***\nas.factor(c_e)Geo  -1.64307    0.19371  -8.482  &lt; 2e-16 ***\nas.factor(c_e)Ida  -1.30647    0.19686  -6.636 4.55e-11 ***\nas.factor(c_e)Ill  -1.35755    0.19407  -6.995 4.06e-12 ***\nas.factor(c_e)Ind  -1.57817    0.19573  -8.063 1.56e-15 ***\nas.factor(c_e)Ken  -1.39710    0.19705  -7.090 2.10e-12 ***\nas.factor(c_e)Lou  -1.83182    0.19702  -9.298  &lt; 2e-16 ***\nas.factor(c_e)Mai  -1.76609    0.19648  -8.989  &lt; 2e-16 ***\nas.factor(c_e)Mas  -1.87801    0.19402  -9.679  &lt; 2e-16 ***\nas.factor(c_e)Mic  -1.58645    0.19688  -8.058 1.62e-15 ***\nas.factor(c_e)Min  -1.17706    0.19477  -6.043 1.92e-09 ***\nas.factor(c_e)MN   -0.53057    0.19094  -2.779 0.005528 ** \nas.factor(c_e)MO   -1.40491    0.19627  -7.158 1.31e-12 ***\nas.factor(c_e)Mon  -1.96394    0.19711  -9.964  &lt; 2e-16 ***\nas.factor(c_e)Mry  -1.95588    0.19703  -9.927  &lt; 2e-16 ***\nas.factor(c_e)NB   -1.09965    0.19128  -5.749 1.10e-08 ***\nas.factor(c_e)Nca  -1.55415    0.19384  -8.018 2.22e-15 ***\nas.factor(c_e)Nda  -1.85527    0.19711  -9.412  &lt; 2e-16 ***\nas.factor(c_e)Nfld -1.77882    0.19609  -9.071  &lt; 2e-16 ***\nas.factor(c_e)NHm  -1.90932    0.19548  -9.767  &lt; 2e-16 ***\nas.factor(c_e)NJr  -1.86410    0.19427  -9.595  &lt; 2e-16 ***\nas.factor(c_e)NS   -0.83361    0.19096  -4.365 1.36e-05 ***\nas.factor(c_e)Nyr  -2.46148    0.19431 -12.668  &lt; 2e-16 ***\nas.factor(c_e)Ohi  -1.42450    0.19713  -7.226 8.06e-13 ***\nas.factor(c_e)ON   -0.66004    0.19239  -3.431 0.000619 ***\nas.factor(c_e)PEI  -1.54122    0.19807  -7.781 1.37e-14 ***\nas.factor(c_e)Pen  -1.84783    0.19448  -9.501  &lt; 2e-16 ***\nas.factor(c_e)Que  -0.45829    0.19160  -2.392 0.016889 *  \nas.factor(c_e)SK   -0.69202    0.19069  -3.629 0.000295 ***\nas.factor(c_e)Ten  -1.30471    0.19528  -6.681 3.39e-11 ***\nas.factor(c_e)Tex  -1.56460    0.19550  -8.003 2.49e-15 ***\nas.factor(c_e)Ver  -2.05854    0.19683 -10.458  &lt; 2e-16 ***\nas.factor(c_e)Vir  -2.28509    0.19413 -11.771  &lt; 2e-16 ***\nas.factor(c_e)Was  -1.57505    0.19697  -7.996 2.62e-15 ***\nas.factor(c_e)Wis  -1.37702    0.19395  -7.100 1.96e-12 ***\nas.factor(c_i)Ala  -1.79804    0.19474  -9.233  &lt; 2e-16 ***\nas.factor(c_i)Ari  -1.29666    0.19730  -6.572 6.94e-11 ***\nas.factor(c_i)BC   -0.15376    0.19057  -0.807 0.419890    \nas.factor(c_i)Cal  -1.01648    0.19331  -5.258 1.68e-07 ***\nas.factor(c_i)Flo  -1.55628    0.19321  -8.055 1.66e-15 ***\nas.factor(c_i)Geo  -1.49839    0.19371  -7.735 1.94e-14 ***\nas.factor(c_i)Ida  -1.45965    0.20150  -7.244 7.09e-13 ***\nas.factor(c_i)Ill  -1.40371    0.19407  -7.233 7.68e-13 ***\nas.factor(c_i)Ind  -1.56421    0.19444  -8.045 1.80e-15 ***\nas.factor(c_i)Ken  -1.55287    0.19713  -7.877 6.58e-15 ***\nas.factor(c_i)Lou  -1.53952    0.19714  -7.809 1.11e-14 ***\nas.factor(c_i)Mai  -1.31609    0.19785  -6.652 4.11e-11 ***\nas.factor(c_i)Mas  -1.57232    0.19662  -7.997 2.61e-15 ***\nas.factor(c_i)Mic  -1.44190    0.19428  -7.422 1.98e-13 ***\nas.factor(c_i)Min  -1.44964    0.19353  -7.490 1.20e-13 ***\nas.factor(c_i)MN   -0.21433    0.19094  -1.123 0.261830    \nas.factor(c_i)MO   -1.68801    0.19369  -8.715  &lt; 2e-16 ***\nas.factor(c_i)Mon  -1.17030    0.20007  -5.849 6.11e-09 ***\nas.factor(c_i)Mry  -2.01908    0.19434 -10.389  &lt; 2e-16 ***\nas.factor(c_i)NB    0.07453    0.19128   0.390 0.696846    \nas.factor(c_i)Nca  -1.77539    0.19384  -9.159  &lt; 2e-16 ***\nas.factor(c_i)Nda  -1.32751    0.20530  -6.466 1.37e-10 ***\nas.factor(c_i)Nfld  0.21260    0.19185   1.108 0.267961    \nas.factor(c_i)NHm  -1.66954    0.19550  -8.540  &lt; 2e-16 ***\nas.factor(c_i)NJr  -1.75002    0.19427  -9.008  &lt; 2e-16 ***\nas.factor(c_i)NS   -0.68673    0.19096  -3.596 0.000334 ***\nas.factor(c_i)Nyr  -2.03481    0.19697 -10.330  &lt; 2e-16 ***\nas.factor(c_i)Ohi  -1.57975    0.19582  -8.067 1.51e-15 ***\nas.factor(c_i)ON   -0.50306    0.19239  -2.615 0.009024 ** \nas.factor(c_i)PEI  -0.42490    0.19218  -2.211 0.027200 *  \nas.factor(c_i)Pen  -1.53740    0.19580  -7.852 7.98e-15 ***\nas.factor(c_i)Que  -0.32607    0.19160  -1.702 0.089003 .  \nas.factor(c_i)SK   -0.28279    0.19069  -1.483 0.138315    \nas.factor(c_i)Ten  -1.57721    0.19401  -8.130 9.23e-16 ***\nas.factor(c_i)Tex  -1.03685    0.19296  -5.373 9.01e-08 ***\nas.factor(c_i)Ver  -1.68015    0.20291  -8.280 2.79e-16 ***\nas.factor(c_i)Vir  -2.01230    0.19542 -10.297  &lt; 2e-16 ***\nas.factor(c_i)Was  -0.86859    0.19566  -4.439 9.72e-06 ***\nas.factor(c_i)Wis  -1.41883    0.19395  -7.315 4.26e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.841 on 1430 degrees of freedom\nMultiple R-squared:  0.6639,    Adjusted R-squared:  0.6451 \nF-statistic: 35.32 on 80 and 1430 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "chapter7.html#data-description-for-feenstra-1989",
    "href": "chapter7.html#data-description-for-feenstra-1989",
    "title": "Chapter 7. Import Tariffs and Dumping",
    "section": "Data Description for Feenstra (1989)",
    "text": "Data Description for Feenstra (1989)\nThere are five data sets in excel format: cars.csv, trucks.csv, cycon.csv, cypool.csv, cyship.csv. All of the variables in the data sets are fitted values from instrumental variables regression.\n\n\n\nVariable\nDescription\n\n\n\n\niprice\nImport price\n\n\nusprice\nUS price\n\n\ngprice\nGerman price\n\n\ntariff\nTariff rate\n\n\nincome\nExpenditure on product class\n\n\nlag0\nFirst order polynomial lag on betas\n\n\nlag1\nSecond order polynomial lag on betas\n\n\nlag2\nThird order polynomial lag on betas\n\n\ny\nImport price transformed, y = iprice – income\n\n\nx1\nUS price transformed, usprice – income\n\n\nx2\nGerman price transformed, gprice – income\n\n\nz0\nFirst order polynomial lag transformed\n\n\nz1\nSecond order polynomial lag transformed\n\n\nz2\nThird order polynomial lag transformed\n\n\n\nNote: all the transformations are done to reflect their restrictions. So some are restricted to homogeneity, where others are restricted to symmetry and homogeneity.\n\nExplanation of lag0, lag1 and lag2\nWith a second-order polynomial, \\(\\alpha_i = a + bi + ci^2\\) it follows that\n\\[\\begin{align}\n\\sum_{i=0}^4 \\log(c_t^* s_{t-i}) \\alpha_i &= \\sum_{i=0}^4 \\log(c_t^* s_{t-i}) (a + bi + ci^2) \\\\\n&= a \\sum_{i=0}^4 \\log(c_t^* s_{t-i}) + b \\sum_{i=0}^4 \\log(c_t^* s_{t-i}) i + c \\sum_{i=0}^4 \\log(c_t^* s_{t-i}) i^2.\n\\end{align}\\]\nLetting \\(\\log(c_t^* s_{t-i}) = x_i\\), we can define the three lags appeating in this formula as\n\\[\\begin{align}\n\\text{lag}0 = x_0 + x_1 + x_2 + x_3 + x_4 \\\\\n\\text{lag}1 = 0 + x_1 + 2x_2 + 3x_3 + 4x_4 \\\\\n\\text{lag}2 = 0 + x_1 + 4x_2 + 9x_3 + 16x_4.\n\\end{align}\\]\nThen to compute the total pass-through of the exchange rate, it follow that,\n\\[\\begin{align}\n\\sum_{i=0}^4 \\alpha_i &= \\sum_{i=0}^4 (a + bi + ci^2) \\\\\n&= 5a + b(1 + 2 + 3 + 4) + c(1^2 + 2^2 + 3^2 + 4^2) \\\\\n&= 5a + 10b + 30c.\n\\end{align}\\]\nWhen estimating the equation using lag0, lag1, and lag2, the coefficient estimates that you obtain are a, b, and c, respectively. Using this, you can recover the coefficient estimate and standard error for each individual exchange rate term reported in the Table 7.2. You can always do this by hand, but STATA does offer a command to calculate the linear combination of the estimated coefficients. The syntax for this is,\nlincom lag0 + lag1 + lag2\nThis will calculate the coefficient estimates for the \\(\\log(c_t^* s_{t-1})\\). This is much in a same way as the syntax for test. Lag0 in above command does not refer to the data, but the coefficient estimate associated with lag0."
  },
  {
    "objectID": "chapter7.html#empirical-exercise",
    "href": "chapter7.html#empirical-exercise",
    "title": "Chapter 7. Import Tariffs and Dumping",
    "section": "Empirical exercise",
    "text": "Empirical exercise\nIn this exercise, you are asked to reproduce some of the empirical results from Feenstra (1989).\nTo complete the exercise, the files “cars.csv, trucks.csv, cycon.csv, cyship.csv, cypool.csv” should be stored in the directory: first-edition/Chapter-7. Each of these can be used in STATA programs “cars.do, trucks.do, cycon.do, cyship.do, cypool.do” to create a dataset with the variables described in “Documentation_Chp7.doc.”"
  },
  {
    "objectID": "chapter7.html#exercise-1",
    "href": "chapter7.html#exercise-1",
    "title": "Chapter 7. Import Tariffs and Dumping",
    "section": "Exercise 1",
    "text": "Exercise 1\nReplicate Table 7.2, i.e., run the specifications of (7.34) without imposing the tests of symmetry or homogeneity. Duplicate all of the coefficients that are reported in this table, except the Durbin-Watson statistics.\n\nFeenstra’s code\n\nCars\nclear\ncapture log close\n\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cars.log, replace\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cars.csv\n* drop if time&lt;=12\nregress iprice time timesq lag0 lag1 lag2 usprice gprice income\n\n*i=0\nlincom lag0\n\n*i=1\nlincom lag0+lag1+lag2\n\n*i=2\nlincom lag0+2*lag1+4*lag2\n\n*i=3\nlincom lag0+3*lag1+9*lag2\n\n*i=4\nlincom lag0+4*lag1+16*lag2\n\n*summation of betai's\nlincom 5*lag0+10*lag1+30*lag2\n\n*Impose the homogeneity constraint\nregress y time timesq z0 z1 z2 x1 x2\n\n*summation of betai's\nlincom 5*z0+10*z1+30*z2\n\nlog close\nexit\nOutput:\n. clear\n\n. capture log close\n\n. \n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cars.log, replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cars.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cars.log\n  log type:  text\n opened on:  19 Jun 2024, 13:46:47\n\n. \n. insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Ch\n&gt; apter-7\\cars.csv\n(15 vars, 46 obs)\n\n. * drop if time&lt;=12\n. regress iprice time timesq lag0 lag1 lag2 usprice gprice income\n\n      Source |       SS       df       MS              Number of obs =      29\n-------------+------------------------------           F(  8,    20) =  313.58\n       Model |  1.88266593     8  .235333241           Prob &gt; F      =  0.0000\n    Residual |  .015009666    20  .000750483           R-squared     =  0.9921\n-------------+------------------------------           Adj R-squared =  0.9889\n       Total |   1.8976756    28  .067774128           Root MSE      =  .02739\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        time |  -.0071005   .0198015    -0.36   0.724    -.0484056    .0342047\n      timesq |   .2232319   .1698526     1.31   0.204    -.1310743    .5775381\n        lag0 |   .4435311   .1011438     4.39   0.000     .2325488    .6545134\n        lag1 |  -.1156862    .165797    -0.70   0.493    -.4615325    .2301602\n        lag2 |  -.0116016   .0404346    -0.29   0.777    -.0959467    .0727435\n     usprice |   1.002242   .9090603     1.10   0.283    -.8940243    2.898509\n      gprice |   .0838093   .0880309     0.95   0.352      -.09982    .2674386\n      income |  -.0257564   .1138551    -0.23   0.823    -.2632538    .2117411\n       _cons |   3.370612   4.178309     0.81   0.429    -5.345189    12.08641\n------------------------------------------------------------------------------\n\n. \n. *i=0\n. lincom lag0\n\n ( 1)  lag0 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .4435311   .1011438     4.39   0.000     .2325488    .6545134\n------------------------------------------------------------------------------\n\n. \n. *i=1\n. lincom lag0+lag1+lag2\n\n ( 1)  lag0 + lag1 + lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .3162433    .041669     7.59   0.000     .2293232    .4031634\n------------------------------------------------------------------------------\n\n. \n. *i=2\n. lincom lag0+2*lag1+4*lag2\n\n ( 1)  lag0 + 2*lag1 + 4*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .1657523   .0782848     2.12   0.047     .0024531    .3290514\n------------------------------------------------------------------------------\n\n. \n. *i=3\n. lincom lag0+3*lag1+9*lag2\n\n ( 1)  lag0 + 3*lag1 + 9*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   -.007942    .051645    -0.15   0.879    -.1156716    .0997877\n------------------------------------------------------------------------------\n\n. \n. *i=4\n. lincom lag0+4*lag1+16*lag2\n\n ( 1)  lag0 + 4*lag1 + 16*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |  -.2048394   .0992571    -2.06   0.052    -.4118862    .0022073\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*lag0+10*lag1+30*lag2\n\n ( 1)  5*lag0 + 10*lag1 + 30*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .7127453   .0974163     7.32   0.000     .5095385     .915952\n------------------------------------------------------------------------------\n\n. \n. *Impose the homogeneity constraint\n. regress y time timesq z0 z1 z2 x1 x2\n\n      Source |       SS       df       MS              Number of obs =      29\n-------------+------------------------------           F(  7,    21) =   88.33\n       Model |  .457112589     7  .065301798           Prob &gt; F      =  0.0000\n    Residual |  .015525208    21  .000739296           R-squared     =  0.9672\n-------------+------------------------------           Adj R-squared =  0.9562\n       Total |  .472637797    28  .016879921           Root MSE      =  .02719\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        time |   .0089206   .0042701     2.09   0.049     .0000405    .0178007\n      timesq |   .1355201    .131858     1.03   0.316    -.1386936    .4097339\n          z0 |    .418623   .0958376     4.37   0.000     .2193179    .6179281\n          z1 |  -.0822192   .1595793    -0.52   0.612    -.4140826    .2496442\n          z2 |  -.0182092   .0393397    -0.46   0.648    -.1000206    .0636022\n          x1 |   .2590963   .1491977     1.74   0.097    -.0511772    .5693698\n          x2 |    .115353   .0787821     1.46   0.158    -.0484832    .2791893\n       _cons |   6.813711   .4488137    15.18   0.000     5.880352     7.74707\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*z0+10*z1+30*z2\n\n ( 1)  5*z0 + 10*z1 + 30*z2 = 0\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .7246472   .0956301     7.58   0.000     .5257736    .9235208\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cars.log\n  log type:  text\n closed on:  19 Jun 2024, 13:46:50\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\nCycon\nclear\ncapture log close\n\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cycon.log,replace\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cycon.csv\ndrop if time&lt;=16\ndrop if time&gt;=45\nregress iprice dummy1 dummy2 dummy3 time timesq lag0 lag1 lag2 /*\n     */ tariff usprice gprice income\n\n*i=0\nlincom lag0\n\n*i=1\nlincom lag0+lag1+lag2\n\n*i=2\nlincom lag0+2*lag1+4*lag2\n\n*i=3\nlincom lag0+3*lag1+9*lag2\n\n*i=4\nlincom lag0+4*lag1+16*lag2\n\n*summation of betai's\nlincom 5*lag0+10*lag1+30*lag2\n\n*Impose the homogeneity and symmetry constraints\nregress y dummy1 dummy2 dummy3 time timesq z0 z1 z2 x1 x2\n\n*summation of betai's\nlincom 5*z0+10*z1+30*z2\n\nlog close\nexit\nOutput:\n. clear\n\n. capture log close\n\n. \n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cycon.log,replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cycon.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cycon.log\n  log type:  text\n opened on:  19 Jun 2024, 13:48:28\n\n. \n. insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Ch\n&gt; apter-7\\cycon.csv\n(19 vars, 57 obs)\n\n. drop if time&lt;=16\n(16 observations deleted)\n\n. drop if time&gt;=45\n(13 observations deleted)\n\n. regress iprice dummy1 dummy2 dummy3 time timesq lag0 lag1 lag2 /*\n&gt;      */ tariff usprice gprice income\n\n      Source |       SS       df       MS              Number of obs =      28\n-------------+------------------------------           F( 12,    15) =   23.08\n       Model |  1.16011255    12  .096676046           Prob &gt; F      =  0.0000\n    Residual |  .062818315    15  .004187888           R-squared     =  0.9486\n-------------+------------------------------           Adj R-squared =  0.9075\n       Total |  1.22293087    27  .045293736           Root MSE      =  .06471\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      dummy1 |   .0634105   .0430635     1.47   0.162    -.0283773    .1551982\n      dummy2 |  -.0305492   .0369325    -0.83   0.421    -.1092689    .0481706\n      dummy3 |   .0397123   .0355224     1.12   0.281     -.036002    .1154265\n        time |  -.0197231   .0600121    -0.33   0.747    -.1476358    .1081896\n      timesq |     .41476   .4312669     0.96   0.351    -.5044635    1.333984\n        lag0 |   .2879891   .2546382     1.13   0.276    -.2547594    .8307377\n        lag1 |  -.1465425   .3537084    -0.41   0.685    -.9004542    .6073692\n        lag2 |   .0306294   .0866307     0.35   0.729    -.1540196    .2152783\n      tariff |   .9493961   .2181512     4.35   0.001     .4844179    1.414374\n     usprice |   .6821239    .597725     1.14   0.272    -.5918968    1.956145\n      gprice |   .0556783   .1064855     0.52   0.609    -.1712902    .2826468\n      income |  -.2273151   1.683928    -0.13   0.894    -3.816524    3.361893\n       _cons |   6.738914   11.55768     0.58   0.569     -17.8957    31.37353\n------------------------------------------------------------------------------\n\n. \n. *i=0\n. lincom lag0\n\n ( 1)  lag0 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .2879891   .2546382     1.13   0.276    -.2547594    .8307377\n------------------------------------------------------------------------------\n\n. \n. *i=1\n. lincom lag0+lag1+lag2\n\n ( 1)  lag0 + lag1 + lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |    .172076   .0947437     1.82   0.089    -.0298654    .3740173\n------------------------------------------------------------------------------\n\n. \n. *i=2\n. lincom lag0+2*lag1+4*lag2\n\n ( 1)  lag0 + 2*lag1 + 4*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .1174215   .1450444     0.81   0.431    -.1917333    .4265763\n------------------------------------------------------------------------------\n\n. \n. *i=3\n. lincom lag0+3*lag1+9*lag2\n\n ( 1)  lag0 + 3*lag1 + 9*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .1240258   .0837432     1.48   0.159    -.0544686    .3025202\n------------------------------------------------------------------------------\n\n. \n. *i=4\n. lincom lag0+4*lag1+16*lag2\n\n ( 1)  lag0 + 4*lag1 + 16*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .1918888   .2302309     0.83   0.418    -.2988368    .6826143\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*lag0+10*lag1+30*lag2\n\n ( 1)  5*lag0 + 10*lag1 + 30*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .8934012   .3594978     2.49   0.025     .1271498    1.659652\n------------------------------------------------------------------------------\n\n. \n. *Impose the homogeneity and symmetry constraints\n. regress y dummy1 dummy2 dummy3 time timesq z0 z1 z2 x1 x2\n\n      Source |       SS       df       MS              Number of obs =      28\n-------------+------------------------------           F( 10,    17) =    8.64\n       Model |  .321112891    10  .032111289           Prob &gt; F      =  0.0001\n    Residual |  .063155914    17  .003715054           R-squared     =  0.8356\n-------------+------------------------------           Adj R-squared =  0.7390\n       Total |  .384268805    27  .014232178           Root MSE      =  .06095\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      dummy1 |     .06846   .0367494     1.86   0.080    -.0090744    .1459945\n      dummy2 |  -.0296761   .0333669    -0.89   0.386    -.1000741    .0407219\n      dummy3 |   .0404237   .0329202     1.23   0.236    -.0290317    .1098792\n        time |   -.005507   .0157472    -0.35   0.731    -.0387307    .0277166\n      timesq |   .3625585    .253875     1.43   0.171    -.1730708    .8981879\n          z0 |   .3294302   .1732048     1.90   0.074        -.036    .6948604\n          z1 |  -.1849915   .2875633    -0.64   0.529    -.7916969     .421714\n          z2 |   .0391241   .0718017     0.54   0.593    -.1123642    .1906124\n          x1 |   .6062422    .501893     1.21   0.244    -.4526596    1.665144\n          x2 |   .0639407   .0948443     0.67   0.509    -.1361634    .2640447\n       _cons |    9.80264   1.904478     5.15   0.000     5.784542    13.82074\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*z0+10*z1+30*z2\n\n ( 1)  5*z0 + 10*z1 + 30*z2 = 0\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .9709581    .144562     6.72   0.000      .665959    1.275957\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cycon.log\n  log type:  text\n closed on:  19 Jun 2024, 13:48:30\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\nCypool\nclear\ncapture log close\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cypool.log,replace\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cypool.csv\n\nregress iprice dummy1 dummy2 dummy3 time timesq lag0 lag1 lag2 /*\n        */ tariff usprice gprice income\n\n*i=0\nlincom lag0\n\n*i=1\nlincom lag0+lag1+lag2\n\n*i=2\nlincom lag0+2*lag1+4*lag2\n\n*i=3\nlincom lag0+3*lag1+9*lag2\n\n*i=4\nlincom lag0+4*lag1+16*lag2\n\n*summation of betai's\nlincom 5*lag0+10*lag1+30*lag2\n\n*Impose the homogeneity and symmetry constraints\nregress y dummy1 dummy2 dummy3 time timesq z0 z1 z2 x1 x2\n\n*summation of betai's\nlincom 5*z0+10*z1+30*z2\n\nlog close\nexit\nOutput:\n. clear\n\n. capture log close\n\n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cypool.log,replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cypool.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cypool.log\n  log type:  text\n opened on:  19 Jun 2024, 13:49:29\n\n. \n. insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Ch\n&gt; apter-7\\cypool.csv\n(19 vars, 65 obs)\n\n. \n. regress iprice dummy1 dummy2 dummy3 time timesq lag0 lag1 lag2 /*\n&gt;         */ tariff usprice gprice income\n\n      Source |       SS       df       MS              Number of obs =      65\n-------------+------------------------------           F( 12,    52) =   28.69\n       Model |   3.7792523    12  .314937692           Prob &gt; F      =  0.0000\n    Residual |  .570888473    52  .010978624           R-squared     =  0.8688\n-------------+------------------------------           Adj R-squared =  0.8385\n       Total |  4.35014078    64   .06797095           Root MSE      =  .10478\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      dummy1 |   .0415538    .039227     1.06   0.294    -.0371609    .1202686\n      dummy2 |  -.0163882   .0377145    -0.43   0.666     -.092068    .0592915\n      dummy3 |   .0336136   .0373974     0.90   0.373    -.0414297     .108657\n        time |  -.0460622    .025957    -1.77   0.082    -.0981486    .0060242\n      timesq |   .6966283   .3011555     2.31   0.025     .0923156    1.300941\n        lag0 |   .4468833     .20907     2.14   0.037     .0273536    .8664129\n        lag1 |  -.4474712   .3375047    -1.33   0.191    -1.124724    .2297816\n        lag2 |   .1041952   .0844251     1.23   0.223    -.0652161    .2736065\n      tariff |   1.129379   .1548965     7.29   0.000     .8185561    1.440201\n     usprice |   .5715626   .5883761     0.97   0.336    -.6091005    1.752226\n      gprice |   .0630112   .1045199     0.60   0.549    -.1467234    .2727457\n      income |    .015869    .010022     1.58   0.119    -.0042417    .0359797\n       _cons |    5.86047   2.524698     2.32   0.024     .7942919    10.92665\n------------------------------------------------------------------------------\n\n. \n. *i=0\n. lincom lag0\n\n ( 1)  lag0 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .4468833     .20907     2.14   0.037     .0273536    .8664129\n------------------------------------------------------------------------------\n\n. \n. *i=1\n. lincom lag0+lag1+lag2\n\n ( 1)  lag0 + lag1 + lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .1036072    .091221     1.14   0.261    -.0794411    .2866556\n------------------------------------------------------------------------------\n\n. \n. *i=2\n. lincom lag0+2*lag1+4*lag2\n\n ( 1)  lag0 + 2*lag1 + 4*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |  -.0312784   .1532273    -0.20   0.839    -.3387515    .2761948\n------------------------------------------------------------------------------\n\n. \n. *i=3\n. lincom lag0+3*lag1+9*lag2\n\n ( 1)  lag0 + 3*lag1 + 9*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .0422264   .0851726     0.50   0.622    -.1286849    .2131377\n------------------------------------------------------------------------------\n\n. \n. *i=4\n. lincom lag0+4*lag1+16*lag2\n\n ( 1)  lag0 + 4*lag1 + 16*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .3241215   .2208683     1.47   0.148    -.1190832    .7673262\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*lag0+10*lag1+30*lag2\n\n ( 1)  5*lag0 + 10*lag1 + 30*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |     .88556   .2128404     4.16   0.000     .4584645    1.312655\n------------------------------------------------------------------------------\n\n. \n. *Impose the homogeneity and symmetry constraints\n. regress y dummy1 dummy2 dummy3 time timesq z0 z1 z2 x1 x2\n\n      Source |       SS       df       MS              Number of obs =      65\n-------------+------------------------------           F( 10,    54) = 1112.76\n       Model |  126.137525    10  12.6137525           Prob &gt; F      =  0.0000\n    Residual |  .612117901    54  .011335517           R-squared     =  0.9952\n-------------+------------------------------           Adj R-squared =  0.9943\n       Total |  126.749643    64  1.98046316           Root MSE      =  .10647\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      dummy1 |   .0390208   .0398367     0.98   0.332     -.040847    .1188886\n      dummy2 |  -.0079258   .0380454    -0.21   0.836    -.0842022    .0683506\n      dummy3 |   .0384614    .037904     1.01   0.315    -.0375315    .1144543\n        time |   -.016386   .0142608    -1.15   0.256    -.0449772    .0122052\n      timesq |   .3842091   .2086319     1.84   0.071    -.0340725    .8024908\n          z0 |   .4880678   .1718376     2.84   0.006     .1435541    .8325815\n          z1 |   -.432728   .2915576    -1.48   0.144    -1.017266    .1518097\n          z2 |   .0987337   .0738784     1.34   0.187    -.0493836    .2468511\n          x1 |  -.0833764   .1803078    -0.46   0.646    -.4448718     .278119\n          x2 |   -.009202   .0973665    -0.09   0.925      -.20441     .186006\n       _cons |    8.96105      .8661    10.35   0.000     7.224624    10.69748\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*z0+10*z1+30*z2\n\n ( 1)  5*z0 + 10*z1 + 30*z2 = 0\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |    1.07507   .1528333     7.03   0.000     .7686582    1.381483\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cypool.log\n  log type:  text\n closed on:  19 Jun 2024, 13:49:32\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\nCyship\nclear\ncapture log close\n\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cyship.log,replace\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\cyship.csv\ndrop if time&lt;=16\nregress iprice dummy1 dummy2 dummy3 time timesq lag0 lag1 lag2 /*\n     */ tariff usprice gprice income\n\n*i=0\nlincom lag0\n\n*i=1\nlincom lag0+lag1+lag2\n\n*i=2\nlincom lag0+2*lag1+4*lag2\n\n*i=3\nlincom lag0+3*lag1+9*lag2\n\n*i=4\nlincom lag0+4*lag1+16*lag2\n\n*summation of betai's\nlincom 5*lag0+10*lag1+30*lag2\n\n*Impose the homogeneity and symmetry constraints\nregress y dummy1 dummy2 dummy3 time timesq z0 z1 z2 x1 x2\n\n*summation of betai's\nlincom 5*z0+10*z1+30*z2\n\nlog close\nexit\nOutput:\n. clear\n\n. capture log close\n\n. \n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cyship.log,replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\cyship.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cyship.log\n  log type:  text\n opened on:  19 Jun 2024, 13:51:15\n\n. \n. insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Ch\n&gt; apter-7\\cyship.csv\n(19 vars, 57 obs)\n\n. drop if time&lt;=16\n(16 observations deleted)\n\n. regress iprice dummy1 dummy2 dummy3 time timesq lag0 lag1 lag2 /*\n&gt;      */ tariff usprice gprice income\n\n      Source |       SS       df       MS              Number of obs =      37\n-------------+------------------------------           F( 12,    24) =   13.33\n       Model |  2.66760727    12  .222300606           Prob &gt; F      =  0.0000\n    Residual |  .400138786    24  .016672449           R-squared     =  0.8696\n-------------+------------------------------           Adj R-squared =  0.8043\n       Total |  3.06774606    36  .085215168           Root MSE      =  .12912\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      dummy1 |   .0785462   .1458493     0.54   0.595    -.2224719    .3795643\n      dummy2 |   .0405177   .1327231     0.31   0.763    -.2334092    .3144447\n      dummy3 |   .0250007   .0625785     0.40   0.693     -.104155    .1541563\n        time |  -.0778322   .0554157    -1.40   0.173    -.1922045    .0365401\n      timesq |   1.035907    .568177     1.82   0.081    -.1367526    2.208567\n        lag0 |   .7977086   .6650261     1.20   0.242    -.5748378    2.170255\n        lag1 |  -1.112321   1.191004    -0.93   0.360    -3.570432    1.345791\n        lag2 |   .2729264   .3031369     0.90   0.377    -.3527174    .8985702\n      tariff |   1.388199   .2721709     5.10   0.000     .8264657    1.949932\n     usprice |   1.142866   1.998888     0.57   0.573    -2.982636    5.268368\n      gprice |   .1241107    .209419     0.59   0.559    -.3081089    .5563303\n      income |  -.2151571   .5969111    -0.36   0.722    -1.447121    1.016807\n       _cons |   4.611564   6.469095     0.71   0.483    -8.739992    17.96312\n------------------------------------------------------------------------------\n\n. \n. *i=0\n. lincom lag0\n\n ( 1)  lag0 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .7977086   .6650261     1.20   0.242    -.5748378    2.170255\n------------------------------------------------------------------------------\n\n. \n. *i=1\n. lincom lag0+lag1+lag2\n\n ( 1)  lag0 + lag1 + lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |  -.0416857   .2597043    -0.16   0.874     -.577689    .4943175\n------------------------------------------------------------------------------\n\n. \n. *i=2\n. lincom lag0+2*lag1+4*lag2\n\n ( 1)  lag0 + 2*lag1 + 4*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |  -.3352272   .5234521    -0.64   0.528    -1.415579    .7451248\n------------------------------------------------------------------------------\n\n. \n. *i=3\n. lincom lag0+3*lag1+9*lag2\n\n ( 1)  lag0 + 3*lag1 + 9*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |  -.0829159   .2158146    -0.38   0.704    -.5283353    .3625036\n------------------------------------------------------------------------------\n\n. \n. *i=4\n. lincom lag0+4*lag1+16*lag2\n\n ( 1)  lag0 + 4*lag1 + 16*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .7152483   .7584352     0.94   0.355     -.850085    2.280582\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*lag0+10*lag1+30*lag2\n\n ( 1)  5*lag0 + 10*lag1 + 30*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   1.053128   .5219069     2.02   0.055    -.0240347    2.130291\n------------------------------------------------------------------------------\n\n. \n. *Impose the homogeneity and symmetry constraints\n. regress y dummy1 dummy2 dummy3 time timesq z0 z1 z2 x1 x2\n\n      Source |       SS       df       MS              Number of obs =      37\n-------------+------------------------------           F( 10,    26) =   14.13\n       Model |  2.49470896    10  .249470896           Prob &gt; F      =  0.0000\n    Residual |   .45918364    26  .017660909           R-squared     =  0.8445\n-------------+------------------------------           Adj R-squared =  0.7848\n       Total |   2.9538926    36  .082052572           Root MSE      =  .13289\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      dummy1 |   .0455011   .0952729     0.48   0.637    -.1503351    .2413373\n      dummy2 |   .0311428   .0889305     0.35   0.729    -.1516564    .2139419\n      dummy3 |   .0367732   .0635252     0.58   0.568    -.0938049    .1673512\n        time |  -.0260349   .0241189    -1.08   0.290    -.0756121    .0235423\n      timesq |   .4997075   .3460414     1.44   0.161    -.2115907    1.211006\n          z0 |   .7524749   .3159082     2.38   0.025     .1031163    1.401833\n          z1 |   -.912172   .5807959    -1.57   0.128    -2.106015    .2816711\n          z2 |   .2210294   .1505169     1.47   0.154    -.0883625    .5304214\n          x1 |  -.1613882   .3756296    -0.43   0.671    -.9335059    .6107296\n          x2 |  -.0247239   .1679367    -0.15   0.884    -.3699227    .3204749\n       _cons |   10.24826   1.511092     6.78   0.000     7.142165    13.35435\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*z0+10*z1+30*z2\n\n ( 1)  5*z0 + 10*z1 + 30*z2 = 0\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   1.271538   .2703125     4.70   0.000     .7159023    1.827173\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\cyship.log\n  log type:  text\n closed on:  19 Jun 2024, 13:51:17\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\n\nTrucks\nclear\ncapture log close\n\nlog using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\trucks.log, replace\n\ninsheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapter-7\\trucks.csv\ndrop if time&lt;=12\nregress iprice time timesq lag0 lag1 lag2 tariff usprice income\n\n*i=0\nlincom lag0\n\n*i=1\nlincom lag0+lag1+lag2\n\n*i=2\nlincom lag0+2*lag1+4*lag2\n\n*i=3\nlincom lag0+3*lag1+9*lag2\n\n*i=4\nlincom lag0+4*lag1+16*lag2\n\n*summation of betai's\nlincom 5*lag0+10*lag1+30*lag2\n\n*Impose the homogeneity and symmetry constraints\nregress y time timesq z0 z1 z2 x1\n\n*summation of betai's\nlincom 5*z0+10*z1+30*z2\n\nlog close\nexit\nOutput:\n. clear\n\n. capture log close\n\n. \n. log using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\trucks.log, replace\n(note: file Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapte\n&gt; r-7\\trucks.log not found)\n----------------------------------------------------------------------------------\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\trucks.log\n  log type:  text\n opened on:  19 Jun 2024, 13:52:25\n\n. \n. insheet using Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Ch\n&gt; apter-7\\trucks.csv\n(14 vars, 53 obs)\n\n. drop if time&lt;=12\n(12 observations deleted)\n\n. regress iprice time timesq lag0 lag1 lag2 tariff usprice income\n\n      Source |       SS       df       MS              Number of obs =      41\n-------------+------------------------------           F(  8,    32) =  468.92\n       Model |  2.20983016     8  .276228771           Prob &gt; F      =  0.0000\n    Residual |  .018850254    32   .00058907           R-squared     =  0.9915\n-------------+------------------------------           Adj R-squared =  0.9894\n       Total |  2.22868042    40   .05571701           Root MSE      =  .02427\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        time |   .0352992   .0115245     3.06   0.004     .0118245    .0587738\n      timesq |  -.3687581   .0950987    -3.88   0.000    -.5624678   -.1750484\n        lag0 |   .2817325   .0563137     5.00   0.000     .1670253    .3964397\n        lag1 |  -.1750568    .103425    -1.69   0.100    -.3857266    .0356129\n        lag2 |   .0322891   .0269044     1.20   0.239    -.0225134    .0870917\n      tariff |   .5702031     .13745     4.15   0.000     .2902267    .8501795\n     usprice |   .0294371    .396435     0.07   0.941    -.7780745    .8369488\n      income |  -.0321876   .0586085    -0.55   0.587    -.1515693     .087194\n       _cons |   8.195509   1.925592     4.26   0.000     4.273206    12.11781\n------------------------------------------------------------------------------\n\n. \n. *i=0\n. lincom lag0\n\n ( 1)  lag0 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .2817325   .0563137     5.00   0.000     .1670253    .3964397\n------------------------------------------------------------------------------\n\n. \n. *i=1\n. lincom lag0+lag1+lag2\n\n ( 1)  lag0 + lag1 + lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .1389648   .0300367     4.63   0.000      .077782    .2001476\n------------------------------------------------------------------------------\n\n. \n. *i=2\n. lincom lag0+2*lag1+4*lag2\n\n ( 1)  lag0 + 2*lag1 + 4*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .0607753   .0495382     1.23   0.229    -.0401306    .1616813\n------------------------------------------------------------------------------\n\n. \n. *i=3\n. lincom lag0+3*lag1+9*lag2\n\n ( 1)  lag0 + 3*lag1 + 9*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .0471641   .0279295     1.69   0.101    -.0097265    .1040548\n------------------------------------------------------------------------------\n\n. \n. *i=4\n. lincom lag0+4*lag1+16*lag2\n\n ( 1)  lag0 + 4*lag1 + 16*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .0981312   .0787782     1.25   0.222    -.0623347    .2585971\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*lag0+10*lag1+30*lag2\n\n ( 1)  5*lag0 + 10*lag1 + 30*lag2 = 0\n\n------------------------------------------------------------------------------\n      iprice |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .6267679   .0805593     7.78   0.000      .462674    .7908619\n------------------------------------------------------------------------------\n\n. \n. *Impose the homogeneity and symmetry constraints\n. regress y time timesq z0 z1 z2 x1\n\n      Source |       SS       df       MS              Number of obs =      41\n-------------+------------------------------           F(  6,    34) =  791.27\n       Model |  2.71482325     6  .452470541           Prob &gt; F      =  0.0000\n    Residual |  .019442165    34  .000571828           R-squared     =  0.9929\n-------------+------------------------------           Adj R-squared =  0.9916\n       Total |  2.73426541    40  .068356635           Root MSE      =  .02391\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n        time |   .0243984   .0032516     7.50   0.000     .0177904    .0310064\n      timesq |  -.2899041   .0503788    -5.75   0.000    -.3922861   -.1875221\n          z0 |    .284604   .0551443     5.16   0.000     .1725374    .3966706\n          z1 |  -.1985585   .0981501    -2.02   0.051    -.3980235    .0009066\n          z2 |    .038167   .0254203     1.50   0.142    -.0134932    .0898273\n          x1 |   .3967109   .0705105     5.63   0.000     .2534164    .5400055\n       _cons |   6.402397   .3544569    18.06   0.000     5.682054     7.12274\n------------------------------------------------------------------------------\n\n. \n. *summation of betai's\n. lincom 5*z0+10*z1+30*z2\n\n ( 1)  5*z0 + 10*z1 + 30*z2 = 0\n\n------------------------------------------------------------------------------\n           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         (1) |   .5824464   .0618586     9.42   0.000     .4567346    .7081583\n------------------------------------------------------------------------------\n\n. \n. log close\n      name:  &lt;unnamed&gt;\n       log:  Z:\\home\\pacha\\github\\advanced-international-trade\\first-edition\\Chapt\n&gt; er-7\\trucks.log\n  log type:  text\n closed on:  19 Jun 2024, 13:52:28\n----------------------------------------------------------------------------------\n\n. exit\n\nend of do-file\n\n\nMy code\n\n# Packages ----\n\nlibrary(archive)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(broom)\n\n# Extract ----\n\nfzip &lt;- \"first-edition/Chapter-7.zip\"\ndout &lt;- gsub(\"\\\\.zip$\", \"\", fzip)\n\nif (!dir.exists(dout)) {\n  archive_extract(fzip, dir = dout)\n}\n\n# Read and transform ----\n\nfout &lt;- paste0(dout, \"/feenstra_93.rds\")\n\nif (!file.exists(fout)) {\n  feenstra_93 &lt;- list(\n    cars = read_csv(paste0(dout, \"/cars.csv\")),\n    cycon = read_csv(paste0(dout, \"/cycon.csv\")) %&gt;%\n      filter(time &gt; 16 & time &lt; 45),\n    cypool = read_csv(paste0(dout, \"/cypool.csv\")),\n    cyship = read_csv(paste0(dout, \"/cyship.csv\")) %&gt;%\n      filter(time &gt; 16),\n    trucks = read_csv(paste0(dout, \"/trucks.csv\")) %&gt;%\n      filter(time &gt; 12)\n  )\n\n  saveRDS(feenstra_93, fout)\n} else {\n  feenstra_93 &lt;- readRDS(fout)\n}\n\n# Models ----\n\n## Cars ----\n\nmod1 &lt;- lm(\n  iprice ~ time + timesq + lag0 + lag1 + lag2 + usprice + gprice + income,\n  data = feenstra_93$cars\n)\n\nmod1_tidy &lt;- tidy(mod1)\n\n# i = 0\n\nmod1_tidy %&gt;%\n  filter(term == \"lag0\")\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic  p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 lag0     0.444     0.101      4.39 0.000286\n\n# i = 1\n# use the delta method to calculate the standard errors\n# define auxiliary variables and functions\n\nmod1_vcov &lt;- vcov(mod1)\n\nmod1_summ &lt;- summary(mod1)\n\nw &lt;- c(1, 1, 1)\n\nstd_error &lt;- function(w, X, vars) {\n  as.numeric(sqrt(w %*% X[vars, vars] %*% w))\n}\n\np_value &lt;- function(statistic, summary) {\n  as.numeric(2 * pt(-abs(statistic), df = summary$df[2]))\n}\n\nmod1_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(w = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * w),\n    std.error = std_error(w, mod1_vcov, c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, mod1_summ)\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic     p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1    0.316    0.0417      7.59 0.000000261\n\n# i = 2\n\nw &lt;- c(1, 2, 4)\n\nmod1_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 2, 4)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, mod1_vcov, c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, mod1_summ)\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.166    0.0783      2.12  0.0470\n\n# i = 3\n\nw &lt;- c(1, 3, 9)\n\nmod1_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 3, 9)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, mod1_vcov, c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, mod1_summ)\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 -0.00794    0.0516    -0.154   0.879\n\n# i = 4\n\nw &lt;- c(1, 4, 16)\n\nmod1_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 4, 16)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, mod1_vcov, c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, mod1_summ)\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1   -0.205    0.0993     -2.06  0.0523\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod1_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, mod1_vcov, c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, mod1_summ)\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic     p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1    0.713    0.0974      7.32 0.000000450\n\n## Cycon ----\n\nmod2 &lt;- lm(\n  iprice ~ dummy1 + dummy2 + dummy3 + time + timesq + lag0 + lag1 + lag2 +\n    tariff + usprice + gprice + income,\n  data = feenstra_93$cycon\n)\n\nmod2_tidy &lt;- tidy(mod2)\n\n# i = 0\n\nmod2_tidy %&gt;%\n  filter(term == \"lag0\")\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 lag0     0.288     0.255      1.13   0.276\n\n# i = 1\n\nw &lt;- c(1, 1, 1)\n\nmod2_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(w = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * w),\n    std.error = std_error(w, vcov(mod2), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod2))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.172    0.0947      1.82  0.0894\n\n# i = 2\n\nw &lt;- c(1, 2, 4)\n\nmod2_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 2, 4)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod2), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod2))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.117     0.145     0.810   0.431\n\n# i = 3\n\nw &lt;- c(1, 3, 9)\n\nmod2_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 3, 9)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod2), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod2))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.124    0.0837      1.48   0.159\n\n# i = 4\n\nw &lt;- c(1, 4, 16)\n\nmod2_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 4, 16)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod2), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod2))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.192     0.230     0.833   0.418\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod2_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod2), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod2))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.893     0.359      2.49  0.0252\n\n## Cypool ----\n\nmod3 &lt;- lm(\n  iprice ~ dummy1 + dummy2 + dummy3 + time + timesq + lag0 + lag1 + lag2 +\n    tariff + usprice + gprice + income,\n  data = feenstra_93$cypool\n)\n\nmod3_tidy &lt;- tidy(mod3)\n\n# i = 0\n\nmod3_tidy %&gt;%\n  filter(term == \"lag0\")\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 lag0     0.447     0.209      2.14  0.0373\n\n# i = 1\n\nw &lt;- c(1, 1, 1)\n\nmod3_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(w = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * w),\n    std.error = std_error(w, vcov(mod3), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod3))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.104    0.0912      1.14   0.261\n\n# i = 2\n\nw &lt;- c(1, 2, 4)\n\nmod3_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 2, 4)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod3), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod3))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1  -0.0313     0.153    -0.204   0.839\n\n# i = 3\n\nw &lt;- c(1, 3, 9)\n\nmod3_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 3, 9)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod3), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod3))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1   0.0422    0.0852     0.496   0.622\n\n# i = 4\n\nw &lt;- c(1, 4, 16)\n\nmod3_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 4, 16)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod3), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod3))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.324     0.221      1.47   0.148\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod3_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod3), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod3))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic  p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1    0.886     0.213      4.16 0.000119\n\n## Cyship ----\n\nmod4 &lt;- lm(\n  iprice ~ dummy1 + dummy2 + dummy3 + time + timesq + lag0 + lag1 + lag2 +\n    tariff + usprice + gprice + income,\n  data = feenstra_93$cyship\n)\n\nmod4_tidy &lt;- tidy(mod4)\n\n# i = 0\n\nmod4_tidy %&gt;%\n  filter(term == \"lag0\")\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 lag0     0.798     0.665      1.20   0.242\n\n# i = 1\n\nw &lt;- c(1, 1, 1)\n\nmod4_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(w = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * w),\n    std.error = std_error(w, vcov(mod4), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod4))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1  -0.0417     0.260    -0.160   0.874\n\n# i = 2\n\nw &lt;- c(1, 2, 4)\n\nmod4_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 2, 4)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod4), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod4))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1   -0.335     0.523    -0.640   0.528\n\n# i = 3\n\nw &lt;- c(1, 3, 9)\n\nmod4_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 3, 9)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod4), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod4))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1  -0.0829     0.216    -0.384   0.704\n\n# i = 4\n\nw &lt;- c(1, 4, 16)\n\nmod4_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 4, 16)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod4), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod4))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1    0.715     0.758     0.943   0.355\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod4_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod4), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod4))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     1.05     0.522      2.02  0.0549\n\n## Trucks ----\n\nmod5 &lt;- lm(\n  iprice ~ time + timesq + lag0 + lag1 + lag2 + tariff + usprice + income,\n  data = feenstra_93$trucks\n)\n\nmod5_tidy &lt;- tidy(mod5)\n\n# i = 0\n\nmod5_tidy %&gt;%\n  filter(term == \"lag0\")\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic   p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 lag0     0.282    0.0563      5.00 0.0000197\n\n# i = 1\n\nw &lt;- c(1, 1, 1)\n\nmod5_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(w = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * w),\n    std.error = std_error(w, vcov(mod5), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod5))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic   p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1    0.139    0.0300      4.63 0.0000586\n\n# i = 2\n\nw &lt;- c(1, 2, 4)\n\nmod5_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 2, 4)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod5), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod5))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1   0.0608    0.0495      1.23   0.229\n\n# i = 3\n\nw &lt;- c(1, 3, 9)\n\nmod5_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 3, 9)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod5), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod5))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1   0.0472    0.0279      1.69   0.101\n\n# i = 4\n\nw &lt;- c(1, 4, 16)\n\nmod5_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = c(1, 4, 16)) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod5), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod5))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1   0.0981    0.0788      1.25   0.222\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod5_tidy %&gt;%\n  filter(term %in% c(\"lag0\", \"lag1\", \"lag2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod5), c(\"lag0\", \"lag1\", \"lag2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod5))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic       p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1    0.627    0.0806      7.78 0.00000000713"
  },
  {
    "objectID": "chapter7.html#exercise-2",
    "href": "chapter7.html#exercise-2",
    "title": "Chapter 7. Import Tariffs and Dumping",
    "section": "Exercise 2",
    "text": "Exercise 2\nThen replicate Feenstra’s Table 2 by imposing the tests of homogeneity and symmetry, shown in (7.35a) and (7.35b). Instead of conducting the Wald test, as done in Feenstra (1989), instead conduct the analogous F-test. Do you accept or reject the hypotheses of symmetry and homogeneity?\n\nFeenstra’s code\nIncluded in exercise 1.\n\n\nMy code\n\n## Cars ----\n\n# impose the homogeneity and symmetry constraints\n\nmod1h &lt;- lm(\n  y ~ time + timesq + z0 + z1 + z2 + x1 + x2,\n  data = feenstra_93$cars\n)\n\nmod1h_tidy &lt;- tidy(mod1h)\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod1h_tidy %&gt;%\n  filter(term %in% c(\"z0\", \"z1\", \"z2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod1h), c(\"z0\", \"z1\", \"z2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod1h))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic     p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1    0.725    0.0956      7.58 0.000000194\n\n## Cycon ----\n\n# impose the homogeneity and symmetry constraints\n\nmod2h &lt;- lm(\n  y ~ dummy1 + dummy2 + dummy3 + time + timesq + z0 + z1 + z2 + x1 + x2,\n  data = feenstra_93$cycon\n)\n\nmod2h_tidy &lt;- tidy(mod2h)\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod2h_tidy %&gt;%\n  filter(term %in% c(\"z0\", \"z1\", \"z2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod2h), c(\"z0\", \"z1\", \"z2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod2h))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic    p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1    0.971     0.145      6.72 0.00000362\n\n## Cypool ----\n\n# impose the homogeneity and symmetry constraints\n\nmod3h &lt;- lm(\n  y ~ dummy1 + dummy2 + dummy3 + time + timesq + z0 + z1 + z2 + x1 + x2,\n  data = feenstra_93$cypool\n)\n\nmod3h_tidy &lt;- tidy(mod3h)\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod3h_tidy %&gt;%\n  filter(term %in% c(\"z0\", \"z1\", \"z2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod3h), c(\"z0\", \"z1\", \"z2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod3h))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic       p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1     1.08     0.153      7.03 0.00000000362\n\n## Cyship ----\n\n# impose the homogeneity and symmetry constraints\n\nmod4h &lt;- lm(\n  y ~ dummy1 + dummy2 + dummy3 + time + timesq + z0 + z1 + z2 + x1 + x2,\n  data = feenstra_93$cyship\n)\n\nmod4h_tidy &lt;- tidy(mod4h)\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod4h_tidy %&gt;%\n  filter(term %in% c(\"z0\", \"z1\", \"z2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod4h), c(\"z0\", \"z1\", \"z2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod4h))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic   p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1     1.27     0.270      4.70 0.0000734\n\n## Trucks ----\n\n# impose the homogeneity and symmetry constraints\n\nmod5h &lt;- lm(\n  y ~ time + timesq + z0 + z1 + z2 + x1,\n  data = feenstra_93$trucks\n)\n\nmod5h_tidy &lt;- tidy(mod5h)\n\n# summation of betai's\n\nw &lt;- c(5, 10, 30)\n\nmod5h_tidy %&gt;%\n  filter(term %in% c(\"z0\", \"z1\", \"z2\")) %&gt;%\n  mutate(weight = w) %&gt;%\n  summarise(\n    estimate = sum(estimate * weight),\n    std.error = std_error(weight, vcov(mod5h), c(\"z0\", \"z1\", \"z2\")),\n    statistic = estimate / std.error,\n    p.value = p_value(statistic, summary(mod5h))\n  )\n\n# A tibble: 1 × 4\n  estimate std.error statistic  p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1    0.582    0.0619      9.42 5.33e-11"
  }
]